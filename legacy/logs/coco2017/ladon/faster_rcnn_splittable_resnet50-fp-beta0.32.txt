2023-02-26 16:34:44,923	INFO	torchdistill.common.main_util	Not using distributed mode
2023-02-26 16:34:44,923	INFO	__main__	Namespace(adjust_lr=False, config='configs/coco2017/proposed/faster_rcnn_splittable_resnet50-fp-beta0.32_fpn.yaml', device='cuda', dist_url='env://', iou_types=None, json=None, log='logs/coco2017/proposed/faster_rcnn_splittable_resnet50-fp-beta0.32.txt', log_config=False, no_dp_eval=False, seed=None, start_epoch=0, student_only=False, test_only=False, world_size=1)
2023-02-26 16:35:09,341	INFO	torchdistill.common.main_util	Loading model parameters
2023-02-26 16:35:09,689	INFO	torchdistill.common.main_util	ckpt file is not found at `./resource/ckpt/coco2017/supervised_compression/entropic_student/coco2017-faster_rcnn_splittable_resnet50-fp-beta0.32_fpn.pt`
2023-02-26 16:35:14,948	INFO	__main__	Start training
2023-02-26 16:35:15,183	INFO	torchdistill.datasets.sampler	Using [0, 0.5, 0.6299605249474366, 0.7937005259840997, 1.0, 1.2599210498948732, 1.5874010519681994, 2.0, inf] as bins for aspect ratio quantization
2023-02-26 16:35:15,183	INFO	torchdistill.datasets.sampler	Count of instances per bin: [  104   982 24236  2332  8225 74466  5763  1158]
2023-02-26 16:35:15,186	INFO	torchdistill.models.util	[student model]
2023-02-26 16:35:15,186	INFO	torchdistill.models.util	Using the original student model
2023-02-26 16:35:15,186	INFO	torchdistill.models.util	Frozen module(s): {'backbone.body'}
2023-02-26 16:35:15,187	INFO	torchdistill.core.training	Loss = 1.0 * OrgLoss
2023-02-26 16:35:15,196	INFO	__main__	Updating entropy bottleneck
2023-02-26 16:35:17,416	INFO	torchdistill.misc.log	Epoch: [0]  [    0/14658]  eta: 9:02:00  lr: 0.02  img/s: 7.385448120833303  loss: 5.6155 (5.6155)  time: 2.2186  data: 1.1259  max mem: 9388
2023-02-26 16:37:59,965	INFO	torchdistill.misc.log	Epoch: [0]  [ 1000/14658]  eta: 0:37:28  lr: 0.02  img/s: 60.45603958041303  loss: 1.0729 (1.2429)  time: 0.1557  data: 0.0128  max mem: 9591
2023-02-26 16:40:38,186	INFO	torchdistill.misc.log	Epoch: [0]  [ 2000/14658]  eta: 0:34:03  lr: 0.02  img/s: 60.588564990032644  loss: 1.0535 (1.1815)  time: 0.1550  data: 0.0123  max mem: 9591
2023-02-26 16:43:14,821	INFO	torchdistill.misc.log	Epoch: [0]  [ 3000/14658]  eta: 0:31:03  lr: 0.02  img/s: 53.88002479277798  loss: 1.0088 (1.1457)  time: 0.1563  data: 0.0122  max mem: 9591
2023-02-26 16:45:51,218	INFO	torchdistill.misc.log	Epoch: [0]  [ 4000/14658]  eta: 0:28:14  lr: 0.02  img/s: 59.93778725699822  loss: 1.0196 (1.1239)  time: 0.1564  data: 0.0123  max mem: 9591
2023-02-26 16:48:28,003	INFO	torchdistill.misc.log	Epoch: [0]  [ 5000/14658]  eta: 0:25:31  lr: 0.02  img/s: 59.779001902698695  loss: 0.9186 (1.1057)  time: 0.1568  data: 0.0124  max mem: 9591
2023-02-26 16:51:04,663	INFO	torchdistill.misc.log	Epoch: [0]  [ 6000/14658]  eta: 0:22:49  lr: 0.02  img/s: 60.87534991899477  loss: 1.0447 (1.0892)  time: 0.1578  data: 0.0133  max mem: 9591
2023-02-26 16:53:41,702	INFO	torchdistill.misc.log	Epoch: [0]  [ 7000/14658]  eta: 0:20:10  lr: 0.02  img/s: 60.292875060195065  loss: 1.0735 (1.0799)  time: 0.1582  data: 0.0129  max mem: 9591
2023-02-26 16:56:18,416	INFO	torchdistill.misc.log	Epoch: [0]  [ 8000/14658]  eta: 0:17:31  lr: 0.02  img/s: 60.204492402317435  loss: 0.8634 (1.0712)  time: 0.1568  data: 0.0127  max mem: 9591
2023-02-26 16:58:55,874	INFO	torchdistill.misc.log	Epoch: [0]  [ 9000/14658]  eta: 0:14:53  lr: 0.02  img/s: 59.04289590467108  loss: 1.0689 (1.0620)  time: 0.1553  data: 0.0122  max mem: 9591
2023-02-26 17:01:32,385	INFO	torchdistill.misc.log	Epoch: [0]  [10000/14658]  eta: 0:12:14  lr: 0.02  img/s: 59.98171648394472  loss: 0.9391 (1.0535)  time: 0.1564  data: 0.0124  max mem: 9591
2023-02-26 17:04:08,700	INFO	torchdistill.misc.log	Epoch: [0]  [11000/14658]  eta: 0:09:36  lr: 0.02  img/s: 59.48281076328259  loss: 0.8848 (1.0471)  time: 0.1572  data: 0.0125  max mem: 9591
2023-02-26 17:06:45,228	INFO	torchdistill.misc.log	Epoch: [0]  [12000/14658]  eta: 0:06:58  lr: 0.02  img/s: 58.597362681117026  loss: 0.8694 (1.0419)  time: 0.1538  data: 0.0121  max mem: 9591
2023-02-26 17:09:21,977	INFO	torchdistill.misc.log	Epoch: [0]  [13000/14658]  eta: 0:04:21  lr: 0.02  img/s: 60.258876010617094  loss: 0.8929 (1.0367)  time: 0.1583  data: 0.0129  max mem: 9591
2023-02-26 17:11:58,772	INFO	torchdistill.misc.log	Epoch: [0]  [14000/14658]  eta: 0:01:43  lr: 0.02  img/s: 62.57341754919896  loss: 0.9589 (1.0312)  time: 0.1557  data: 0.0128  max mem: 9591
2023-02-26 17:13:41,864	INFO	torchdistill.misc.log	Epoch: [0] Total time: 0:38:26
2023-02-26 17:13:48,868	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 2:20:22  model_time: 1.1160 (1.1160)  evaluator_time: 0.0533 (0.0533)  time: 1.6845  data: 0.5115  max mem: 17051
2023-02-26 17:15:45,993	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:07:54  model_time: 0.0834 (0.1027)  evaluator_time: 0.0082 (0.0146)  time: 0.0984  data: 0.0001  max mem: 17061
2023-02-26 17:17:29,211	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:32  model_time: 0.0849 (0.0950)  evaluator_time: 0.0095 (0.0149)  time: 0.1003  data: 0.0001  max mem: 17061
2023-02-26 17:19:12,031	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:36  model_time: 0.0834 (0.0926)  evaluator_time: 0.0083 (0.0147)  time: 0.0988  data: 0.0001  max mem: 17061
2023-02-26 17:20:52,952	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:46  model_time: 0.0838 (0.0909)  evaluator_time: 0.0087 (0.0146)  time: 0.1002  data: 0.0001  max mem: 17061
2023-02-26 17:22:36,514	INFO	torchdistill.misc.log	Validation: Total time: 0:08:49
2023-02-26 17:22:36,514	INFO	__main__	Averaged stats: model_time: 0.0816 (0.0900)  evaluator_time: 0.0094 (0.0150)
2023-02-26 17:22:36,751	INFO	__main__	Accumulating evaluation results...
2023-02-26 17:22:50,869	INFO	__main__	DONE (t=14.12s).
2023-02-26 17:22:50,870	INFO	__main__	IoU metric: bbox
2023-02-26 17:22:50,871	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.140
2023-02-26 17:22:50,871	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.300
2023-02-26 17:22:50,871	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.112
2023-02-26 17:22:50,872	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.033
2023-02-26 17:22:50,873	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.140
2023-02-26 17:22:50,873	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.241
2023-02-26 17:22:50,874	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.163
2023-02-26 17:22:50,874	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.253
2023-02-26 17:22:50,874	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.267
2023-02-26 17:22:50,874	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.072
2023-02-26 17:22:50,874	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.285
2023-02-26 17:22:50,874	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.437
2023-02-26 17:22:50,874	INFO	__main__	Best mAP (bbox): 0.0000 -> 0.1403
2023-02-26 17:22:50,875	INFO	__main__	Updating ckpt at ./resource/ckpt/coco2017/supervised_compression/entropic_student/coco2017-faster_rcnn_splittable_resnet50-fp-beta0.32_fpn.pt
2023-02-26 17:22:52,047	INFO	torchdistill.misc.log	Epoch: [1]  [    0/14658]  eta: 3:13:15  lr: 0.02  img/s: 53.33474056989902  loss: 1.2448 (1.2448)  time: 0.7911  data: 0.6318  max mem: 17061
2023-02-26 17:25:28,017	INFO	torchdistill.misc.log	Epoch: [1]  [ 1000/14658]  eta: 0:35:38  lr: 0.02  img/s: 60.30631200575126  loss: 1.0483 (0.9376)  time: 0.1565  data: 0.0130  max mem: 17061
2023-02-26 17:28:04,478	INFO	torchdistill.misc.log	Epoch: [1]  [ 2000/14658]  eta: 0:33:01  lr: 0.02  img/s: 60.03483886666333  loss: 0.9423 (0.9399)  time: 0.1576  data: 0.0131  max mem: 17061
2023-02-26 17:30:40,853	INFO	torchdistill.misc.log	Epoch: [1]  [ 3000/14658]  eta: 0:30:24  lr: 0.02  img/s: 59.75409141257466  loss: 0.8755 (0.9400)  time: 0.1584  data: 0.0134  max mem: 17061
2023-02-26 17:33:17,606	INFO	torchdistill.misc.log	Epoch: [1]  [ 4000/14658]  eta: 0:27:48  lr: 0.02  img/s: 58.857305235240254  loss: 0.9747 (0.9427)  time: 0.1570  data: 0.0131  max mem: 17061
2023-02-26 17:35:53,966	INFO	torchdistill.misc.log	Epoch: [1]  [ 5000/14658]  eta: 0:25:11  lr: 0.02  img/s: 57.00476874070928  loss: 0.9167 (0.9414)  time: 0.1572  data: 0.0126  max mem: 17061
2023-02-26 17:38:30,437	INFO	torchdistill.misc.log	Epoch: [1]  [ 6000/14658]  eta: 0:22:34  lr: 0.02  img/s: 58.91486653287472  loss: 0.9286 (0.9410)  time: 0.1575  data: 0.0134  max mem: 17061
2023-02-26 17:41:07,030	INFO	torchdistill.misc.log	Epoch: [1]  [ 7000/14658]  eta: 0:19:58  lr: 0.02  img/s: 60.21389169032434  loss: 0.9162 (0.9386)  time: 0.1568  data: 0.0129  max mem: 17061
2023-02-26 17:43:43,611	INFO	torchdistill.misc.log	Epoch: [1]  [ 8000/14658]  eta: 0:17:22  lr: 0.02  img/s: 60.14999121621379  loss: 0.9431 (0.9383)  time: 0.1571  data: 0.0131  max mem: 17061
2023-02-26 17:46:20,109	INFO	torchdistill.misc.log	Epoch: [1]  [ 9000/14658]  eta: 0:14:45  lr: 0.02  img/s: 60.61428574009209  loss: 0.9571 (0.9374)  time: 0.1567  data: 0.0126  max mem: 17061
2023-02-26 17:48:56,939	INFO	torchdistill.misc.log	Epoch: [1]  [10000/14658]  eta: 0:12:09  lr: 0.02  img/s: 60.242431641501646  loss: 0.9291 (0.9374)  time: 0.1590  data: 0.0134  max mem: 17061
2023-02-26 17:51:33,506	INFO	torchdistill.misc.log	Epoch: [1]  [11000/14658]  eta: 0:09:32  lr: 0.02  img/s: 61.27063068458832  loss: 0.7934 (0.9362)  time: 0.1591  data: 0.0136  max mem: 17061
2023-02-26 17:54:10,189	INFO	torchdistill.misc.log	Epoch: [1]  [12000/14658]  eta: 0:06:56  lr: 0.02  img/s: 60.15473590987483  loss: 0.9735 (0.9358)  time: 0.1556  data: 0.0129  max mem: 17061
2023-02-26 17:56:46,955	INFO	torchdistill.misc.log	Epoch: [1]  [13000/14658]  eta: 0:04:19  lr: 0.02  img/s: 60.500513870908414  loss: 0.9335 (0.9355)  time: 0.1571  data: 0.0124  max mem: 17061
2023-02-26 17:59:23,884	INFO	torchdistill.misc.log	Epoch: [1]  [14000/14658]  eta: 0:01:43  lr: 0.02  img/s: 59.98246705422199  loss: 0.9549 (0.9349)  time: 0.1552  data: 0.0125  max mem: 17061
2023-02-26 18:01:06,969	INFO	torchdistill.misc.log	Epoch: [1] Total time: 0:38:15
2023-02-26 18:01:11,094	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 0:55:42  model_time: 0.1200 (0.1200)  evaluator_time: 0.0272 (0.0272)  time: 0.6686  data: 0.5181  max mem: 17061
2023-02-26 18:02:54,268	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:06:54  model_time: 0.0851 (0.0871)  evaluator_time: 0.0082 (0.0153)  time: 0.1005  data: 0.0001  max mem: 17061
2023-02-26 18:04:38,053	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:11  model_time: 0.0863 (0.0869)  evaluator_time: 0.0101 (0.0158)  time: 0.1028  data: 0.0001  max mem: 17061
2023-02-26 18:06:20,850	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:26  model_time: 0.0856 (0.0869)  evaluator_time: 0.0094 (0.0156)  time: 0.1014  data: 0.0001  max mem: 17061
2023-02-26 18:08:03,562	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:43  model_time: 0.0863 (0.0867)  evaluator_time: 0.0107 (0.0156)  time: 0.1034  data: 0.0001  max mem: 17061
2023-02-26 18:09:48,429	INFO	torchdistill.misc.log	Validation: Total time: 0:08:38
2023-02-26 18:09:48,429	INFO	__main__	Averaged stats: model_time: 0.0839 (0.0872)  evaluator_time: 0.0105 (0.0155)
2023-02-26 18:09:48,667	INFO	__main__	Accumulating evaluation results...
2023-02-26 18:10:02,776	INFO	__main__	DONE (t=14.11s).
2023-02-26 18:10:02,776	INFO	__main__	IoU metric: bbox
2023-02-26 18:10:02,777	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.163
2023-02-26 18:10:02,778	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.329
2023-02-26 18:10:02,778	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.146
2023-02-26 18:10:02,779	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.047
2023-02-26 18:10:02,780	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.167
2023-02-26 18:10:02,780	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.280
2023-02-26 18:10:02,781	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.180
2023-02-26 18:10:02,781	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.282
2023-02-26 18:10:02,781	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.297
2023-02-26 18:10:02,781	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.090
2023-02-26 18:10:02,781	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.319
2023-02-26 18:10:02,781	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.486
2023-02-26 18:10:03,486	INFO	__main__	Best mAP (bbox): 0.1403 -> 0.1634
2023-02-26 18:10:03,486	INFO	__main__	Updating ckpt at ./resource/ckpt/coco2017/supervised_compression/entropic_student/coco2017-faster_rcnn_splittable_resnet50-fp-beta0.32_fpn.pt
2023-02-26 18:10:04,826	INFO	torchdistill.misc.log	Epoch: [2]  [    0/14658]  eta: 3:15:43  lr: 0.02  img/s: 55.24118027648222  loss: 0.4341 (0.4341)  time: 0.8012  data: 0.6472  max mem: 17061
2023-02-26 18:12:42,623	INFO	torchdistill.misc.log	Epoch: [2]  [ 1000/14658]  eta: 0:36:03  lr: 0.02  img/s: 59.05921158006086  loss: 0.7548 (0.9156)  time: 0.1597  data: 0.0130  max mem: 17061
2023-02-26 18:15:20,410	INFO	torchdistill.misc.log	Epoch: [2]  [ 2000/14658]  eta: 0:33:21  lr: 0.02  img/s: 53.92973184953744  loss: 0.8473 (0.9136)  time: 0.1570  data: 0.0126  max mem: 17061
2023-02-26 18:17:58,397	INFO	torchdistill.misc.log	Epoch: [2]  [ 3000/14658]  eta: 0:30:42  lr: 0.02  img/s: 58.35827421461529  loss: 0.8890 (0.9124)  time: 0.1595  data: 0.0138  max mem: 17061
2023-02-26 18:20:36,244	INFO	torchdistill.misc.log	Epoch: [2]  [ 4000/14658]  eta: 0:28:04  lr: 0.02  img/s: 53.407662310789945  loss: 0.8866 (0.9113)  time: 0.1591  data: 0.0127  max mem: 17061
2023-02-26 18:23:14,265	INFO	torchdistill.misc.log	Epoch: [2]  [ 5000/14658]  eta: 0:25:26  lr: 0.02  img/s: 60.261581536350626  loss: 0.8880 (0.9095)  time: 0.1574  data: 0.0130  max mem: 17061
2023-02-26 18:25:52,314	INFO	torchdistill.misc.log	Epoch: [2]  [ 6000/14658]  eta: 0:22:48  lr: 0.02  img/s: 55.65486928223824  loss: 0.9266 (0.9108)  time: 0.1599  data: 0.0130  max mem: 17061
2023-02-26 18:28:30,346	INFO	torchdistill.misc.log	Epoch: [2]  [ 7000/14658]  eta: 0:20:10  lr: 0.02  img/s: 57.064195968789754  loss: 0.9468 (0.9105)  time: 0.1569  data: 0.0126  max mem: 17061
2023-02-26 18:31:08,297	INFO	torchdistill.misc.log	Epoch: [2]  [ 8000/14658]  eta: 0:17:32  lr: 0.02  img/s: 53.25703003109292  loss: 0.8797 (0.9109)  time: 0.1595  data: 0.0131  max mem: 17061
2023-02-26 18:33:46,168	INFO	torchdistill.misc.log	Epoch: [2]  [ 9000/14658]  eta: 0:14:53  lr: 0.02  img/s: 53.33516445088726  loss: 0.8165 (0.9095)  time: 0.1576  data: 0.0126  max mem: 17061
2023-02-26 18:36:25,069	INFO	torchdistill.misc.log	Epoch: [2]  [10000/14658]  eta: 0:12:16  lr: 0.02  img/s: 58.421067110062594  loss: 0.8858 (0.9092)  time: 0.1550  data: 0.0123  max mem: 17061
2023-02-26 18:39:03,443	INFO	torchdistill.misc.log	Epoch: [2]  [11000/14658]  eta: 0:09:38  lr: 0.02  img/s: 60.52332139861654  loss: 0.8547 (0.9081)  time: 0.1583  data: 0.0130  max mem: 17061
2023-02-26 18:41:41,433	INFO	torchdistill.misc.log	Epoch: [2]  [12000/14658]  eta: 0:07:00  lr: 0.02  img/s: 62.16247179437777  loss: 0.9088 (0.9082)  time: 0.1591  data: 0.0130  max mem: 17061
2023-02-26 18:44:19,556	INFO	torchdistill.misc.log	Epoch: [2]  [13000/14658]  eta: 0:04:22  lr: 0.02  img/s: 59.638646425975196  loss: 0.8408 (0.9077)  time: 0.1591  data: 0.0135  max mem: 17061
2023-02-26 18:46:57,787	INFO	torchdistill.misc.log	Epoch: [2]  [14000/14658]  eta: 0:01:44  lr: 0.02  img/s: 59.92911616675775  loss: 0.8551 (0.9073)  time: 0.1577  data: 0.0130  max mem: 17061
2023-02-26 18:48:42,071	INFO	torchdistill.misc.log	Epoch: [2] Total time: 0:38:38
2023-02-26 18:48:46,105	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 0:57:38  model_time: 0.1112 (0.1112)  evaluator_time: 0.0262 (0.0262)  time: 0.6917  data: 0.5527  max mem: 17061
2023-02-26 18:50:32,146	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:07:06  model_time: 0.0855 (0.0878)  evaluator_time: 0.0088 (0.0174)  time: 0.1018  data: 0.0001  max mem: 17061
2023-02-26 18:52:17,106	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:17  model_time: 0.0845 (0.0871)  evaluator_time: 0.0104 (0.0176)  time: 0.1009  data: 0.0001  max mem: 17061
2023-02-26 18:54:01,449	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:30  model_time: 0.0877 (0.0870)  evaluator_time: 0.0103 (0.0173)  time: 0.1030  data: 0.0001  max mem: 17061
2023-02-26 18:55:45,138	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:44  model_time: 0.0857 (0.0868)  evaluator_time: 0.0100 (0.0171)  time: 0.1036  data: 0.0001  max mem: 17061
2023-02-26 18:57:29,137	INFO	torchdistill.misc.log	Validation: Total time: 0:08:43
2023-02-26 18:57:29,138	INFO	__main__	Averaged stats: model_time: 0.0831 (0.0868)  evaluator_time: 0.0103 (0.0170)
2023-02-26 18:57:29,334	INFO	__main__	Accumulating evaluation results...
2023-02-26 18:57:45,303	INFO	__main__	DONE (t=15.97s).
2023-02-26 18:57:45,303	INFO	__main__	IoU metric: bbox
2023-02-26 18:57:45,304	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.170
2023-02-26 18:57:45,304	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.341
2023-02-26 18:57:45,305	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.150
2023-02-26 18:57:45,305	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.048
2023-02-26 18:57:45,306	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.178
2023-02-26 18:57:45,307	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.292
2023-02-26 18:57:45,307	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.187
2023-02-26 18:57:45,307	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.290
2023-02-26 18:57:45,307	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.305
2023-02-26 18:57:45,307	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.095
2023-02-26 18:57:45,307	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.328
2023-02-26 18:57:45,307	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.506
2023-02-26 18:57:46,030	INFO	__main__	Best mAP (bbox): 0.1634 -> 0.1698
2023-02-26 18:57:46,032	INFO	__main__	Updating ckpt at ./resource/ckpt/coco2017/supervised_compression/entropic_student/coco2017-faster_rcnn_splittable_resnet50-fp-beta0.32_fpn.pt
2023-02-26 18:57:47,420	INFO	torchdistill.misc.log	Epoch: [3]  [    0/14658]  eta: 3:20:58  lr: 0.02  img/s: 54.95573331236938  loss: 1.0643 (1.0643)  time: 0.8227  data: 0.6662  max mem: 17061
2023-02-26 19:00:24,494	INFO	torchdistill.misc.log	Epoch: [3]  [ 1000/14658]  eta: 0:35:54  lr: 0.02  img/s: 59.115918844828435  loss: 0.7824 (0.8927)  time: 0.1589  data: 0.0128  max mem: 17061
2023-02-26 19:03:02,893	INFO	torchdistill.misc.log	Epoch: [3]  [ 2000/14658]  eta: 0:33:20  lr: 0.02  img/s: 57.76572078826452  loss: 0.8667 (0.8952)  time: 0.1582  data: 0.0141  max mem: 17061
2023-02-26 19:05:40,920	INFO	torchdistill.misc.log	Epoch: [3]  [ 3000/14658]  eta: 0:30:42  lr: 0.02  img/s: 60.01422265465706  loss: 0.8684 (0.8894)  time: 0.1573  data: 0.0133  max mem: 17061
2023-02-26 19:08:19,343	INFO	torchdistill.misc.log	Epoch: [3]  [ 4000/14658]  eta: 0:28:05  lr: 0.02  img/s: 58.92997304156166  loss: 0.9323 (0.8890)  time: 0.1586  data: 0.0135  max mem: 17061
2023-02-26 19:10:57,600	INFO	torchdistill.misc.log	Epoch: [3]  [ 5000/14658]  eta: 0:25:27  lr: 0.02  img/s: 56.926722675389186  loss: 0.8807 (0.8898)  time: 0.1573  data: 0.0128  max mem: 17061
2023-02-26 19:13:35,697	INFO	torchdistill.misc.log	Epoch: [3]  [ 6000/14658]  eta: 0:22:49  lr: 0.02  img/s: 60.707281197702294  loss: 0.9382 (0.8895)  time: 0.1566  data: 0.0131  max mem: 17061
2023-02-26 19:16:14,080	INFO	torchdistill.misc.log	Epoch: [3]  [ 7000/14658]  eta: 0:20:11  lr: 0.02  img/s: 59.984075482356644  loss: 0.8076 (0.8887)  time: 0.1579  data: 0.0130  max mem: 17061
2023-02-26 19:18:52,640	INFO	torchdistill.misc.log	Epoch: [3]  [ 8000/14658]  eta: 0:17:33  lr: 0.02  img/s: 60.22610434342474  loss: 0.9982 (0.8896)  time: 0.1576  data: 0.0130  max mem: 17061
2023-02-26 19:21:31,055	INFO	torchdistill.misc.log	Epoch: [3]  [ 9000/14658]  eta: 0:14:55  lr: 0.02  img/s: 58.95482250002196  loss: 0.9800 (0.8901)  time: 0.1568  data: 0.0132  max mem: 17061
2023-02-26 19:24:09,822	INFO	torchdistill.misc.log	Epoch: [3]  [10000/14658]  eta: 0:12:17  lr: 0.02  img/s: 59.73047756709223  loss: 0.8598 (0.8907)  time: 0.1587  data: 0.0130  max mem: 17061
2023-02-26 19:26:48,426	INFO	torchdistill.misc.log	Epoch: [3]  [11000/14658]  eta: 0:09:39  lr: 0.02  img/s: 53.03220708119573  loss: 0.9052 (0.8910)  time: 0.1587  data: 0.0134  max mem: 17061
2023-02-26 19:29:26,858	INFO	torchdistill.misc.log	Epoch: [3]  [12000/14658]  eta: 0:07:00  lr: 0.02  img/s: 60.18786177454506  loss: 0.9154 (0.8910)  time: 0.1592  data: 0.0132  max mem: 17061
2023-02-26 19:32:05,019	INFO	torchdistill.misc.log	Epoch: [3]  [13000/14658]  eta: 0:04:22  lr: 0.02  img/s: 53.34177786680147  loss: 0.8391 (0.8916)  time: 0.1576  data: 0.0127  max mem: 17061
2023-02-26 19:34:43,477	INFO	torchdistill.misc.log	Epoch: [3]  [14000/14658]  eta: 0:01:44  lr: 0.02  img/s: 52.9979482789393  loss: 0.8038 (0.8914)  time: 0.1602  data: 0.0138  max mem: 17061
2023-02-26 19:36:28,091	INFO	torchdistill.misc.log	Epoch: [3] Total time: 0:38:41
2023-02-26 19:36:34,564	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 0:57:19  model_time: 0.1028 (0.1028)  evaluator_time: 0.0262 (0.0262)  time: 0.6879  data: 0.5575  max mem: 17061
2023-02-26 19:38:19,023	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:07:00  model_time: 0.0872 (0.0878)  evaluator_time: 0.0084 (0.0159)  time: 0.1015  data: 0.0001  max mem: 17061
2023-02-26 19:40:02,803	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:13  model_time: 0.0849 (0.0872)  evaluator_time: 0.0096 (0.0162)  time: 0.1012  data: 0.0001  max mem: 17061
2023-02-26 19:41:45,492	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:27  model_time: 0.0855 (0.0870)  evaluator_time: 0.0096 (0.0158)  time: 0.1014  data: 0.0001  max mem: 17061
2023-02-26 19:43:27,539	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:43  model_time: 0.0888 (0.0868)  evaluator_time: 0.0094 (0.0157)  time: 0.1030  data: 0.0002  max mem: 17061
2023-02-26 19:45:08,946	INFO	torchdistill.misc.log	Validation: Total time: 0:08:35
2023-02-26 19:45:08,947	INFO	__main__	Averaged stats: model_time: 0.0832 (0.0866)  evaluator_time: 0.0085 (0.0154)
2023-02-26 19:45:09,179	INFO	__main__	Accumulating evaluation results...
2023-02-26 19:45:23,399	INFO	__main__	DONE (t=14.22s).
2023-02-26 19:45:23,400	INFO	__main__	IoU metric: bbox
2023-02-26 19:45:23,401	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.185
2023-02-26 19:45:23,401	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.356
2023-02-26 19:45:23,401	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.176
2023-02-26 19:45:23,402	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.056
2023-02-26 19:45:23,403	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.191
2023-02-26 19:45:23,403	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.313
2023-02-26 19:45:23,403	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.198
2023-02-26 19:45:23,404	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.304
2023-02-26 19:45:23,404	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.318
2023-02-26 19:45:23,404	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.101
2023-02-26 19:45:23,404	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.346
2023-02-26 19:45:23,404	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.520
2023-02-26 19:45:24,251	INFO	__main__	Best mAP (bbox): 0.1698 -> 0.1848
2023-02-26 19:45:24,253	INFO	__main__	Updating ckpt at ./resource/ckpt/coco2017/supervised_compression/entropic_student/coco2017-faster_rcnn_splittable_resnet50-fp-beta0.32_fpn.pt
2023-02-26 19:45:25,763	INFO	torchdistill.misc.log	Epoch: [4]  [    0/14658]  eta: 3:49:12  lr: 0.02  img/s: 51.78448769451342  loss: 1.1129 (1.1129)  time: 0.9382  data: 0.7655  max mem: 17061
2023-02-26 19:48:04,077	INFO	torchdistill.misc.log	Epoch: [4]  [ 1000/14658]  eta: 0:36:12  lr: 0.02  img/s: 59.686490755596985  loss: 0.8672 (0.8790)  time: 0.1619  data: 0.0142  max mem: 17061
2023-02-26 19:50:45,169	INFO	torchdistill.misc.log	Epoch: [4]  [ 2000/14658]  eta: 0:33:46  lr: 0.02  img/s: 58.59306510392565  loss: 0.9801 (0.8784)  time: 0.1598  data: 0.0133  max mem: 17061
2023-02-26 19:53:23,387	INFO	torchdistill.misc.log	Epoch: [4]  [ 3000/14658]  eta: 0:30:59  lr: 0.02  img/s: 59.189435860708876  loss: 0.7851 (0.8793)  time: 0.1603  data: 0.0135  max mem: 17061
2023-02-26 19:56:02,062	INFO	torchdistill.misc.log	Epoch: [4]  [ 4000/14658]  eta: 0:28:17  lr: 0.02  img/s: 52.50780784211243  loss: 0.8677 (0.8804)  time: 0.1598  data: 0.0131  max mem: 17061
2023-02-26 19:58:40,568	INFO	torchdistill.misc.log	Epoch: [4]  [ 5000/14658]  eta: 0:25:36  lr: 0.02  img/s: 60.28680872471163  loss: 1.0015 (0.8842)  time: 0.1588  data: 0.0134  max mem: 17061
2023-02-26 20:01:18,877	INFO	torchdistill.misc.log	Epoch: [4]  [ 6000/14658]  eta: 0:22:56  lr: 0.02  img/s: 58.78471343828508  loss: 0.8590 (0.8837)  time: 0.1611  data: 0.0149  max mem: 17061
2023-02-26 20:03:57,289	INFO	torchdistill.misc.log	Epoch: [4]  [ 7000/14658]  eta: 0:20:16  lr: 0.02  img/s: 59.83165898140916  loss: 0.8343 (0.8825)  time: 0.1585  data: 0.0130  max mem: 17061
2023-02-26 20:06:36,025	INFO	torchdistill.misc.log	Epoch: [4]  [ 8000/14658]  eta: 0:17:37  lr: 0.02  img/s: 60.3507832874692  loss: 0.9022 (0.8830)  time: 0.1563  data: 0.0132  max mem: 17061
2023-02-26 20:09:14,384	INFO	torchdistill.misc.log	Epoch: [4]  [ 9000/14658]  eta: 0:14:58  lr: 0.02  img/s: 60.57139349958933  loss: 0.7463 (0.8817)  time: 0.1560  data: 0.0131  max mem: 17061
2023-02-26 20:11:52,681	INFO	torchdistill.misc.log	Epoch: [4]  [10000/14658]  eta: 0:12:19  lr: 0.02  img/s: 61.61886922732248  loss: 0.9966 (0.8827)  time: 0.1593  data: 0.0137  max mem: 17061
2023-02-26 20:14:30,994	INFO	torchdistill.misc.log	Epoch: [4]  [11000/14658]  eta: 0:09:40  lr: 0.02  img/s: 60.13328291526359  loss: 0.9674 (0.8833)  time: 0.1573  data: 0.0129  max mem: 17061
2023-02-26 20:17:09,603	INFO	torchdistill.misc.log	Epoch: [4]  [12000/14658]  eta: 0:07:01  lr: 0.02  img/s: 58.83759286958016  loss: 0.8416 (0.8832)  time: 0.1608  data: 0.0139  max mem: 17061
2023-02-26 20:19:48,102	INFO	torchdistill.misc.log	Epoch: [4]  [13000/14658]  eta: 0:04:23  lr: 0.02  img/s: 57.83103160035504  loss: 0.8239 (0.8824)  time: 0.1568  data: 0.0124  max mem: 17061
2023-02-26 20:22:26,347	INFO	torchdistill.misc.log	Epoch: [4]  [14000/14658]  eta: 0:01:44  lr: 0.02  img/s: 60.47663350954251  loss: 0.9681 (0.8823)  time: 0.1611  data: 0.0141  max mem: 17061
2023-02-26 20:24:10,726	INFO	torchdistill.misc.log	Epoch: [4] Total time: 0:38:45
2023-02-26 20:24:17,213	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 0:59:35  model_time: 0.1041 (0.1041)  evaluator_time: 0.0294 (0.0294)  time: 0.7151  data: 0.5797  max mem: 17061
2023-02-26 20:26:00,464	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:06:55  model_time: 0.0863 (0.0879)  evaluator_time: 0.0072 (0.0146)  time: 0.0995  data: 0.0001  max mem: 17061
2023-02-26 20:27:44,332	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:11  model_time: 0.0871 (0.0878)  evaluator_time: 0.0092 (0.0149)  time: 0.1005  data: 0.0001  max mem: 17061
2023-02-26 20:29:26,876	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:26  model_time: 0.0875 (0.0877)  evaluator_time: 0.0088 (0.0148)  time: 0.1028  data: 0.0001  max mem: 17061
2023-02-26 20:31:08,686	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:43  model_time: 0.0864 (0.0875)  evaluator_time: 0.0080 (0.0146)  time: 0.1022  data: 0.0001  max mem: 17061
2023-02-26 20:32:50,251	INFO	torchdistill.misc.log	Validation: Total time: 0:08:33
2023-02-26 20:32:50,252	INFO	__main__	Averaged stats: model_time: 0.0844 (0.0873)  evaluator_time: 0.0086 (0.0145)
2023-02-26 20:32:50,424	INFO	__main__	Accumulating evaluation results...
2023-02-26 20:33:03,376	INFO	__main__	DONE (t=12.95s).
2023-02-26 20:33:03,376	INFO	__main__	IoU metric: bbox
2023-02-26 20:33:03,377	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.187
2023-02-26 20:33:03,377	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.357
2023-02-26 20:33:03,378	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.178
2023-02-26 20:33:03,379	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.059
2023-02-26 20:33:03,379	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.194
2023-02-26 20:33:03,380	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.318
2023-02-26 20:33:03,380	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.197
2023-02-26 20:33:03,380	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.301
2023-02-26 20:33:03,380	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.316
2023-02-26 20:33:03,380	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.101
2023-02-26 20:33:03,380	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.345
2023-02-26 20:33:03,381	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.511
2023-02-26 20:33:04,101	INFO	__main__	Best mAP (bbox): 0.1848 -> 0.1875
2023-02-26 20:33:04,102	INFO	__main__	Updating ckpt at ./resource/ckpt/coco2017/supervised_compression/entropic_student/coco2017-faster_rcnn_splittable_resnet50-fp-beta0.32_fpn.pt
2023-02-26 20:33:05,488	INFO	torchdistill.misc.log	Epoch: [5]  [    0/14658]  eta: 3:20:54  lr: 0.02  img/s: 54.378877528364846  loss: 0.7215 (0.7215)  time: 0.8224  data: 0.6656  max mem: 17061
2023-02-26 20:35:44,052	INFO	torchdistill.misc.log	Epoch: [5]  [ 1000/14658]  eta: 0:36:14  lr: 0.02  img/s: 59.266694927229054  loss: 0.9506 (0.8731)  time: 0.1579  data: 0.0137  max mem: 17061
2023-02-26 20:38:21,621	INFO	torchdistill.misc.log	Epoch: [5]  [ 2000/14658]  eta: 0:33:24  lr: 0.02  img/s: 59.98278873294828  loss: 0.7415 (0.8715)  time: 0.1560  data: 0.0126  max mem: 17061
2023-02-26 20:40:59,906	INFO	torchdistill.misc.log	Epoch: [5]  [ 3000/14658]  eta: 0:30:46  lr: 0.02  img/s: 58.80377205726433  loss: 0.7772 (0.8723)  time: 0.1594  data: 0.0133  max mem: 17061
2023-02-26 20:43:38,426	INFO	torchdistill.misc.log	Epoch: [5]  [ 4000/14658]  eta: 0:28:08  lr: 0.02  img/s: 59.94678214947377  loss: 0.8403 (0.8728)  time: 0.1587  data: 0.0128  max mem: 17061
2023-02-26 20:46:17,111	INFO	torchdistill.misc.log	Epoch: [5]  [ 5000/14658]  eta: 0:25:30  lr: 0.02  img/s: 60.65592297805648  loss: 0.8471 (0.8738)  time: 0.1584  data: 0.0130  max mem: 17061
2023-02-26 20:48:55,708	INFO	torchdistill.misc.log	Epoch: [5]  [ 6000/14658]  eta: 0:22:52  lr: 0.02  img/s: 60.338520022369956  loss: 0.7964 (0.8750)  time: 0.1564  data: 0.0127  max mem: 17061
2023-02-26 20:51:34,614	INFO	torchdistill.misc.log	Epoch: [5]  [ 7000/14658]  eta: 0:20:14  lr: 0.02  img/s: 60.41522010381763  loss: 0.8091 (0.8756)  time: 0.1570  data: 0.0131  max mem: 17061
2023-02-26 20:54:13,127	INFO	torchdistill.misc.log	Epoch: [5]  [ 8000/14658]  eta: 0:17:35  lr: 0.02  img/s: 58.67923921179096  loss: 0.8105 (0.8742)  time: 0.1587  data: 0.0130  max mem: 17061
2023-02-26 20:56:51,773	INFO	torchdistill.misc.log	Epoch: [5]  [ 9000/14658]  eta: 0:14:57  lr: 0.02  img/s: 59.381438628408006  loss: 0.8598 (0.8747)  time: 0.1596  data: 0.0132  max mem: 17061
2023-02-26 20:59:30,301	INFO	torchdistill.misc.log	Epoch: [5]  [10000/14658]  eta: 0:12:18  lr: 0.02  img/s: 58.06048567107672  loss: 0.8749 (0.8743)  time: 0.1590  data: 0.0134  max mem: 17061
2023-02-26 21:02:08,778	INFO	torchdistill.misc.log	Epoch: [5]  [11000/14658]  eta: 0:09:39  lr: 0.02  img/s: 63.620066778026576  loss: 0.9419 (0.8734)  time: 0.1543  data: 0.0132  max mem: 17061
2023-02-26 21:04:47,161	INFO	torchdistill.misc.log	Epoch: [5]  [12000/14658]  eta: 0:07:01  lr: 0.02  img/s: 60.074070228143896  loss: 0.8994 (0.8737)  time: 0.1568  data: 0.0130  max mem: 17061
2023-02-26 21:07:25,735	INFO	torchdistill.misc.log	Epoch: [5]  [13000/14658]  eta: 0:04:22  lr: 0.02  img/s: 60.39064617555429  loss: 0.9740 (0.8747)  time: 0.1585  data: 0.0134  max mem: 17061
2023-02-26 21:10:04,321	INFO	torchdistill.misc.log	Epoch: [5]  [14000/14658]  eta: 0:01:44  lr: 0.02  img/s: 59.19695427352614  loss: 1.0702 (0.8753)  time: 0.1580  data: 0.0132  max mem: 17061
2023-02-26 21:11:48,671	INFO	torchdistill.misc.log	Epoch: [5] Total time: 0:38:44
2023-02-26 21:11:52,686	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 1:01:28  model_time: 0.1040 (0.1040)  evaluator_time: 0.0282 (0.0282)  time: 0.7376  data: 0.6019  max mem: 17061
2023-02-26 21:13:39,711	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:07:10  model_time: 0.0850 (0.0879)  evaluator_time: 0.0093 (0.0184)  time: 0.1011  data: 0.0001  max mem: 17061
2023-02-26 21:15:24,280	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:18  model_time: 0.0865 (0.0877)  evaluator_time: 0.0112 (0.0173)  time: 0.1053  data: 0.0001  max mem: 17061
2023-02-26 21:17:07,764	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:30  model_time: 0.0892 (0.0876)  evaluator_time: 0.0110 (0.0166)  time: 0.1031  data: 0.0001  max mem: 17061
2023-02-26 21:18:50,449	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:44  model_time: 0.0875 (0.0874)  evaluator_time: 0.0106 (0.0163)  time: 0.1029  data: 0.0001  max mem: 17061
2023-02-26 21:20:32,733	INFO	torchdistill.misc.log	Validation: Total time: 0:08:40
2023-02-26 21:20:32,734	INFO	__main__	Averaged stats: model_time: 0.0843 (0.0872)  evaluator_time: 0.0098 (0.0160)
2023-02-26 21:20:32,970	INFO	__main__	Accumulating evaluation results...
2023-02-26 21:20:47,952	INFO	__main__	DONE (t=14.98s).
2023-02-26 21:20:47,952	INFO	__main__	IoU metric: bbox
2023-02-26 21:20:47,953	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.189
2023-02-26 21:20:47,953	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.363
2023-02-26 21:20:47,954	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.180
2023-02-26 21:20:47,955	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.055
2023-02-26 21:20:47,955	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.193
2023-02-26 21:20:47,956	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.319
2023-02-26 21:20:47,956	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.200
2023-02-26 21:20:47,956	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.313
2023-02-26 21:20:47,956	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.329
2023-02-26 21:20:47,956	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.108
2023-02-26 21:20:47,956	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.360
2023-02-26 21:20:47,957	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.520
2023-02-26 21:20:48,570	INFO	__main__	Best mAP (bbox): 0.1875 -> 0.1892
2023-02-26 21:20:48,572	INFO	__main__	Updating ckpt at ./resource/ckpt/coco2017/supervised_compression/entropic_student/coco2017-faster_rcnn_splittable_resnet50-fp-beta0.32_fpn.pt
2023-02-26 21:20:49,923	INFO	torchdistill.misc.log	Epoch: [6]  [    0/14658]  eta: 3:15:57  lr: 0.02  img/s: 55.274212837737664  loss: 0.6239 (0.6239)  time: 0.8021  data: 0.6469  max mem: 17061
2023-02-26 21:23:27,031	INFO	torchdistill.misc.log	Epoch: [6]  [ 1000/14658]  eta: 0:35:54  lr: 0.02  img/s: 58.99545504893954  loss: 0.7951 (0.8736)  time: 0.1552  data: 0.0122  max mem: 17061
2023-02-26 21:26:04,198	INFO	torchdistill.misc.log	Epoch: [6]  [ 2000/14658]  eta: 0:33:13  lr: 0.02  img/s: 59.78230356846976  loss: 0.8383 (0.8705)  time: 0.1582  data: 0.0124  max mem: 17061
2023-02-26 21:28:42,560	INFO	torchdistill.misc.log	Epoch: [6]  [ 3000/14658]  eta: 0:30:39  lr: 0.02  img/s: 58.56780400617193  loss: 0.7312 (0.8704)  time: 0.1567  data: 0.0127  max mem: 17061
2023-02-26 21:31:20,753	INFO	torchdistill.misc.log	Epoch: [6]  [ 4000/14658]  eta: 0:28:02  lr: 0.02  img/s: 59.6869154389922  loss: 0.8229 (0.8679)  time: 0.1574  data: 0.0126  max mem: 17061
2023-02-26 21:33:59,141	INFO	torchdistill.misc.log	Epoch: [6]  [ 5000/14658]  eta: 0:25:25  lr: 0.02  img/s: 58.115793630449694  loss: 0.7985 (0.8672)  time: 0.1591  data: 0.0136  max mem: 17061
2023-02-26 21:36:37,887	INFO	torchdistill.misc.log	Epoch: [6]  [ 6000/14658]  eta: 0:22:48  lr: 0.02  img/s: 57.56365819766345  loss: 0.8544 (0.8677)  time: 0.1587  data: 0.0134  max mem: 17061
2023-02-26 21:39:16,616	INFO	torchdistill.misc.log	Epoch: [6]  [ 7000/14658]  eta: 0:20:11  lr: 0.02  img/s: 58.92945556726379  loss: 0.9056 (0.8688)  time: 0.1598  data: 0.0137  max mem: 17061
2023-02-26 21:41:55,443	INFO	torchdistill.misc.log	Epoch: [6]  [ 8000/14658]  eta: 0:17:33  lr: 0.02  img/s: 58.79377761891245  loss: 0.7613 (0.8696)  time: 0.1577  data: 0.0127  max mem: 17061
2023-02-26 21:44:33,880	INFO	torchdistill.misc.log	Epoch: [6]  [ 9000/14658]  eta: 0:14:55  lr: 0.02  img/s: 52.87068325741234  loss: 0.8895 (0.8701)  time: 0.1591  data: 0.0126  max mem: 17061
2023-02-26 21:47:12,387	INFO	torchdistill.misc.log	Epoch: [6]  [10000/14658]  eta: 0:12:17  lr: 0.02  img/s: 59.66706795101367  loss: 0.8283 (0.8700)  time: 0.1593  data: 0.0124  max mem: 17061
2023-02-26 21:49:50,697	INFO	torchdistill.misc.log	Epoch: [6]  [11000/14658]  eta: 0:09:39  lr: 0.02  img/s: 58.45139419953071  loss: 0.8940 (0.8690)  time: 0.1579  data: 0.0132  max mem: 17061
2023-02-26 21:52:28,892	INFO	torchdistill.misc.log	Epoch: [6]  [12000/14658]  eta: 0:07:00  lr: 0.02  img/s: 59.80723759141456  loss: 0.8490 (0.8689)  time: 0.1582  data: 0.0124  max mem: 17061
2023-02-26 21:55:07,539	INFO	torchdistill.misc.log	Epoch: [6]  [13000/14658]  eta: 0:04:22  lr: 0.02  img/s: 56.750146296252446  loss: 0.7949 (0.8689)  time: 0.1581  data: 0.0128  max mem: 17061
2023-02-26 21:57:45,961	INFO	torchdistill.misc.log	Epoch: [6]  [14000/14658]  eta: 0:01:44  lr: 0.02  img/s: 58.516734796378195  loss: 0.9143 (0.8684)  time: 0.1605  data: 0.0137  max mem: 17061
2023-02-26 21:59:30,498	INFO	torchdistill.misc.log	Epoch: [6] Total time: 0:38:41
2023-02-26 21:59:35,014	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 1:00:14  model_time: 0.1134 (0.1134)  evaluator_time: 0.0446 (0.0446)  time: 0.7230  data: 0.5634  max mem: 17061
2023-02-26 22:01:21,377	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:07:07  model_time: 0.0867 (0.0868)  evaluator_time: 0.0080 (0.0188)  time: 0.1012  data: 0.0001  max mem: 17061
2023-02-26 22:03:05,590	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:16  model_time: 0.0866 (0.0868)  evaluator_time: 0.0111 (0.0177)  time: 0.1029  data: 0.0001  max mem: 17061
2023-02-26 22:04:49,286	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:29  model_time: 0.0876 (0.0868)  evaluator_time: 0.0105 (0.0171)  time: 0.1044  data: 0.0001  max mem: 17061
2023-02-26 22:06:32,578	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:44  model_time: 0.0859 (0.0868)  evaluator_time: 0.0094 (0.0168)  time: 0.1034  data: 0.0001  max mem: 17061
2023-02-26 22:08:14,916	INFO	torchdistill.misc.log	Validation: Total time: 0:08:40
2023-02-26 22:08:14,917	INFO	__main__	Averaged stats: model_time: 0.0845 (0.0867)  evaluator_time: 0.0093 (0.0165)
2023-02-26 22:08:15,085	INFO	__main__	Accumulating evaluation results...
2023-02-26 22:08:30,793	INFO	__main__	DONE (t=15.71s).
2023-02-26 22:08:30,793	INFO	__main__	IoU metric: bbox
2023-02-26 22:08:30,794	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.194
2023-02-26 22:08:30,794	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.371
2023-02-26 22:08:30,795	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.181
2023-02-26 22:08:30,795	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.061
2023-02-26 22:08:30,796	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.200
2023-02-26 22:08:30,797	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.319
2023-02-26 22:08:30,797	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.205
2023-02-26 22:08:30,797	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.317
2023-02-26 22:08:30,797	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.334
2023-02-26 22:08:30,797	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.113
2023-02-26 22:08:30,797	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.363
2023-02-26 22:08:30,797	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.528
2023-02-26 22:08:31,598	INFO	__main__	Best mAP (bbox): 0.1892 -> 0.1937
2023-02-26 22:08:31,600	INFO	__main__	Updating ckpt at ./resource/ckpt/coco2017/supervised_compression/entropic_student/coco2017-faster_rcnn_splittable_resnet50-fp-beta0.32_fpn.pt
2023-02-26 22:08:33,036	INFO	torchdistill.misc.log	Epoch: [7]  [    0/14658]  eta: 3:25:38  lr: 0.02  img/s: 51.71178379777892  loss: 0.9150 (0.9150)  time: 0.8418  data: 0.6767  max mem: 17061
2023-02-26 22:11:10,367	INFO	torchdistill.misc.log	Epoch: [7]  [ 1000/14658]  eta: 0:35:58  lr: 0.02  img/s: 57.54016476091832  loss: 0.7485 (0.8630)  time: 0.1570  data: 0.0120  max mem: 17061
2023-02-26 22:13:49,103	INFO	torchdistill.misc.log	Epoch: [7]  [ 2000/14658]  eta: 0:33:24  lr: 0.02  img/s: 59.88419515921203  loss: 0.7787 (0.8562)  time: 0.1569  data: 0.0126  max mem: 17061
2023-02-26 22:16:28,066	INFO	torchdistill.misc.log	Epoch: [7]  [ 3000/14658]  eta: 0:30:48  lr: 0.02  img/s: 59.52301311639425  loss: 0.7455 (0.8575)  time: 0.1574  data: 0.0128  max mem: 17061
2023-02-26 22:19:06,878	INFO	torchdistill.misc.log	Epoch: [7]  [ 4000/14658]  eta: 0:28:10  lr: 0.02  img/s: 58.463309753632785  loss: 0.9024 (0.8592)  time: 0.1572  data: 0.0131  max mem: 17061
2023-02-26 22:21:45,695	INFO	torchdistill.misc.log	Epoch: [7]  [ 5000/14658]  eta: 0:25:32  lr: 0.02  img/s: 60.26915830104734  loss: 0.8064 (0.8625)  time: 0.1556  data: 0.0122  max mem: 17061
2023-02-26 22:24:24,247	INFO	torchdistill.misc.log	Epoch: [7]  [ 6000/14658]  eta: 0:22:53  lr: 0.02  img/s: 53.29374075821179  loss: 0.8526 (0.8628)  time: 0.1593  data: 0.0126  max mem: 17061
2023-02-26 22:27:03,121	INFO	torchdistill.misc.log	Epoch: [7]  [ 7000/14658]  eta: 0:20:15  lr: 0.02  img/s: 59.38080810940907  loss: 0.9642 (0.8623)  time: 0.1591  data: 0.0135  max mem: 17061
2023-02-26 22:29:41,728	INFO	torchdistill.misc.log	Epoch: [7]  [ 8000/14658]  eta: 0:17:36  lr: 0.02  img/s: 58.67246727540418  loss: 0.7882 (0.8632)  time: 0.1586  data: 0.0127  max mem: 17061
2023-02-26 22:32:20,551	INFO	torchdistill.misc.log	Epoch: [7]  [ 9000/14658]  eta: 0:14:57  lr: 0.02  img/s: 61.76621033816905  loss: 0.8925 (0.8621)  time: 0.1606  data: 0.0131  max mem: 17061
2023-02-26 22:34:59,255	INFO	torchdistill.misc.log	Epoch: [7]  [10000/14658]  eta: 0:12:19  lr: 0.02  img/s: 59.464679455939034  loss: 0.8087 (0.8635)  time: 0.1583  data: 0.0131  max mem: 17061
2023-02-26 22:37:38,103	INFO	torchdistill.misc.log	Epoch: [7]  [11000/14658]  eta: 0:09:40  lr: 0.02  img/s: 59.29507730314602  loss: 0.8978 (0.8636)  time: 0.1577  data: 0.0134  max mem: 17061
2023-02-26 22:40:16,850	INFO	torchdistill.misc.log	Epoch: [7]  [12000/14658]  eta: 0:07:01  lr: 0.02  img/s: 59.66993281572873  loss: 0.7697 (0.8640)  time: 0.1551  data: 0.0122  max mem: 17061
2023-02-26 22:42:55,414	INFO	torchdistill.misc.log	Epoch: [7]  [13000/14658]  eta: 0:04:23  lr: 0.02  img/s: 59.61808952370461  loss: 0.8359 (0.8645)  time: 0.1605  data: 0.0129  max mem: 17061
2023-02-26 22:45:34,160	INFO	torchdistill.misc.log	Epoch: [7]  [14000/14658]  eta: 0:01:44  lr: 0.02  img/s: 60.04730136005727  loss: 0.8843 (0.8649)  time: 0.1614  data: 0.0139  max mem: 17061
2023-02-26 22:47:18,588	INFO	torchdistill.misc.log	Epoch: [7] Total time: 0:38:46
2023-02-26 22:47:22,591	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 0:59:14  model_time: 0.1129 (0.1129)  evaluator_time: 0.0300 (0.0300)  time: 0.7110  data: 0.5638  max mem: 17061
2023-02-26 22:49:09,313	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:07:09  model_time: 0.0842 (0.0876)  evaluator_time: 0.0085 (0.0184)  time: 0.0994  data: 0.0001  max mem: 17061
2023-02-26 22:50:53,200	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:16  model_time: 0.0814 (0.0872)  evaluator_time: 0.0102 (0.0173)  time: 0.0984  data: 0.0001  max mem: 17061
2023-02-26 22:52:36,181	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:29  model_time: 0.0856 (0.0871)  evaluator_time: 0.0100 (0.0166)  time: 0.1010  data: 0.0001  max mem: 17061
2023-02-26 22:54:18,726	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:44  model_time: 0.0863 (0.0870)  evaluator_time: 0.0077 (0.0163)  time: 0.1039  data: 0.0001  max mem: 17061
2023-02-26 22:56:00,459	INFO	torchdistill.misc.log	Validation: Total time: 0:08:38
2023-02-26 22:56:00,460	INFO	__main__	Averaged stats: model_time: 0.0826 (0.0868)  evaluator_time: 0.0098 (0.0160)
2023-02-26 22:56:00,622	INFO	__main__	Accumulating evaluation results...
2023-02-26 22:56:15,844	INFO	__main__	DONE (t=15.22s).
2023-02-26 22:56:15,844	INFO	__main__	IoU metric: bbox
2023-02-26 22:56:15,845	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.195
2023-02-26 22:56:15,845	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.367
2023-02-26 22:56:15,846	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.185
2023-02-26 22:56:15,847	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.060
2023-02-26 22:56:15,847	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.202
2023-02-26 22:56:15,848	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.326
2023-02-26 22:56:15,848	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.204
2023-02-26 22:56:15,848	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.317
2023-02-26 22:56:15,848	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.332
2023-02-26 22:56:15,848	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.112
2023-02-26 22:56:15,848	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.361
2023-02-26 22:56:15,848	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.530
2023-02-26 22:56:16,657	INFO	__main__	Best mAP (bbox): 0.1937 -> 0.1946
2023-02-26 22:56:16,658	INFO	__main__	Updating ckpt at ./resource/ckpt/coco2017/supervised_compression/entropic_student/coco2017-faster_rcnn_splittable_resnet50-fp-beta0.32_fpn.pt
2023-02-26 22:56:18,236	INFO	torchdistill.misc.log	Epoch: [8]  [    0/14658]  eta: 3:19:39  lr: 0.02  img/s: 53.23590624737227  loss: 0.8962 (0.8962)  time: 0.8173  data: 0.6549  max mem: 17061
2023-02-26 22:58:55,874	INFO	torchdistill.misc.log	Epoch: [8]  [ 1000/14658]  eta: 0:36:01  lr: 0.02  img/s: 66.51066706045823  loss: 0.8980 (0.8591)  time: 0.1568  data: 0.0123  max mem: 17061
2023-02-26 23:01:34,962	INFO	torchdistill.misc.log	Epoch: [8]  [ 2000/14658]  eta: 0:33:28  lr: 0.02  img/s: 59.873936954202044  loss: 0.8276 (0.8639)  time: 0.1599  data: 0.0132  max mem: 17061
2023-02-26 23:04:13,384	INFO	torchdistill.misc.log	Epoch: [8]  [ 3000/14658]  eta: 0:30:48  lr: 0.02  img/s: 59.50411863075256  loss: 0.8298 (0.8635)  time: 0.1598  data: 0.0134  max mem: 17061
2023-02-26 23:06:52,037	INFO	torchdistill.misc.log	Epoch: [8]  [ 4000/14658]  eta: 0:28:10  lr: 0.02  img/s: 59.79700573298238  loss: 0.8308 (0.8644)  time: 0.1584  data: 0.0128  max mem: 17061
2023-02-26 23:09:31,029	INFO	torchdistill.misc.log	Epoch: [8]  [ 5000/14658]  eta: 0:25:32  lr: 0.02  img/s: 59.39636482075465  loss: 0.9027 (0.8642)  time: 0.1572  data: 0.0124  max mem: 17061
2023-02-26 23:12:09,478	INFO	torchdistill.misc.log	Epoch: [8]  [ 6000/14658]  eta: 0:22:53  lr: 0.02  img/s: 59.50063659931836  loss: 0.9027 (0.8638)  time: 0.1602  data: 0.0135  max mem: 17061
2023-02-26 23:14:48,556	INFO	torchdistill.misc.log	Epoch: [8]  [ 7000/14658]  eta: 0:20:15  lr: 0.02  img/s: 53.0660066580739  loss: 0.8644 (0.8639)  time: 0.1610  data: 0.0132  max mem: 17061
2023-02-26 23:17:27,422	INFO	torchdistill.misc.log	Epoch: [8]  [ 8000/14658]  eta: 0:17:36  lr: 0.02  img/s: 53.19101055912141  loss: 0.9060 (0.8637)  time: 0.1607  data: 0.0136  max mem: 17061
2023-02-26 23:20:06,504	INFO	torchdistill.misc.log	Epoch: [8]  [ 9000/14658]  eta: 0:14:58  lr: 0.02  img/s: 57.45572726260905  loss: 0.7962 (0.8634)  time: 0.1596  data: 0.0133  max mem: 17061
2023-02-26 23:22:45,399	INFO	torchdistill.misc.log	Epoch: [8]  [10000/14658]  eta: 0:12:19  lr: 0.02  img/s: 59.94356937797333  loss: 0.6655 (0.8637)  time: 0.1592  data: 0.0128  max mem: 17061
2023-02-26 23:25:24,224	INFO	torchdistill.misc.log	Epoch: [8]  [11000/14658]  eta: 0:09:40  lr: 0.02  img/s: 60.3272378808609  loss: 0.7918 (0.8635)  time: 0.1605  data: 0.0129  max mem: 17061
2023-02-26 23:28:03,162	INFO	torchdistill.misc.log	Epoch: [8]  [12000/14658]  eta: 0:07:02  lr: 0.02  img/s: 59.20833995038097  loss: 0.9351 (0.8638)  time: 0.1601  data: 0.0133  max mem: 17061
2023-02-26 23:30:41,995	INFO	torchdistill.misc.log	Epoch: [8]  [13000/14658]  eta: 0:04:23  lr: 0.02  img/s: 58.890050738792624  loss: 0.9590 (0.8637)  time: 0.1577  data: 0.0131  max mem: 17061
2023-02-26 23:33:20,250	INFO	torchdistill.misc.log	Epoch: [8]  [14000/14658]  eta: 0:01:44  lr: 0.02  img/s: 58.58539242663389  loss: 0.8221 (0.8633)  time: 0.1577  data: 0.0133  max mem: 17061
2023-02-26 23:35:04,737	INFO	torchdistill.misc.log	Epoch: [8] Total time: 0:38:47
2023-02-26 23:35:08,750	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 0:59:19  model_time: 0.1003 (0.1003)  evaluator_time: 0.0278 (0.0278)  time: 0.7119  data: 0.5815  max mem: 17061
2023-02-26 23:36:54,776	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:07:06  model_time: 0.0849 (0.0877)  evaluator_time: 0.0083 (0.0175)  time: 0.1014  data: 0.0001  max mem: 17061
2023-02-26 23:38:37,920	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:14  model_time: 0.0858 (0.0873)  evaluator_time: 0.0099 (0.0165)  time: 0.1017  data: 0.0001  max mem: 17061
2023-02-26 23:40:20,373	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:28  model_time: 0.0881 (0.0873)  evaluator_time: 0.0099 (0.0158)  time: 0.1019  data: 0.0001  max mem: 17061
2023-02-26 23:42:02,715	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:43  model_time: 0.0855 (0.0872)  evaluator_time: 0.0092 (0.0155)  time: 0.1030  data: 0.0001  max mem: 17061
2023-02-26 23:43:44,637	INFO	torchdistill.misc.log	Validation: Total time: 0:08:36
2023-02-26 23:43:44,638	INFO	__main__	Averaged stats: model_time: 0.0835 (0.0872)  evaluator_time: 0.0083 (0.0152)
2023-02-26 23:43:44,798	INFO	__main__	Accumulating evaluation results...
2023-02-26 23:43:59,473	INFO	__main__	DONE (t=14.67s).
2023-02-26 23:43:59,473	INFO	__main__	IoU metric: bbox
2023-02-26 23:43:59,474	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.196
2023-02-26 23:43:59,474	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.367
2023-02-26 23:43:59,474	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.190
2023-02-26 23:43:59,475	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.062
2023-02-26 23:43:59,476	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.207
2023-02-26 23:43:59,477	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.332
2023-02-26 23:43:59,477	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.208
2023-02-26 23:43:59,477	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.321
2023-02-26 23:43:59,477	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.337
2023-02-26 23:43:59,477	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.118
2023-02-26 23:43:59,477	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.364
2023-02-26 23:43:59,477	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.544
2023-02-26 23:44:00,249	INFO	__main__	Best mAP (bbox): 0.1946 -> 0.1962
2023-02-26 23:44:00,251	INFO	__main__	Updating ckpt at ./resource/ckpt/coco2017/supervised_compression/entropic_student/coco2017-faster_rcnn_splittable_resnet50-fp-beta0.32_fpn.pt
2023-02-26 23:44:01,613	INFO	torchdistill.misc.log	Epoch: [9]  [    0/14658]  eta: 3:25:01  lr: 0.02  img/s: 52.73971711354595  loss: 1.0516 (1.0516)  time: 0.8392  data: 0.6768  max mem: 17061
2023-02-26 23:46:39,385	INFO	torchdistill.misc.log	Epoch: [9]  [ 1000/14658]  eta: 0:36:04  lr: 0.02  img/s: 52.74029738140894  loss: 0.9139 (0.8613)  time: 0.1595  data: 0.0135  max mem: 17061
2023-02-26 23:49:18,091	INFO	torchdistill.misc.log	Epoch: [9]  [ 2000/14658]  eta: 0:33:27  lr: 0.02  img/s: 59.73069022112567  loss: 0.8385 (0.8588)  time: 0.1607  data: 0.0137  max mem: 17061
2023-02-26 23:51:56,518	INFO	torchdistill.misc.log	Epoch: [9]  [ 3000/14658]  eta: 0:30:48  lr: 0.02  img/s: 59.95406570669449  loss: 0.9475 (0.8604)  time: 0.1602  data: 0.0137  max mem: 17061
2023-02-26 23:54:35,094	INFO	torchdistill.misc.log	Epoch: [9]  [ 4000/14658]  eta: 0:28:09  lr: 0.02  img/s: 52.935742446018196  loss: 0.7412 (0.8606)  time: 0.1591  data: 0.0128  max mem: 17061
2023-02-26 23:57:13,662	INFO	torchdistill.misc.log	Epoch: [9]  [ 5000/14658]  eta: 0:25:31  lr: 0.02  img/s: 60.05761906125605  loss: 0.8480 (0.8608)  time: 0.1591  data: 0.0129  max mem: 17061
2023-02-26 23:59:52,167	INFO	torchdistill.misc.log	Epoch: [9]  [ 6000/14658]  eta: 0:22:52  lr: 0.02  img/s: 59.591407894152645  loss: 0.8628 (0.8579)  time: 0.1592  data: 0.0128  max mem: 17061
2023-02-27 00:02:30,755	INFO	torchdistill.misc.log	Epoch: [9]  [ 7000/14658]  eta: 0:20:14  lr: 0.02  img/s: 59.92226670905019  loss: 0.9060 (0.8565)  time: 0.1589  data: 0.0134  max mem: 17061
2023-02-27 00:05:09,540	INFO	torchdistill.misc.log	Epoch: [9]  [ 8000/14658]  eta: 0:17:35  lr: 0.02  img/s: 59.131962287426205  loss: 0.7787 (0.8573)  time: 0.1600  data: 0.0132  max mem: 17061
2023-02-27 00:07:47,932	INFO	torchdistill.misc.log	Epoch: [9]  [ 9000/14658]  eta: 0:14:57  lr: 0.02  img/s: 58.93649399647306  loss: 0.8635 (0.8571)  time: 0.1584  data: 0.0134  max mem: 17061
2023-02-27 00:10:26,722	INFO	torchdistill.misc.log	Epoch: [9]  [10000/14658]  eta: 0:12:18  lr: 0.02  img/s: 58.215714952435974  loss: 0.8831 (0.8571)  time: 0.1610  data: 0.0140  max mem: 17061
2023-02-27 00:13:05,260	INFO	torchdistill.misc.log	Epoch: [9]  [11000/14658]  eta: 0:09:40  lr: 0.02  img/s: 58.77225475239218  loss: 0.7506 (0.8576)  time: 0.1574  data: 0.0126  max mem: 17061
2023-02-27 00:15:43,860	INFO	torchdistill.misc.log	Epoch: [9]  [12000/14658]  eta: 0:07:01  lr: 0.02  img/s: 54.022288696906564  loss: 0.8147 (0.8590)  time: 0.1598  data: 0.0131  max mem: 17061
2023-02-27 00:18:21,865	INFO	torchdistill.misc.log	Epoch: [9]  [13000/14658]  eta: 0:04:22  lr: 0.02  img/s: 59.47637920888253  loss: 0.9398 (0.8595)  time: 0.1585  data: 0.0129  max mem: 17061
2023-02-27 00:21:00,632	INFO	torchdistill.misc.log	Epoch: [9]  [14000/14658]  eta: 0:01:44  lr: 0.02  img/s: 57.101777494150184  loss: 0.9011 (0.8600)  time: 0.1599  data: 0.0143  max mem: 17061
2023-02-27 00:22:45,326	INFO	torchdistill.misc.log	Epoch: [9] Total time: 0:38:44
2023-02-27 00:22:49,505	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 1:06:42  model_time: 0.1218 (0.1218)  evaluator_time: 0.0332 (0.0332)  time: 0.8005  data: 0.6435  max mem: 17061
2023-02-27 00:24:36,646	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:07:11  model_time: 0.0878 (0.0875)  evaluator_time: 0.0085 (0.0189)  time: 0.1025  data: 0.0001  max mem: 17061
2023-02-27 00:26:20,997	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:18  model_time: 0.0857 (0.0872)  evaluator_time: 0.0095 (0.0177)  time: 0.1002  data: 0.0001  max mem: 17061
2023-02-27 00:28:04,898	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:30  model_time: 0.0876 (0.0872)  evaluator_time: 0.0103 (0.0171)  time: 0.1022  data: 0.0001  max mem: 17061
2023-02-27 00:29:48,027	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:44  model_time: 0.0894 (0.0870)  evaluator_time: 0.0113 (0.0168)  time: 0.1054  data: 0.0001  max mem: 17061
2023-02-27 00:31:30,909	INFO	torchdistill.misc.log	Validation: Total time: 0:08:42
2023-02-27 00:31:30,909	INFO	__main__	Averaged stats: model_time: 0.0832 (0.0869)  evaluator_time: 0.0116 (0.0165)
2023-02-27 00:31:31,159	INFO	__main__	Accumulating evaluation results...
2023-02-27 00:31:46,805	INFO	__main__	DONE (t=15.65s).
2023-02-27 00:31:46,805	INFO	__main__	IoU metric: bbox
2023-02-27 00:31:46,806	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.201
2023-02-27 00:31:46,807	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.379
2023-02-27 00:31:46,807	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.193
2023-02-27 00:31:46,808	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.064
2023-02-27 00:31:46,808	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.206
2023-02-27 00:31:46,809	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.338
2023-02-27 00:31:46,809	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.208
2023-02-27 00:31:46,809	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.324
2023-02-27 00:31:46,809	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.340
2023-02-27 00:31:46,809	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.119
2023-02-27 00:31:46,809	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.369
2023-02-27 00:31:46,809	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.536
2023-02-27 00:31:47,579	INFO	__main__	Best mAP (bbox): 0.1962 -> 0.2010
2023-02-27 00:31:47,581	INFO	__main__	Updating ckpt at ./resource/ckpt/coco2017/supervised_compression/entropic_student/coco2017-faster_rcnn_splittable_resnet50-fp-beta0.32_fpn.pt
2023-02-27 00:31:48,921	INFO	torchdistill.misc.log	Epoch: [10]  [    0/14658]  eta: 3:15:17  lr: 0.02  img/s: 52.16763577340937  loss: 0.6164 (0.6164)  time: 0.7994  data: 0.6365  max mem: 17061
2023-02-27 00:34:26,426	INFO	torchdistill.misc.log	Epoch: [10]  [ 1000/14658]  eta: 0:35:59  lr: 0.02  img/s: 63.44491987709761  loss: 0.8621 (0.8549)  time: 0.1583  data: 0.0127  max mem: 17061
2023-02-27 00:37:04,929	INFO	torchdistill.misc.log	Epoch: [10]  [ 2000/14658]  eta: 0:33:24  lr: 0.02  img/s: 59.64034247342312  loss: 0.8582 (0.8564)  time: 0.1586  data: 0.0129  max mem: 17061
2023-02-27 00:39:43,325	INFO	torchdistill.misc.log	Epoch: [10]  [ 3000/14658]  eta: 0:30:45  lr: 0.02  img/s: 59.170543838611835  loss: 0.7567 (0.8547)  time: 0.1576  data: 0.0125  max mem: 17061
2023-02-27 00:42:22,107	INFO	torchdistill.misc.log	Epoch: [10]  [ 4000/14658]  eta: 0:28:08  lr: 0.02  img/s: 57.86084881258665  loss: 0.7765 (0.8546)  time: 0.1586  data: 0.0124  max mem: 17061
2023-02-27 00:45:00,901	INFO	torchdistill.misc.log	Epoch: [10]  [ 5000/14658]  eta: 0:25:30  lr: 0.02  img/s: 60.31791160413667  loss: 0.8833 (0.8582)  time: 0.1584  data: 0.0128  max mem: 17061
2023-02-27 00:47:39,025	INFO	torchdistill.misc.log	Epoch: [10]  [ 6000/14658]  eta: 0:22:51  lr: 0.02  img/s: 58.689400047924806  loss: 0.8108 (0.8574)  time: 0.1584  data: 0.0126  max mem: 17061
2023-02-27 00:50:17,359	INFO	torchdistill.misc.log	Epoch: [10]  [ 7000/14658]  eta: 0:20:13  lr: 0.02  img/s: 58.50826592548548  loss: 0.7977 (0.8574)  time: 0.1560  data: 0.0130  max mem: 17061
2023-02-27 00:52:55,880	INFO	torchdistill.misc.log	Epoch: [10]  [ 8000/14658]  eta: 0:17:34  lr: 0.02  img/s: 59.01465058444048  loss: 0.8412 (0.8573)  time: 0.1587  data: 0.0131  max mem: 17061
2023-02-27 00:55:34,457	INFO	torchdistill.misc.log	Epoch: [10]  [ 9000/14658]  eta: 0:14:56  lr: 0.02  img/s: 59.69859660109881  loss: 0.8148 (0.8573)  time: 0.1584  data: 0.0130  max mem: 17061
2023-02-27 00:58:12,677	INFO	torchdistill.misc.log	Epoch: [10]  [10000/14658]  eta: 0:12:17  lr: 0.02  img/s: 59.66452163553438  loss: 0.8579 (0.8571)  time: 0.1587  data: 0.0132  max mem: 17061
2023-02-27 01:00:51,199	INFO	torchdistill.misc.log	Epoch: [10]  [11000/14658]  eta: 0:09:39  lr: 0.02  img/s: 57.17182849013043  loss: 0.8366 (0.8574)  time: 0.1576  data: 0.0126  max mem: 17061
2023-02-27 01:03:29,631	INFO	torchdistill.misc.log	Epoch: [10]  [12000/14658]  eta: 0:07:01  lr: 0.02  img/s: 60.07751213477071  loss: 0.8565 (0.8573)  time: 0.1581  data: 0.0131  max mem: 17061
2023-02-27 01:06:07,835	INFO	torchdistill.misc.log	Epoch: [10]  [13000/14658]  eta: 0:04:22  lr: 0.02  img/s: 54.34540975561563  loss: 0.9026 (0.8577)  time: 0.1590  data: 0.0131  max mem: 17061
2023-02-27 01:08:46,496	INFO	torchdistill.misc.log	Epoch: [10]  [14000/14658]  eta: 0:01:44  lr: 0.02  img/s: 59.1793099069482  loss: 0.9039 (0.8585)  time: 0.1608  data: 0.0134  max mem: 17061
2023-02-27 01:10:30,996	INFO	torchdistill.misc.log	Epoch: [10] Total time: 0:38:42
2023-02-27 01:10:35,050	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 1:01:13  model_time: 0.1237 (0.1237)  evaluator_time: 0.0456 (0.0456)  time: 0.7347  data: 0.5632  max mem: 17061
2023-02-27 01:12:22,399	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:07:11  model_time: 0.0852 (0.0879)  evaluator_time: 0.0080 (0.0187)  time: 0.0981  data: 0.0001  max mem: 17061
2023-02-27 01:14:05,910	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:17  model_time: 0.0848 (0.0871)  evaluator_time: 0.0107 (0.0176)  time: 0.1016  data: 0.0001  max mem: 17061
2023-02-27 01:15:50,358	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:30  model_time: 0.0893 (0.0873)  evaluator_time: 0.0092 (0.0170)  time: 0.1041  data: 0.0001  max mem: 17061
2023-02-27 01:17:33,629	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:44  model_time: 0.0862 (0.0871)  evaluator_time: 0.0089 (0.0167)  time: 0.1043  data: 0.0001  max mem: 17061
2023-02-27 01:19:16,441	INFO	torchdistill.misc.log	Validation: Total time: 0:08:42
2023-02-27 01:19:16,442	INFO	__main__	Averaged stats: model_time: 0.0834 (0.0870)  evaluator_time: 0.0099 (0.0164)
2023-02-27 01:19:16,680	INFO	__main__	Accumulating evaluation results...
2023-02-27 01:19:32,018	INFO	__main__	DONE (t=15.34s).
2023-02-27 01:19:32,018	INFO	__main__	IoU metric: bbox
2023-02-27 01:19:32,019	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.198
2023-02-27 01:19:32,019	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.370
2023-02-27 01:19:32,020	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.191
2023-02-27 01:19:32,020	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.060
2023-02-27 01:19:32,021	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.206
2023-02-27 01:19:32,021	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.334
2023-02-27 01:19:32,022	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.207
2023-02-27 01:19:32,022	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.324
2023-02-27 01:19:32,022	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.340
2023-02-27 01:19:32,022	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.108
2023-02-27 01:19:32,022	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.381
2023-02-27 01:19:32,022	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.539
2023-02-27 01:19:34,064	INFO	torchdistill.misc.log	Epoch: [11]  [    0/14658]  eta: 5:00:09  lr: 0.02  img/s: 56.06805478737892  loss: 0.7423 (0.7423)  time: 1.2286  data: 1.0682  max mem: 17061
2023-02-27 01:22:11,609	INFO	torchdistill.misc.log	Epoch: [11]  [ 1000/14658]  eta: 0:36:06  lr: 0.02  img/s: 59.46288800833611  loss: 0.7067 (0.8376)  time: 0.1579  data: 0.0121  max mem: 17061
2023-02-27 01:24:50,166	INFO	torchdistill.misc.log	Epoch: [11]  [ 2000/14658]  eta: 0:33:27  lr: 0.02  img/s: 57.22760274451549  loss: 0.8064 (0.8427)  time: 0.1589  data: 0.0131  max mem: 17061
2023-02-27 01:27:28,592	INFO	torchdistill.misc.log	Epoch: [11]  [ 3000/14658]  eta: 0:30:48  lr: 0.02  img/s: 53.52634089303005  loss: 0.9101 (0.8445)  time: 0.1578  data: 0.0128  max mem: 17061
2023-02-27 01:30:07,331	INFO	torchdistill.misc.log	Epoch: [11]  [ 4000/14658]  eta: 0:28:10  lr: 0.02  img/s: 64.20414028521624  loss: 0.6901 (0.8493)  time: 0.1552  data: 0.0123  max mem: 17061
2023-02-27 01:32:46,046	INFO	torchdistill.misc.log	Epoch: [11]  [ 5000/14658]  eta: 0:25:31  lr: 0.02  img/s: 60.1043079513497  loss: 0.7665 (0.8495)  time: 0.1595  data: 0.0133  max mem: 17061
2023-02-27 01:35:24,610	INFO	torchdistill.misc.log	Epoch: [11]  [ 6000/14658]  eta: 0:22:53  lr: 0.02  img/s: 60.04407780541489  loss: 0.9089 (0.8501)  time: 0.1579  data: 0.0131  max mem: 17061
2023-02-27 01:38:03,058	INFO	torchdistill.misc.log	Epoch: [11]  [ 7000/14658]  eta: 0:20:14  lr: 0.02  img/s: 60.14966774162901  loss: 0.8240 (0.8506)  time: 0.1564  data: 0.0127  max mem: 17061
2023-02-27 01:40:41,779	INFO	torchdistill.misc.log	Epoch: [11]  [ 8000/14658]  eta: 0:17:35  lr: 0.02  img/s: 58.8707295848188  loss: 0.7868 (0.8528)  time: 0.1588  data: 0.0130  max mem: 17061
2023-02-27 01:43:20,489	INFO	torchdistill.misc.log	Epoch: [11]  [ 9000/14658]  eta: 0:14:57  lr: 0.02  img/s: 60.348069746319794  loss: 0.8212 (0.8539)  time: 0.1598  data: 0.0128  max mem: 17061
2023-02-27 01:45:58,904	INFO	torchdistill.misc.log	Epoch: [11]  [10000/14658]  eta: 0:12:18  lr: 0.02  img/s: 60.253249295192944  loss: 0.9092 (0.8551)  time: 0.1568  data: 0.0128  max mem: 17061
2023-02-27 01:48:37,366	INFO	torchdistill.misc.log	Epoch: [11]  [11000/14658]  eta: 0:09:40  lr: 0.02  img/s: 58.837799213378524  loss: 0.9189 (0.8563)  time: 0.1588  data: 0.0128  max mem: 17061
2023-02-27 01:51:16,036	INFO	torchdistill.misc.log	Epoch: [11]  [12000/14658]  eta: 0:07:01  lr: 0.02  img/s: 59.743558607722726  loss: 0.8971 (0.8575)  time: 0.1592  data: 0.0134  max mem: 17061
2023-02-27 01:53:54,543	INFO	torchdistill.misc.log	Epoch: [11]  [13000/14658]  eta: 0:04:22  lr: 0.02  img/s: 59.57151810078063  loss: 0.8560 (0.8578)  time: 0.1575  data: 0.0132  max mem: 17061
2023-02-27 01:56:33,343	INFO	torchdistill.misc.log	Epoch: [11]  [14000/14658]  eta: 0:01:44  lr: 0.02  img/s: 59.96692336149292  loss: 0.8784 (0.8576)  time: 0.1572  data: 0.0132  max mem: 17061
2023-02-27 01:58:17,516	INFO	torchdistill.misc.log	Epoch: [11] Total time: 0:38:44
2023-02-27 01:58:21,485	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 0:59:58  model_time: 0.1204 (0.1204)  evaluator_time: 0.0300 (0.0300)  time: 0.7196  data: 0.5673  max mem: 17061
2023-02-27 02:00:07,952	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:07:08  model_time: 0.0833 (0.0906)  evaluator_time: 0.0073 (0.0151)  time: 0.1000  data: 0.0001  max mem: 17061
2023-02-27 02:01:51,526	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:15  model_time: 0.0845 (0.0889)  evaluator_time: 0.0097 (0.0153)  time: 0.1022  data: 0.0001  max mem: 17061
2023-02-27 02:03:33,845	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:28  model_time: 0.0863 (0.0882)  evaluator_time: 0.0091 (0.0151)  time: 0.1016  data: 0.0001  max mem: 17061
2023-02-27 02:05:15,830	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:43  model_time: 0.0846 (0.0877)  evaluator_time: 0.0088 (0.0151)  time: 0.1018  data: 0.0001  max mem: 17061
2023-02-27 02:06:57,797	INFO	torchdistill.misc.log	Validation: Total time: 0:08:37
2023-02-27 02:06:57,798	INFO	__main__	Averaged stats: model_time: 0.0828 (0.0875)  evaluator_time: 0.0091 (0.0149)
2023-02-27 02:06:57,960	INFO	__main__	Accumulating evaluation results...
2023-02-27 02:07:12,062	INFO	__main__	DONE (t=14.10s).
2023-02-27 02:07:12,062	INFO	__main__	IoU metric: bbox
2023-02-27 02:07:12,063	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.203
2023-02-27 02:07:12,063	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.376
2023-02-27 02:07:12,064	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.200
2023-02-27 02:07:12,064	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.065
2023-02-27 02:07:12,065	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.210
2023-02-27 02:07:12,066	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.341
2023-02-27 02:07:12,066	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.209
2023-02-27 02:07:12,066	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.319
2023-02-27 02:07:12,066	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.334
2023-02-27 02:07:12,066	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.114
2023-02-27 02:07:12,066	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.362
2023-02-27 02:07:12,066	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.535
2023-02-27 02:07:12,861	INFO	__main__	Best mAP (bbox): 0.2010 -> 0.2025
2023-02-27 02:07:12,863	INFO	__main__	Updating ckpt at ./resource/ckpt/coco2017/supervised_compression/entropic_student/coco2017-faster_rcnn_splittable_resnet50-fp-beta0.32_fpn.pt
2023-02-27 02:07:14,252	INFO	torchdistill.misc.log	Epoch: [12]  [    0/14658]  eta: 3:23:35  lr: 0.02  img/s: 51.75269949919875  loss: 0.5897 (0.5897)  time: 0.8334  data: 0.6700  max mem: 17061
2023-02-27 02:09:51,861	INFO	torchdistill.misc.log	Epoch: [12]  [ 1000/14658]  eta: 0:36:01  lr: 0.02  img/s: 58.655441736880746  loss: 0.9131 (0.8507)  time: 0.1597  data: 0.0122  max mem: 17061
2023-02-27 02:12:29,093	INFO	torchdistill.misc.log	Epoch: [12]  [ 2000/14658]  eta: 0:33:16  lr: 0.02  img/s: 59.39899344838635  loss: 0.8739 (0.8480)  time: 0.1550  data: 0.0119  max mem: 17061
2023-02-27 02:15:07,016	INFO	torchdistill.misc.log	Epoch: [12]  [ 3000/14658]  eta: 0:30:39  lr: 0.02  img/s: 60.15991279309517  loss: 0.8014 (0.8496)  time: 0.1582  data: 0.0129  max mem: 17061
2023-02-27 02:17:45,875	INFO	torchdistill.misc.log	Epoch: [12]  [ 4000/14658]  eta: 0:28:04  lr: 0.02  img/s: 59.44350512687873  loss: 0.9201 (0.8497)  time: 0.1587  data: 0.0137  max mem: 17061
2023-02-27 02:20:24,956	INFO	torchdistill.misc.log	Epoch: [12]  [ 5000/14658]  eta: 0:25:28  lr: 0.02  img/s: 66.38145600509615  loss: 0.7996 (0.8498)  time: 0.1577  data: 0.0128  max mem: 17061
2023-02-27 02:23:03,783	INFO	torchdistill.misc.log	Epoch: [12]  [ 6000/14658]  eta: 0:22:51  lr: 0.02  img/s: 55.053835703644395  loss: 0.7624 (0.8491)  time: 0.1603  data: 0.0136  max mem: 17061
2023-02-27 02:25:42,647	INFO	torchdistill.misc.log	Epoch: [12]  [ 7000/14658]  eta: 0:20:13  lr: 0.02  img/s: 58.31364950044577  loss: 0.8962 (0.8503)  time: 0.1589  data: 0.0133  max mem: 17061
2023-02-27 02:28:21,110	INFO	torchdistill.misc.log	Epoch: [12]  [ 8000/14658]  eta: 0:17:34  lr: 0.02  img/s: 59.04850664845878  loss: 0.8103 (0.8508)  time: 0.1566  data: 0.0124  max mem: 17061
2023-02-27 02:30:59,724	INFO	torchdistill.misc.log	Epoch: [12]  [ 9000/14658]  eta: 0:14:56  lr: 0.02  img/s: 58.733471030981974  loss: 0.8486 (0.8522)  time: 0.1587  data: 0.0131  max mem: 17061
2023-02-27 02:33:38,195	INFO	torchdistill.misc.log	Epoch: [12]  [10000/14658]  eta: 0:12:18  lr: 0.02  img/s: 59.52185165672402  loss: 0.8201 (0.8514)  time: 0.1605  data: 0.0132  max mem: 17061
2023-02-27 02:36:16,829	INFO	torchdistill.misc.log	Epoch: [12]  [11000/14658]  eta: 0:09:39  lr: 0.02  img/s: 59.898412857089305  loss: 0.7366 (0.8523)  time: 0.1597  data: 0.0138  max mem: 17061
2023-02-27 02:38:56,013	INFO	torchdistill.misc.log	Epoch: [12]  [12000/14658]  eta: 0:07:01  lr: 0.02  img/s: 58.41323603141886  loss: 0.8743 (0.8535)  time: 0.1609  data: 0.0134  max mem: 17061
2023-02-27 02:41:34,756	INFO	torchdistill.misc.log	Epoch: [12]  [13000/14658]  eta: 0:04:22  lr: 0.02  img/s: 59.268265197078485  loss: 0.7451 (0.8545)  time: 0.1591  data: 0.0131  max mem: 17061
2023-02-27 02:44:13,597	INFO	torchdistill.misc.log	Epoch: [12]  [14000/14658]  eta: 0:01:44  lr: 0.02  img/s: 60.661625155249745  loss: 0.8843 (0.8548)  time: 0.1586  data: 0.0132  max mem: 17061
2023-02-27 02:45:58,260	INFO	torchdistill.misc.log	Epoch: [12] Total time: 0:38:44
2023-02-27 02:46:02,312	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 1:02:02  model_time: 0.1160 (0.1160)  evaluator_time: 0.0405 (0.0405)  time: 0.7445  data: 0.5860  max mem: 17061
2023-02-27 02:47:47,273	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:07:02  model_time: 0.0836 (0.0880)  evaluator_time: 0.0084 (0.0162)  time: 0.0986  data: 0.0001  max mem: 17061
2023-02-27 02:49:34,435	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:19  model_time: 0.0879 (0.0874)  evaluator_time: 0.0088 (0.0178)  time: 0.1035  data: 0.0001  max mem: 17061
2023-02-27 02:51:18,349	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:31  model_time: 0.0903 (0.0874)  evaluator_time: 0.0086 (0.0172)  time: 0.1031  data: 0.0001  max mem: 17061
2023-02-27 02:53:01,837	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:45  model_time: 0.0882 (0.0873)  evaluator_time: 0.0097 (0.0168)  time: 0.1044  data: 0.0001  max mem: 17061
2023-02-27 02:54:44,993	INFO	torchdistill.misc.log	Validation: Total time: 0:08:43
2023-02-27 02:54:44,993	INFO	__main__	Averaged stats: model_time: 0.0835 (0.0872)  evaluator_time: 0.0095 (0.0166)
2023-02-27 02:54:45,163	INFO	__main__	Accumulating evaluation results...
2023-02-27 02:54:59,583	INFO	__main__	DONE (t=14.42s).
2023-02-27 02:54:59,584	INFO	__main__	IoU metric: bbox
2023-02-27 02:54:59,585	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.199
2023-02-27 02:54:59,585	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.371
2023-02-27 02:54:59,585	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.193
2023-02-27 02:54:59,586	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.052
2023-02-27 02:54:59,587	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.208
2023-02-27 02:54:59,587	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.344
2023-02-27 02:54:59,588	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.208
2023-02-27 02:54:59,588	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.318
2023-02-27 02:54:59,588	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.334
2023-02-27 02:54:59,588	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.107
2023-02-27 02:54:59,588	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.359
2023-02-27 02:54:59,588	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.548
2023-02-27 02:55:01,555	INFO	torchdistill.misc.log	Epoch: [13]  [    0/14658]  eta: 5:05:03  lr: 0.02  img/s: 53.54034781470944  loss: 1.3789 (1.3789)  time: 1.2487  data: 1.0829  max mem: 17061
2023-02-27 02:57:38,448	INFO	torchdistill.misc.log	Epoch: [13]  [ 1000/14658]  eta: 0:35:57  lr: 0.02  img/s: 60.34351154647815  loss: 0.9361 (0.8458)  time: 0.1583  data: 0.0130  max mem: 17061
2023-02-27 03:00:17,331	INFO	torchdistill.misc.log	Epoch: [13]  [ 2000/14658]  eta: 0:33:25  lr: 0.02  img/s: 59.77314500599434  loss: 0.7875 (0.8452)  time: 0.1606  data: 0.0134  max mem: 17061
2023-02-27 03:02:56,156	INFO	torchdistill.misc.log	Epoch: [13]  [ 3000/14658]  eta: 0:30:48  lr: 0.02  img/s: 60.09774130399351  loss: 0.8555 (0.8509)  time: 0.1603  data: 0.0136  max mem: 17061
2023-02-27 03:05:35,306	INFO	torchdistill.misc.log	Epoch: [13]  [ 4000/14658]  eta: 0:28:11  lr: 0.02  img/s: 57.71087831062755  loss: 0.9143 (0.8526)  time: 0.1605  data: 0.0134  max mem: 17061
2023-02-27 03:08:14,045	INFO	torchdistill.misc.log	Epoch: [13]  [ 5000/14658]  eta: 0:25:32  lr: 0.02  img/s: 60.08762501678829  loss: 0.8516 (0.8537)  time: 0.1597  data: 0.0136  max mem: 17061
2023-02-27 03:10:52,798	INFO	torchdistill.misc.log	Epoch: [13]  [ 6000/14658]  eta: 0:22:54  lr: 0.02  img/s: 55.72206086270602  loss: 0.7915 (0.8542)  time: 0.1597  data: 0.0137  max mem: 17061
2023-02-27 03:13:31,323	INFO	torchdistill.misc.log	Epoch: [13]  [ 7000/14658]  eta: 0:20:15  lr: 0.02  img/s: 53.26709084212799  loss: 0.8540 (0.8542)  time: 0.1581  data: 0.0132  max mem: 17061
2023-02-27 03:16:09,588	INFO	torchdistill.misc.log	Epoch: [13]  [ 8000/14658]  eta: 0:17:36  lr: 0.02  img/s: 56.554828183675255  loss: 0.7589 (0.8522)  time: 0.1599  data: 0.0133  max mem: 17061
2023-02-27 03:18:48,249	INFO	torchdistill.misc.log	Epoch: [13]  [ 9000/14658]  eta: 0:14:57  lr: 0.02  img/s: 58.95658346481873  loss: 0.7052 (0.8522)  time: 0.1587  data: 0.0128  max mem: 17061
2023-02-27 03:21:26,715	INFO	torchdistill.misc.log	Epoch: [13]  [10000/14658]  eta: 0:12:18  lr: 0.02  img/s: 59.184215864213535  loss: 0.8826 (0.8519)  time: 0.1582  data: 0.0129  max mem: 17061
2023-02-27 03:24:05,418	INFO	torchdistill.misc.log	Epoch: [13]  [11000/14658]  eta: 0:09:40  lr: 0.02  img/s: 59.4408725582417  loss: 0.6576 (0.8518)  time: 0.1558  data: 0.0126  max mem: 17061
2023-02-27 03:26:44,008	INFO	torchdistill.misc.log	Epoch: [13]  [12000/14658]  eta: 0:07:01  lr: 0.02  img/s: 53.57360088388757  loss: 0.7380 (0.8526)  time: 0.1582  data: 0.0123  max mem: 17061
2023-02-27 03:29:22,463	INFO	torchdistill.misc.log	Epoch: [13]  [13000/14658]  eta: 0:04:22  lr: 0.02  img/s: 52.76302075962425  loss: 0.7997 (0.8526)  time: 0.1612  data: 0.0129  max mem: 17061
2023-02-27 03:32:01,183	INFO	torchdistill.misc.log	Epoch: [13]  [14000/14658]  eta: 0:01:44  lr: 0.02  img/s: 59.7203782443638  loss: 0.7741 (0.8531)  time: 0.1571  data: 0.0126  max mem: 17061
2023-02-27 03:33:45,535	INFO	torchdistill.misc.log	Epoch: [13] Total time: 0:38:45
2023-02-27 03:33:49,567	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 1:00:16  model_time: 0.1240 (0.1240)  evaluator_time: 0.0247 (0.0247)  time: 0.7234  data: 0.5717  max mem: 17061
2023-02-27 03:35:33,410	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:06:57  model_time: 0.0866 (0.0883)  evaluator_time: 0.0075 (0.0148)  time: 0.0989  data: 0.0001  max mem: 17061
2023-02-27 03:37:16,745	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:11  model_time: 0.0844 (0.0878)  evaluator_time: 0.0088 (0.0150)  time: 0.0995  data: 0.0001  max mem: 17061
2023-02-27 03:39:01,674	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:28  model_time: 0.0877 (0.0875)  evaluator_time: 0.0092 (0.0158)  time: 0.1029  data: 0.0001  max mem: 17061
2023-02-27 03:40:43,879	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:43  model_time: 0.0892 (0.0873)  evaluator_time: 0.0080 (0.0155)  time: 0.1040  data: 0.0001  max mem: 17061
2023-02-27 03:42:25,796	INFO	torchdistill.misc.log	Validation: Total time: 0:08:36
2023-02-27 03:42:25,796	INFO	__main__	Averaged stats: model_time: 0.0834 (0.0873)  evaluator_time: 0.0084 (0.0152)
2023-02-27 03:42:25,943	INFO	__main__	Accumulating evaluation results...
2023-02-27 03:42:38,279	INFO	__main__	DONE (t=12.34s).
2023-02-27 03:42:38,279	INFO	__main__	IoU metric: bbox
2023-02-27 03:42:38,280	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.199
2023-02-27 03:42:38,280	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.369
2023-02-27 03:42:38,280	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.192
2023-02-27 03:42:38,281	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.056
2023-02-27 03:42:38,282	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.205
2023-02-27 03:42:38,283	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.342
2023-02-27 03:42:38,283	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.205
2023-02-27 03:42:38,283	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.310
2023-02-27 03:42:38,283	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.324
2023-02-27 03:42:38,283	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.100
2023-02-27 03:42:38,283	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.350
2023-02-27 03:42:38,283	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.537
2023-02-27 03:42:40,287	INFO	torchdistill.misc.log	Epoch: [14]  [    0/14658]  eta: 5:14:58  lr: 0.02  img/s: 54.956183350885325  loss: 0.9207 (0.9207)  time: 1.2893  data: 1.1339  max mem: 17061
2023-02-27 03:45:17,244	INFO	torchdistill.misc.log	Epoch: [14]  [ 1000/14658]  eta: 0:35:59  lr: 0.02  img/s: 51.28341693489471  loss: 0.8645 (0.8373)  time: 0.1602  data: 0.0133  max mem: 17061
2023-02-27 03:47:56,014	INFO	torchdistill.misc.log	Epoch: [14]  [ 2000/14658]  eta: 0:33:25  lr: 0.02  img/s: 58.830990632117306  loss: 0.7958 (0.8463)  time: 0.1566  data: 0.0130  max mem: 17061
2023-02-27 03:50:34,792	INFO	torchdistill.misc.log	Epoch: [14]  [ 3000/14658]  eta: 0:30:48  lr: 0.02  img/s: 59.898199007124354  loss: 0.8267 (0.8468)  time: 0.1577  data: 0.0128  max mem: 17061
2023-02-27 03:53:13,494	INFO	torchdistill.misc.log	Epoch: [14]  [ 4000/14658]  eta: 0:28:10  lr: 0.02  img/s: 58.64570265050555  loss: 0.8546 (0.8448)  time: 0.1595  data: 0.0131  max mem: 17061
2023-02-27 03:55:52,428	INFO	torchdistill.misc.log	Epoch: [14]  [ 5000/14658]  eta: 0:25:32  lr: 0.02  img/s: 57.16062825798099  loss: 0.8496 (0.8461)  time: 0.1599  data: 0.0131  max mem: 17061
2023-02-27 03:58:31,488	INFO	torchdistill.misc.log	Epoch: [14]  [ 6000/14658]  eta: 0:22:54  lr: 0.02  img/s: 62.404674803930135  loss: 0.8123 (0.8470)  time: 0.1575  data: 0.0132  max mem: 17061
2023-02-27 04:01:10,423	INFO	torchdistill.misc.log	Epoch: [14]  [ 7000/14658]  eta: 0:20:15  lr: 0.02  img/s: 59.24064059716565  loss: 0.7905 (0.8494)  time: 0.1602  data: 0.0134  max mem: 17061
2023-02-27 04:03:49,376	INFO	torchdistill.misc.log	Epoch: [14]  [ 8000/14658]  eta: 0:17:37  lr: 0.02  img/s: 58.79563200022429  loss: 0.7851 (0.8502)  time: 0.1583  data: 0.0129  max mem: 17061
2023-02-27 04:06:28,143	INFO	torchdistill.misc.log	Epoch: [14]  [ 9000/14658]  eta: 0:14:58  lr: 0.02  img/s: 59.87254809245027  loss: 0.7859 (0.8491)  time: 0.1556  data: 0.0131  max mem: 17061
2023-02-27 04:09:07,133	INFO	torchdistill.misc.log	Epoch: [14]  [10000/14658]  eta: 0:12:19  lr: 0.02  img/s: 60.166708804696505  loss: 0.8224 (0.8502)  time: 0.1578  data: 0.0127  max mem: 17061
2023-02-27 04:11:45,748	INFO	torchdistill.misc.log	Epoch: [14]  [11000/14658]  eta: 0:09:40  lr: 0.02  img/s: 59.790612599095866  loss: 0.8320 (0.8510)  time: 0.1590  data: 0.0132  max mem: 17061
2023-02-27 04:14:24,886	INFO	torchdistill.misc.log	Epoch: [14]  [12000/14658]  eta: 0:07:02  lr: 0.02  img/s: 59.74813300617168  loss: 0.7856 (0.8512)  time: 0.1607  data: 0.0137  max mem: 17061
2023-02-27 04:17:03,898	INFO	torchdistill.misc.log	Epoch: [14]  [13000/14658]  eta: 0:04:23  lr: 0.02  img/s: 59.623386338719165  loss: 0.7978 (0.8518)  time: 0.1590  data: 0.0131  max mem: 17061
2023-02-27 04:19:42,860	INFO	torchdistill.misc.log	Epoch: [14]  [14000/14658]  eta: 0:01:44  lr: 0.02  img/s: 59.768353853169174  loss: 0.8713 (0.8525)  time: 0.1605  data: 0.0136  max mem: 17061
2023-02-27 04:21:27,392	INFO	torchdistill.misc.log	Epoch: [14] Total time: 0:38:48
2023-02-27 04:21:31,974	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 1:03:52  model_time: 0.1173 (0.1173)  evaluator_time: 0.0270 (0.0270)  time: 0.7665  data: 0.6173  max mem: 17061
2023-02-27 04:23:17,916	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:07:06  model_time: 0.0867 (0.0877)  evaluator_time: 0.0095 (0.0175)  time: 0.1021  data: 0.0001  max mem: 17061
2023-02-27 04:25:03,608	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:18  model_time: 0.0842 (0.0873)  evaluator_time: 0.0118 (0.0178)  time: 0.1027  data: 0.0001  max mem: 17061
2023-02-27 04:26:48,391	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:31  model_time: 0.0871 (0.0872)  evaluator_time: 0.0108 (0.0175)  time: 0.1029  data: 0.0001  max mem: 17061
2023-02-27 04:28:35,458	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:46  model_time: 0.0850 (0.0870)  evaluator_time: 0.0109 (0.0181)  time: 0.1032  data: 0.0001  max mem: 17061
2023-02-27 04:30:19,899	INFO	torchdistill.misc.log	Validation: Total time: 0:08:48
2023-02-27 04:30:19,899	INFO	__main__	Averaged stats: model_time: 0.0835 (0.0870)  evaluator_time: 0.0117 (0.0178)
2023-02-27 04:30:20,099	INFO	__main__	Accumulating evaluation results...
2023-02-27 04:30:36,661	INFO	__main__	DONE (t=16.56s).
2023-02-27 04:30:36,661	INFO	__main__	IoU metric: bbox
2023-02-27 04:30:36,662	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.196
2023-02-27 04:30:36,662	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.369
2023-02-27 04:30:36,663	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.187
2023-02-27 04:30:36,663	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.062
2023-02-27 04:30:36,664	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.205
2023-02-27 04:30:36,665	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.336
2023-02-27 04:30:36,665	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.209
2023-02-27 04:30:36,665	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.322
2023-02-27 04:30:36,665	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.338
2023-02-27 04:30:36,665	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.109
2023-02-27 04:30:36,665	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.371
2023-02-27 04:30:36,665	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.554
2023-02-27 04:30:38,587	INFO	torchdistill.misc.log	Epoch: [15]  [    0/14658]  eta: 5:21:13  lr: 0.02  img/s: 55.41936762549053  loss: 0.6846 (0.6846)  time: 1.3149  data: 1.1434  max mem: 17061
2023-02-27 04:33:15,877	INFO	torchdistill.misc.log	Epoch: [15]  [ 1000/14658]  eta: 0:36:03  lr: 0.02  img/s: 59.68277503366162  loss: 0.8971 (0.8512)  time: 0.1594  data: 0.0134  max mem: 17061
2023-02-27 04:35:54,033	INFO	torchdistill.misc.log	Epoch: [15]  [ 2000/14658]  eta: 0:33:23  lr: 0.02  img/s: 59.4901929497033  loss: 0.7992 (0.8518)  time: 0.1567  data: 0.0127  max mem: 17061
2023-02-27 04:38:32,338	INFO	torchdistill.misc.log	Epoch: [15]  [ 3000/14658]  eta: 0:30:45  lr: 0.02  img/s: 57.774075521662844  loss: 0.8852 (0.8513)  time: 0.1579  data: 0.0129  max mem: 17061
2023-02-27 04:41:10,458	INFO	torchdistill.misc.log	Epoch: [15]  [ 4000/14658]  eta: 0:28:06  lr: 0.02  img/s: 57.05109776977525  loss: 0.7566 (0.8484)  time: 0.1586  data: 0.0123  max mem: 17061
2023-02-27 04:43:48,807	INFO	torchdistill.misc.log	Epoch: [15]  [ 5000/14658]  eta: 0:25:28  lr: 0.02  img/s: 59.798604230081054  loss: 0.7230 (0.8473)  time: 0.1568  data: 0.0130  max mem: 17061
2023-02-27 04:46:27,373	INFO	torchdistill.misc.log	Epoch: [15]  [ 6000/14658]  eta: 0:22:50  lr: 0.02  img/s: 58.80923437160424  loss: 0.7700 (0.8494)  time: 0.1573  data: 0.0127  max mem: 17061
2023-02-27 04:49:05,643	INFO	torchdistill.misc.log	Epoch: [15]  [ 7000/14658]  eta: 0:20:12  lr: 0.02  img/s: 59.190688796885446  loss: 0.8105 (0.8493)  time: 0.1601  data: 0.0135  max mem: 17061
2023-02-27 04:51:43,987	INFO	torchdistill.misc.log	Epoch: [15]  [ 8000/14658]  eta: 0:17:34  lr: 0.02  img/s: 59.31069395835543  loss: 0.7757 (0.8505)  time: 0.1563  data: 0.0126  max mem: 17061
2023-02-27 04:54:22,599	INFO	torchdistill.misc.log	Epoch: [15]  [ 9000/14658]  eta: 0:14:55  lr: 0.02  img/s: 59.56972021019742  loss: 0.8675 (0.8511)  time: 0.1582  data: 0.0139  max mem: 17061
2023-02-27 04:57:01,042	INFO	torchdistill.misc.log	Epoch: [15]  [10000/14658]  eta: 0:12:17  lr: 0.02  img/s: 60.26969957143216  loss: 0.9186 (0.8504)  time: 0.1580  data: 0.0139  max mem: 17061
2023-02-27 04:59:39,459	INFO	torchdistill.misc.log	Epoch: [15]  [11000/14658]  eta: 0:09:39  lr: 0.02  img/s: 54.05945271026833  loss: 0.8253 (0.8512)  time: 0.1579  data: 0.0130  max mem: 17061
2023-02-27 05:02:18,178	INFO	torchdistill.misc.log	Epoch: [15]  [12000/14658]  eta: 0:07:01  lr: 0.02  img/s: 60.02366999391793  loss: 0.8124 (0.8515)  time: 0.1582  data: 0.0132  max mem: 17061
2023-02-27 05:04:56,421	INFO	torchdistill.misc.log	Epoch: [15]  [13000/14658]  eta: 0:04:22  lr: 0.02  img/s: 63.64190744976652  loss: 0.8610 (0.8513)  time: 0.1592  data: 0.0134  max mem: 17061
2023-02-27 05:07:34,671	INFO	torchdistill.misc.log	Epoch: [15]  [14000/14658]  eta: 0:01:44  lr: 0.02  img/s: 59.729733289899265  loss: 0.8808 (0.8517)  time: 0.1578  data: 0.0132  max mem: 17061
2023-02-27 05:09:19,027	INFO	torchdistill.misc.log	Epoch: [15] Total time: 0:38:41
2023-02-27 05:09:23,077	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 1:02:01  model_time: 0.1185 (0.1185)  evaluator_time: 0.0286 (0.0286)  time: 0.7444  data: 0.5934  max mem: 17061
2023-02-27 05:11:08,505	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:07:04  model_time: 0.0858 (0.0884)  evaluator_time: 0.0094 (0.0163)  time: 0.1013  data: 0.0001  max mem: 17061
2023-02-27 05:12:52,771	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:15  model_time: 0.0865 (0.0877)  evaluator_time: 0.0102 (0.0164)  time: 0.1031  data: 0.0001  max mem: 17061
2023-02-27 05:14:36,563	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:29  model_time: 0.0870 (0.0875)  evaluator_time: 0.0100 (0.0162)  time: 0.1023  data: 0.0001  max mem: 17061
2023-02-27 05:16:22,240	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:44  model_time: 0.0892 (0.0879)  evaluator_time: 0.0099 (0.0161)  time: 0.1035  data: 0.0001  max mem: 17061
2023-02-27 05:18:05,046	INFO	torchdistill.misc.log	Validation: Total time: 0:08:42
2023-02-27 05:18:05,047	INFO	__main__	Averaged stats: model_time: 0.0836 (0.0877)  evaluator_time: 0.0107 (0.0159)
2023-02-27 05:18:05,263	INFO	__main__	Accumulating evaluation results...
2023-02-27 05:18:20,960	INFO	__main__	DONE (t=15.70s).
2023-02-27 05:18:20,960	INFO	__main__	IoU metric: bbox
2023-02-27 05:18:20,961	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.202
2023-02-27 05:18:20,961	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.376
2023-02-27 05:18:20,961	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.197
2023-02-27 05:18:20,962	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.067
2023-02-27 05:18:20,963	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.211
2023-02-27 05:18:20,963	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.340
2023-02-27 05:18:20,963	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.212
2023-02-27 05:18:20,963	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.326
2023-02-27 05:18:20,964	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.344
2023-02-27 05:18:20,964	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.110
2023-02-27 05:18:20,964	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.384
2023-02-27 05:18:20,964	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.548
2023-02-27 05:18:23,107	INFO	torchdistill.misc.log	Epoch: [16]  [    0/14658]  eta: 5:22:25  lr: 0.002  img/s: 54.80502604324044  loss: 0.8602 (0.8602)  time: 1.3198  data: 1.1458  max mem: 17061
2023-02-27 05:21:00,346	INFO	torchdistill.misc.log	Epoch: [16]  [ 1000/14658]  eta: 0:36:03  lr: 0.002  img/s: 59.41508571995198  loss: 0.7607 (0.8184)  time: 0.1595  data: 0.0133  max mem: 17061
2023-02-27 05:23:38,915	INFO	torchdistill.misc.log	Epoch: [16]  [ 2000/14658]  eta: 0:33:26  lr: 0.002  img/s: 58.93162902038888  loss: 0.7710 (0.8134)  time: 0.1589  data: 0.0131  max mem: 17061
2023-02-27 05:26:17,657	INFO	torchdistill.misc.log	Epoch: [16]  [ 3000/14658]  eta: 0:30:48  lr: 0.002  img/s: 59.82141876593393  loss: 0.7375 (0.8094)  time: 0.1582  data: 0.0128  max mem: 17061
2023-02-27 05:28:56,210	INFO	torchdistill.misc.log	Epoch: [16]  [ 4000/14658]  eta: 0:28:09  lr: 0.002  img/s: 57.62118943275954  loss: 0.7238 (0.8090)  time: 0.1581  data: 0.0125  max mem: 17061
2023-02-27 05:31:35,160	INFO	torchdistill.misc.log	Epoch: [16]  [ 5000/14658]  eta: 0:25:32  lr: 0.002  img/s: 58.95440817065179  loss: 0.7572 (0.8076)  time: 0.1588  data: 0.0131  max mem: 17061
2023-02-27 05:34:14,065	INFO	torchdistill.misc.log	Epoch: [16]  [ 6000/14658]  eta: 0:22:53  lr: 0.002  img/s: 60.17329053314922  loss: 0.7350 (0.8075)  time: 0.1560  data: 0.0124  max mem: 17061
2023-02-27 05:36:52,892	INFO	torchdistill.misc.log	Epoch: [16]  [ 7000/14658]  eta: 0:20:15  lr: 0.002  img/s: 59.83827431734528  loss: 0.8150 (0.8071)  time: 0.1602  data: 0.0128  max mem: 17061
2023-02-27 05:39:31,338	INFO	torchdistill.misc.log	Epoch: [16]  [ 8000/14658]  eta: 0:17:36  lr: 0.002  img/s: 59.44792836717845  loss: 0.6879 (0.8054)  time: 0.1618  data: 0.0129  max mem: 17061
2023-02-27 05:42:09,559	INFO	torchdistill.misc.log	Epoch: [16]  [ 9000/14658]  eta: 0:14:57  lr: 0.002  img/s: 58.35380867000454  loss: 0.7140 (0.8040)  time: 0.1565  data: 0.0123  max mem: 17061
2023-02-27 05:44:47,913	INFO	torchdistill.misc.log	Epoch: [16]  [10000/14658]  eta: 0:12:18  lr: 0.002  img/s: 57.3181256800824  loss: 0.7408 (0.8034)  time: 0.1591  data: 0.0128  max mem: 17061
2023-02-27 05:47:26,211	INFO	torchdistill.misc.log	Epoch: [16]  [11000/14658]  eta: 0:09:40  lr: 0.002  img/s: 59.83635358524885  loss: 0.8024 (0.8027)  time: 0.1570  data: 0.0129  max mem: 17061
2023-02-27 05:50:04,917	INFO	torchdistill.misc.log	Epoch: [16]  [12000/14658]  eta: 0:07:01  lr: 0.002  img/s: 58.68960535360408  loss: 0.7481 (0.8024)  time: 0.1604  data: 0.0130  max mem: 17061
2023-02-27 05:52:43,672	INFO	torchdistill.misc.log	Epoch: [16]  [13000/14658]  eta: 0:04:22  lr: 0.002  img/s: 59.56305838538865  loss: 0.6896 (0.8017)  time: 0.1606  data: 0.0135  max mem: 17061
2023-02-27 05:55:22,218	INFO	torchdistill.misc.log	Epoch: [16]  [14000/14658]  eta: 0:01:44  lr: 0.002  img/s: 64.09070454172127  loss: 0.7840 (0.8018)  time: 0.1596  data: 0.0129  max mem: 17061
2023-02-27 05:57:06,879	INFO	torchdistill.misc.log	Epoch: [16] Total time: 0:38:45
2023-02-27 05:57:10,891	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 0:58:07  model_time: 0.1009 (0.1009)  evaluator_time: 0.0273 (0.0273)  time: 0.6975  data: 0.5678  max mem: 17061
2023-02-27 05:58:55,215	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:06:59  model_time: 0.0843 (0.0874)  evaluator_time: 0.0079 (0.0162)  time: 0.1005  data: 0.0001  max mem: 17061
2023-02-27 06:00:39,526	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:13  model_time: 0.0854 (0.0872)  evaluator_time: 0.0094 (0.0164)  time: 0.1013  data: 0.0001  max mem: 17061
2023-02-27 06:02:22,956	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:28  model_time: 0.0875 (0.0871)  evaluator_time: 0.0094 (0.0162)  time: 0.1025  data: 0.0001  max mem: 17061
2023-02-27 06:04:06,057	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:43  model_time: 0.0861 (0.0869)  evaluator_time: 0.0090 (0.0161)  time: 0.1061  data: 0.0001  max mem: 17061
2023-02-27 06:05:48,627	INFO	torchdistill.misc.log	Validation: Total time: 0:08:38
2023-02-27 06:05:48,628	INFO	__main__	Averaged stats: model_time: 0.0841 (0.0868)  evaluator_time: 0.0096 (0.0159)
2023-02-27 06:05:48,793	INFO	__main__	Accumulating evaluation results...
2023-02-27 06:06:06,467	INFO	__main__	DONE (t=17.67s).
2023-02-27 06:06:06,467	INFO	__main__	IoU metric: bbox
2023-02-27 06:06:06,468	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.236
2023-02-27 06:06:06,468	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.413
2023-02-27 06:06:06,469	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.240
2023-02-27 06:06:06,469	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.080
2023-02-27 06:06:06,470	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.246
2023-02-27 06:06:06,471	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.384
2023-02-27 06:06:06,471	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.233
2023-02-27 06:06:06,471	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.357
2023-02-27 06:06:06,471	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.375
2023-02-27 06:06:06,471	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.140
2023-02-27 06:06:06,471	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.414
2023-02-27 06:06:06,471	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.583
2023-02-27 06:06:07,280	INFO	__main__	Best mAP (bbox): 0.2025 -> 0.2360
2023-02-27 06:06:07,282	INFO	__main__	Updating ckpt at ./resource/ckpt/coco2017/supervised_compression/entropic_student/coco2017-faster_rcnn_splittable_resnet50-fp-beta0.32_fpn.pt
2023-02-27 06:06:08,675	INFO	torchdistill.misc.log	Epoch: [17]  [    0/14658]  eta: 3:33:22  lr: 0.002  img/s: 52.364735019499584  loss: 0.9647 (0.9647)  time: 0.8734  data: 0.7083  max mem: 17061
2023-02-27 06:08:46,013	INFO	torchdistill.misc.log	Epoch: [17]  [ 1000/14658]  eta: 0:35:58  lr: 0.002  img/s: 56.9515542920185  loss: 0.7814 (0.7865)  time: 0.1588  data: 0.0131  max mem: 17061
2023-02-27 06:11:24,905	INFO	torchdistill.misc.log	Epoch: [17]  [ 2000/14658]  eta: 0:33:25  lr: 0.002  img/s: 59.39352616421601  loss: 0.7251 (0.7884)  time: 0.1586  data: 0.0131  max mem: 17061
2023-02-27 06:14:03,866	INFO	torchdistill.misc.log	Epoch: [17]  [ 3000/14658]  eta: 0:30:49  lr: 0.002  img/s: 57.527438935531485  loss: 0.8388 (0.7898)  time: 0.1583  data: 0.0125  max mem: 17061
2023-02-27 06:16:42,856	INFO	torchdistill.misc.log	Epoch: [17]  [ 4000/14658]  eta: 0:28:11  lr: 0.002  img/s: 67.14539109275447  loss: 0.7413 (0.7895)  time: 0.1586  data: 0.0129  max mem: 17061
2023-02-27 06:19:21,734	INFO	torchdistill.misc.log	Epoch: [17]  [ 5000/14658]  eta: 0:25:33  lr: 0.002  img/s: 59.3541284144016  loss: 0.6829 (0.7903)  time: 0.1572  data: 0.0125  max mem: 17061
2023-02-27 06:22:00,883	INFO	torchdistill.misc.log	Epoch: [17]  [ 6000/14658]  eta: 0:22:55  lr: 0.002  img/s: 59.42424011660135  loss: 0.8993 (0.7899)  time: 0.1608  data: 0.0133  max mem: 17061
2023-02-27 06:24:40,223	INFO	torchdistill.misc.log	Epoch: [17]  [ 7000/14658]  eta: 0:20:16  lr: 0.002  img/s: 60.605527288753066  loss: 0.8808 (0.7914)  time: 0.1585  data: 0.0137  max mem: 17061
2023-02-27 06:27:19,539	INFO	torchdistill.misc.log	Epoch: [17]  [ 8000/14658]  eta: 0:17:38  lr: 0.002  img/s: 59.272348288129784  loss: 0.8478 (0.7921)  time: 0.1598  data: 0.0126  max mem: 17061
2023-02-27 06:29:58,534	INFO	torchdistill.misc.log	Epoch: [17]  [ 9000/14658]  eta: 0:14:59  lr: 0.002  img/s: 58.85224687668268  loss: 0.7681 (0.7931)  time: 0.1598  data: 0.0135  max mem: 17061
2023-02-27 06:32:37,871	INFO	torchdistill.misc.log	Epoch: [17]  [10000/14658]  eta: 0:12:20  lr: 0.002  img/s: 57.71226795594839  loss: 0.8206 (0.7941)  time: 0.1597  data: 0.0136  max mem: 17061
2023-02-27 06:35:16,791	INFO	torchdistill.misc.log	Epoch: [17]  [11000/14658]  eta: 0:09:41  lr: 0.002  img/s: 59.38101828092095  loss: 0.8033 (0.7921)  time: 0.1589  data: 0.0133  max mem: 17061
2023-02-27 06:37:55,895	INFO	torchdistill.misc.log	Epoch: [17]  [12000/14658]  eta: 0:07:02  lr: 0.002  img/s: 52.59719320135873  loss: 0.8334 (0.7920)  time: 0.1570  data: 0.0125  max mem: 17061
2023-02-27 06:40:34,952	INFO	torchdistill.misc.log	Epoch: [17]  [13000/14658]  eta: 0:04:23  lr: 0.002  img/s: 52.613027805174056  loss: 0.7253 (0.7910)  time: 0.1595  data: 0.0128  max mem: 17061
2023-02-27 06:43:15,579	INFO	torchdistill.misc.log	Epoch: [17]  [14000/14658]  eta: 0:01:44  lr: 0.002  img/s: 56.92855773455964  loss: 0.7437 (0.7920)  time: 0.1631  data: 0.0131  max mem: 17061
2023-02-27 06:45:01,496	INFO	torchdistill.misc.log	Epoch: [17] Total time: 0:38:53
2023-02-27 06:45:05,862	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 1:03:13  model_time: 0.1268 (0.1268)  evaluator_time: 0.0268 (0.0268)  time: 0.7586  data: 0.6029  max mem: 17061
2023-02-27 06:46:50,603	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:07:01  model_time: 0.0883 (0.0878)  evaluator_time: 0.0090 (0.0162)  time: 0.1042  data: 0.0001  max mem: 17061
2023-02-27 06:48:34,939	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:14  model_time: 0.0870 (0.0872)  evaluator_time: 0.0110 (0.0165)  time: 0.1031  data: 0.0001  max mem: 17061
2023-02-27 06:50:18,515	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:28  model_time: 0.0827 (0.0871)  evaluator_time: 0.0110 (0.0163)  time: 0.1005  data: 0.0001  max mem: 17061
2023-02-27 06:52:02,236	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:44  model_time: 0.0844 (0.0870)  evaluator_time: 0.0098 (0.0163)  time: 0.1019  data: 0.0001  max mem: 17061
2023-02-27 06:53:44,975	INFO	torchdistill.misc.log	Validation: Total time: 0:08:39
2023-02-27 06:53:44,976	INFO	__main__	Averaged stats: model_time: 0.0839 (0.0869)  evaluator_time: 0.0104 (0.0161)
2023-02-27 06:53:45,154	INFO	__main__	Accumulating evaluation results...
2023-02-27 06:54:00,205	INFO	__main__	DONE (t=15.05s).
2023-02-27 06:54:00,206	INFO	__main__	IoU metric: bbox
2023-02-27 06:54:00,207	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.240
2023-02-27 06:54:00,207	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.420
2023-02-27 06:54:00,207	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.242
2023-02-27 06:54:00,208	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.084
2023-02-27 06:54:00,209	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.251
2023-02-27 06:54:00,209	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.391
2023-02-27 06:54:00,210	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.235
2023-02-27 06:54:00,210	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.361
2023-02-27 06:54:00,210	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.380
2023-02-27 06:54:00,210	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.146
2023-02-27 06:54:00,210	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.421
2023-02-27 06:54:00,210	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.588
2023-02-27 06:54:00,991	INFO	__main__	Best mAP (bbox): 0.2360 -> 0.2397
2023-02-27 06:54:00,992	INFO	__main__	Updating ckpt at ./resource/ckpt/coco2017/supervised_compression/entropic_student/coco2017-faster_rcnn_splittable_resnet50-fp-beta0.32_fpn.pt
2023-02-27 06:54:02,417	INFO	torchdistill.misc.log	Epoch: [18]  [    0/14658]  eta: 3:30:25  lr: 0.002  img/s: 51.13632927751091  loss: 1.0654 (1.0654)  time: 0.8613  data: 0.6943  max mem: 17061
2023-02-27 06:56:40,031	INFO	torchdistill.misc.log	Epoch: [18]  [ 1000/14658]  eta: 0:36:02  lr: 0.002  img/s: 58.80686380867422  loss: 0.8639 (0.7797)  time: 0.1592  data: 0.0128  max mem: 17061
2023-02-27 06:59:17,694	INFO	torchdistill.misc.log	Epoch: [18]  [ 2000/14658]  eta: 0:33:19  lr: 0.002  img/s: 59.94656795399284  loss: 0.7366 (0.7804)  time: 0.1579  data: 0.0126  max mem: 17061
2023-02-27 07:01:55,102	INFO	torchdistill.misc.log	Epoch: [18]  [ 3000/14658]  eta: 0:30:39  lr: 0.002  img/s: 59.818219417406496  loss: 0.9425 (0.7869)  time: 0.1595  data: 0.0127  max mem: 17061
2023-02-27 07:04:33,637	INFO	torchdistill.misc.log	Epoch: [18]  [ 4000/14658]  eta: 0:28:03  lr: 0.002  img/s: 60.48437347907751  loss: 0.8306 (0.7882)  time: 0.1595  data: 0.0129  max mem: 17061
2023-02-27 07:07:12,349	INFO	torchdistill.misc.log	Epoch: [18]  [ 5000/14658]  eta: 0:25:27  lr: 0.002  img/s: 60.04988045299011  loss: 0.8287 (0.7899)  time: 0.1577  data: 0.0138  max mem: 17061
2023-02-27 07:09:51,253	INFO	torchdistill.misc.log	Epoch: [18]  [ 6000/14658]  eta: 0:22:50  lr: 0.002  img/s: 58.68601271158279  loss: 0.7579 (0.7883)  time: 0.1605  data: 0.0137  max mem: 17061
2023-02-27 07:12:30,035	INFO	torchdistill.misc.log	Epoch: [18]  [ 7000/14658]  eta: 0:20:12  lr: 0.002  img/s: 53.214039672923576  loss: 0.7561 (0.7867)  time: 0.1596  data: 0.0132  max mem: 17061
2023-02-27 07:15:09,045	INFO	torchdistill.misc.log	Epoch: [18]  [ 8000/14658]  eta: 0:17:34  lr: 0.002  img/s: 59.233738470364976  loss: 0.7647 (0.7877)  time: 0.1615  data: 0.0136  max mem: 17061
2023-02-27 07:17:48,280	INFO	torchdistill.misc.log	Epoch: [18]  [ 9000/14658]  eta: 0:14:56  lr: 0.002  img/s: 59.564750136244136  loss: 0.6945 (0.7875)  time: 0.1591  data: 0.0129  max mem: 17061
2023-02-27 07:20:26,851	INFO	torchdistill.misc.log	Epoch: [18]  [10000/14658]  eta: 0:12:18  lr: 0.002  img/s: 60.11550685638323  loss: 0.8100 (0.7875)  time: 0.1595  data: 0.0133  max mem: 17061
2023-02-27 07:23:05,815	INFO	torchdistill.misc.log	Epoch: [18]  [11000/14658]  eta: 0:09:39  lr: 0.002  img/s: 59.28187768875383  loss: 0.7460 (0.7883)  time: 0.1573  data: 0.0124  max mem: 17061
2023-02-27 07:25:44,328	INFO	torchdistill.misc.log	Epoch: [18]  [12000/14658]  eta: 0:07:01  lr: 0.002  img/s: 59.67449594604929  loss: 0.6951 (0.7885)  time: 0.1587  data: 0.0124  max mem: 17061
2023-02-27 07:28:23,380	INFO	torchdistill.misc.log	Epoch: [18]  [13000/14658]  eta: 0:04:22  lr: 0.002  img/s: 60.14050407395857  loss: 0.8504 (0.7880)  time: 0.1580  data: 0.0133  max mem: 17061
2023-02-27 07:31:01,964	INFO	torchdistill.misc.log	Epoch: [18]  [14000/14658]  eta: 0:01:44  lr: 0.002  img/s: 61.14546872608261  loss: 0.8976 (0.7878)  time: 0.1582  data: 0.0132  max mem: 17061
2023-02-27 07:32:46,386	INFO	torchdistill.misc.log	Epoch: [18] Total time: 0:38:44
2023-02-27 07:32:50,396	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 0:59:53  model_time: 0.1101 (0.1101)  evaluator_time: 0.0300 (0.0300)  time: 0.7187  data: 0.5767  max mem: 17061
2023-02-27 07:34:37,288	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:07:10  model_time: 0.0844 (0.0876)  evaluator_time: 0.0085 (0.0185)  time: 0.0991  data: 0.0001  max mem: 17061
2023-02-27 07:36:21,342	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:17  model_time: 0.0877 (0.0872)  evaluator_time: 0.0099 (0.0175)  time: 0.1024  data: 0.0001  max mem: 17061
2023-02-27 07:38:04,859	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:30  model_time: 0.0875 (0.0872)  evaluator_time: 0.0094 (0.0168)  time: 0.1022  data: 0.0003  max mem: 17061
2023-02-27 07:39:47,614	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:44  model_time: 0.0851 (0.0870)  evaluator_time: 0.0091 (0.0165)  time: 0.1030  data: 0.0001  max mem: 17061
2023-02-27 07:41:29,975	INFO	torchdistill.misc.log	Validation: Total time: 0:08:40
2023-02-27 07:41:29,976	INFO	__main__	Averaged stats: model_time: 0.0837 (0.0869)  evaluator_time: 0.0097 (0.0162)
2023-02-27 07:41:30,163	INFO	__main__	Accumulating evaluation results...
2023-02-27 07:41:44,656	INFO	__main__	DONE (t=14.49s).
2023-02-27 07:41:44,656	INFO	__main__	IoU metric: bbox
2023-02-27 07:41:44,657	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.240
2023-02-27 07:41:44,657	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.421
2023-02-27 07:41:44,658	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.244
2023-02-27 07:41:44,658	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.084
2023-02-27 07:41:44,659	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.253
2023-02-27 07:41:44,660	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.391
2023-02-27 07:41:44,660	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.236
2023-02-27 07:41:44,660	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.360
2023-02-27 07:41:44,660	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.378
2023-02-27 07:41:44,660	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.147
2023-02-27 07:41:44,660	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.418
2023-02-27 07:41:44,660	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.586
2023-02-27 07:41:45,427	INFO	__main__	Best mAP (bbox): 0.2397 -> 0.2399
2023-02-27 07:41:45,429	INFO	__main__	Updating ckpt at ./resource/ckpt/coco2017/supervised_compression/entropic_student/coco2017-faster_rcnn_splittable_resnet50-fp-beta0.32_fpn.pt
2023-02-27 07:41:46,878	INFO	torchdistill.misc.log	Epoch: [19]  [    0/14658]  eta: 3:34:45  lr: 0.002  img/s: 50.256087971734495  loss: 0.7105 (0.7105)  time: 0.8791  data: 0.7077  max mem: 17061
2023-02-27 07:44:24,360	INFO	torchdistill.misc.log	Epoch: [19]  [ 1000/14658]  eta: 0:36:00  lr: 0.002  img/s: 59.355073348227634  loss: 0.6907 (0.7829)  time: 0.1566  data: 0.0124  max mem: 17061
2023-02-27 07:47:02,032	INFO	torchdistill.misc.log	Epoch: [19]  [ 2000/14658]  eta: 0:33:19  lr: 0.002  img/s: 58.795528975971486  loss: 0.9015 (0.7851)  time: 0.1593  data: 0.0130  max mem: 17061
2023-02-27 07:49:41,224	INFO	torchdistill.misc.log	Epoch: [19]  [ 3000/14658]  eta: 0:30:46  lr: 0.002  img/s: 60.48884394136872  loss: 0.7534 (0.7862)  time: 0.1586  data: 0.0135  max mem: 17061
2023-02-27 07:52:20,560	INFO	torchdistill.misc.log	Epoch: [19]  [ 4000/14658]  eta: 0:28:10  lr: 0.002  img/s: 59.95952953621935  loss: 0.8065 (0.7883)  time: 0.1594  data: 0.0135  max mem: 17061
2023-02-27 07:54:59,602	INFO	torchdistill.misc.log	Epoch: [19]  [ 5000/14658]  eta: 0:25:32  lr: 0.002  img/s: 62.38738658337052  loss: 0.6478 (0.7855)  time: 0.1607  data: 0.0131  max mem: 17061
2023-02-27 07:57:38,624	INFO	torchdistill.misc.log	Epoch: [19]  [ 6000/14658]  eta: 0:22:54  lr: 0.002  img/s: 58.29662897142192  loss: 0.7706 (0.7857)  time: 0.1590  data: 0.0129  max mem: 17061
2023-02-27 08:00:17,740	INFO	torchdistill.misc.log	Epoch: [19]  [ 7000/14658]  eta: 0:20:16  lr: 0.002  img/s: 61.37901060225801  loss: 0.7338 (0.7853)  time: 0.1612  data: 0.0129  max mem: 17061
2023-02-27 08:02:56,853	INFO	torchdistill.misc.log	Epoch: [19]  [ 8000/14658]  eta: 0:17:37  lr: 0.002  img/s: 59.37229741326685  loss: 0.7047 (0.7844)  time: 0.1589  data: 0.0127  max mem: 17061
2023-02-27 08:05:35,799	INFO	torchdistill.misc.log	Epoch: [19]  [ 9000/14658]  eta: 0:14:58  lr: 0.002  img/s: 58.015913798528956  loss: 0.7549 (0.7842)  time: 0.1565  data: 0.0121  max mem: 17061
2023-02-27 08:08:15,014	INFO	torchdistill.misc.log	Epoch: [19]  [10000/14658]  eta: 0:12:20  lr: 0.002  img/s: 58.72031472031472  loss: 0.7331 (0.7852)  time: 0.1620  data: 0.0149  max mem: 17061
2023-02-27 08:10:54,216	INFO	torchdistill.misc.log	Epoch: [19]  [11000/14658]  eta: 0:09:41  lr: 0.002  img/s: 58.77379893082598  loss: 0.7878 (0.7853)  time: 0.1590  data: 0.0127  max mem: 17061
2023-02-27 08:13:33,125	INFO	torchdistill.misc.log	Epoch: [19]  [12000/14658]  eta: 0:07:02  lr: 0.002  img/s: 57.63187798426711  loss: 0.8225 (0.7857)  time: 0.1574  data: 0.0128  max mem: 17061
2023-02-27 08:16:12,025	INFO	torchdistill.misc.log	Epoch: [19]  [13000/14658]  eta: 0:04:23  lr: 0.002  img/s: 58.879716993547774  loss: 0.7382 (0.7848)  time: 0.1559  data: 0.0129  max mem: 17061
2023-02-27 08:18:50,965	INFO	torchdistill.misc.log	Epoch: [19]  [14000/14658]  eta: 0:01:44  lr: 0.002  img/s: 58.909488002837115  loss: 0.6874 (0.7848)  time: 0.1591  data: 0.0131  max mem: 17061
2023-02-27 08:20:35,664	INFO	torchdistill.misc.log	Epoch: [19] Total time: 0:38:49
2023-02-27 08:20:39,734	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 0:59:18  model_time: 0.1153 (0.1153)  evaluator_time: 0.0281 (0.0281)  time: 0.7117  data: 0.5661  max mem: 17061
2023-02-27 08:22:24,559	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:07:01  model_time: 0.0822 (0.0880)  evaluator_time: 0.0083 (0.0160)  time: 0.0976  data: 0.0001  max mem: 17061
2023-02-27 08:24:12,084	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:19  model_time: 0.0842 (0.0877)  evaluator_time: 0.0095 (0.0176)  time: 0.1008  data: 0.0001  max mem: 17061
2023-02-27 08:25:55,671	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:31  model_time: 0.0876 (0.0875)  evaluator_time: 0.0097 (0.0170)  time: 0.1024  data: 0.0001  max mem: 17061
2023-02-27 08:27:38,951	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:44  model_time: 0.0858 (0.0873)  evaluator_time: 0.0098 (0.0167)  time: 0.1048  data: 0.0001  max mem: 17061
2023-02-27 08:29:21,739	INFO	torchdistill.misc.log	Validation: Total time: 0:08:42
2023-02-27 08:29:21,739	INFO	__main__	Averaged stats: model_time: 0.0834 (0.0872)  evaluator_time: 0.0096 (0.0164)
2023-02-27 08:29:21,930	INFO	__main__	Accumulating evaluation results...
2023-02-27 08:29:36,653	INFO	__main__	DONE (t=14.72s).
2023-02-27 08:29:36,654	INFO	__main__	IoU metric: bbox
2023-02-27 08:29:36,655	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.241
2023-02-27 08:29:36,655	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.423
2023-02-27 08:29:36,655	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.243
2023-02-27 08:29:36,656	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.084
2023-02-27 08:29:36,657	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.254
2023-02-27 08:29:36,657	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.391
2023-02-27 08:29:36,658	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.236
2023-02-27 08:29:36,658	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.363
2023-02-27 08:29:36,658	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.381
2023-02-27 08:29:36,658	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.146
2023-02-27 08:29:36,658	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.424
2023-02-27 08:29:36,658	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.589
2023-02-27 08:29:37,362	INFO	__main__	Best mAP (bbox): 0.2399 -> 0.2413
2023-02-27 08:29:37,364	INFO	__main__	Updating ckpt at ./resource/ckpt/coco2017/supervised_compression/entropic_student/coco2017-faster_rcnn_splittable_resnet50-fp-beta0.32_fpn.pt
2023-02-27 08:29:38,782	INFO	torchdistill.misc.log	Epoch: [20]  [    0/14658]  eta: 3:29:42  lr: 0.002  img/s: 51.95165650478883  loss: 0.6175 (0.6175)  time: 0.8584  data: 0.6922  max mem: 17061
2023-02-27 08:32:16,253	INFO	torchdistill.misc.log	Epoch: [20]  [ 1000/14658]  eta: 0:36:00  lr: 0.002  img/s: 53.35865798835011  loss: 0.6449 (0.7803)  time: 0.1561  data: 0.0118  max mem: 17061
2023-02-27 08:34:53,760	INFO	torchdistill.misc.log	Epoch: [20]  [ 2000/14658]  eta: 0:33:17  lr: 0.002  img/s: 58.096373568342955  loss: 0.7404 (0.7838)  time: 0.1591  data: 0.0133  max mem: 17061
2023-02-27 08:37:32,303	INFO	torchdistill.misc.log	Epoch: [20]  [ 3000/14658]  eta: 0:30:42  lr: 0.002  img/s: 60.56428713246575  loss: 0.8432 (0.7852)  time: 0.1586  data: 0.0131  max mem: 17061
2023-02-27 08:40:11,115	INFO	torchdistill.misc.log	Epoch: [20]  [ 4000/14658]  eta: 0:28:06  lr: 0.002  img/s: 59.151351046426356  loss: 0.6579 (0.7857)  time: 0.1562  data: 0.0126  max mem: 17061
2023-02-27 08:42:49,869	INFO	torchdistill.misc.log	Epoch: [20]  [ 5000/14658]  eta: 0:25:29  lr: 0.002  img/s: 58.193200185916155  loss: 0.7740 (0.7835)  time: 0.1591  data: 0.0131  max mem: 17061
2023-02-27 08:45:28,726	INFO	torchdistill.misc.log	Epoch: [20]  [ 6000/14658]  eta: 0:22:51  lr: 0.002  img/s: 59.631969176743226  loss: 0.7794 (0.7839)  time: 0.1586  data: 0.0130  max mem: 17061
2023-02-27 08:48:07,366	INFO	torchdistill.misc.log	Epoch: [20]  [ 7000/14658]  eta: 0:20:13  lr: 0.002  img/s: 53.29069370395252  loss: 0.8880 (0.7834)  time: 0.1597  data: 0.0138  max mem: 17061
2023-02-27 08:50:45,961	INFO	torchdistill.misc.log	Epoch: [20]  [ 8000/14658]  eta: 0:17:35  lr: 0.002  img/s: 60.281934875364925  loss: 0.8524 (0.7847)  time: 0.1586  data: 0.0132  max mem: 17061
2023-02-27 08:53:24,449	INFO	torchdistill.misc.log	Epoch: [20]  [ 9000/14658]  eta: 0:14:56  lr: 0.002  img/s: 58.48501464982474  loss: 0.7107 (0.7838)  time: 0.1599  data: 0.0135  max mem: 17061
2023-02-27 08:56:03,212	INFO	torchdistill.misc.log	Epoch: [20]  [10000/14658]  eta: 0:12:18  lr: 0.002  img/s: 59.91927056361318  loss: 0.7372 (0.7832)  time: 0.1605  data: 0.0131  max mem: 17061
2023-02-27 08:58:41,888	INFO	torchdistill.misc.log	Epoch: [20]  [11000/14658]  eta: 0:09:39  lr: 0.002  img/s: 59.7682473918302  loss: 0.6827 (0.7836)  time: 0.1572  data: 0.0130  max mem: 17061
2023-02-27 09:01:20,513	INFO	torchdistill.misc.log	Epoch: [20]  [12000/14658]  eta: 0:07:01  lr: 0.002  img/s: 62.971273503198816  loss: 0.7864 (0.7833)  time: 0.1588  data: 0.0132  max mem: 17061
2023-02-27 09:03:58,838	INFO	torchdistill.misc.log	Epoch: [20]  [13000/14658]  eta: 0:04:22  lr: 0.002  img/s: 53.855551364668685  loss: 0.7387 (0.7841)  time: 0.1565  data: 0.0126  max mem: 17061
2023-02-27 09:06:37,257	INFO	torchdistill.misc.log	Epoch: [20]  [14000/14658]  eta: 0:01:44  lr: 0.002  img/s: 62.28732662092726  loss: 0.7880 (0.7841)  time: 0.1598  data: 0.0131  max mem: 17061
2023-02-27 09:08:21,905	INFO	torchdistill.misc.log	Epoch: [20] Total time: 0:38:43
2023-02-27 09:08:25,946	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 0:59:16  model_time: 0.1014 (0.1014)  evaluator_time: 0.0297 (0.0297)  time: 0.7112  data: 0.5785  max mem: 17061
2023-02-27 09:10:10,113	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:06:59  model_time: 0.0843 (0.0879)  evaluator_time: 0.0080 (0.0154)  time: 0.1010  data: 0.0001  max mem: 17061
2023-02-27 09:11:56,681	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:17  model_time: 0.0833 (0.0875)  evaluator_time: 0.0096 (0.0170)  time: 0.1007  data: 0.0001  max mem: 17061
2023-02-27 09:13:39,644	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:29  model_time: 0.0841 (0.0874)  evaluator_time: 0.0092 (0.0164)  time: 0.0989  data: 0.0001  max mem: 17061
2023-02-27 09:15:21,890	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:44  model_time: 0.0865 (0.0871)  evaluator_time: 0.0084 (0.0161)  time: 0.1027  data: 0.0001  max mem: 17061
2023-02-27 09:17:04,153	INFO	torchdistill.misc.log	Validation: Total time: 0:08:38
2023-02-27 09:17:04,154	INFO	__main__	Averaged stats: model_time: 0.0838 (0.0870)  evaluator_time: 0.0094 (0.0158)
2023-02-27 09:17:04,325	INFO	__main__	Accumulating evaluation results...
2023-02-27 09:17:18,298	INFO	__main__	DONE (t=13.97s).
2023-02-27 09:17:18,298	INFO	__main__	IoU metric: bbox
2023-02-27 09:17:18,299	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.243
2023-02-27 09:17:18,299	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.425
2023-02-27 09:17:18,300	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.247
2023-02-27 09:17:18,301	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.087
2023-02-27 09:17:18,301	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.258
2023-02-27 09:17:18,302	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.397
2023-02-27 09:17:18,302	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.238
2023-02-27 09:17:18,302	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.365
2023-02-27 09:17:18,302	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.382
2023-02-27 09:17:18,302	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.146
2023-02-27 09:17:18,302	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.423
2023-02-27 09:17:18,302	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.594
2023-02-27 09:17:19,022	INFO	__main__	Best mAP (bbox): 0.2413 -> 0.2433
2023-02-27 09:17:19,024	INFO	__main__	Updating ckpt at ./resource/ckpt/coco2017/supervised_compression/entropic_student/coco2017-faster_rcnn_splittable_resnet50-fp-beta0.32_fpn.pt
2023-02-27 09:17:20,375	INFO	torchdistill.misc.log	Epoch: [21]  [    0/14658]  eta: 3:18:35  lr: 0.002  img/s: 51.79951680753348  loss: 0.4385 (0.4385)  time: 0.8129  data: 0.6501  max mem: 17061
2023-02-27 09:19:57,915	INFO	torchdistill.misc.log	Epoch: [21]  [ 1000/14658]  eta: 0:36:00  lr: 0.002  img/s: 59.802654138581254  loss: 0.7173 (0.7923)  time: 0.1582  data: 0.0127  max mem: 17061
2023-02-27 09:22:36,799	INFO	torchdistill.misc.log	Epoch: [21]  [ 2000/14658]  eta: 0:33:26  lr: 0.002  img/s: 58.697818758779455  loss: 0.8138 (0.7810)  time: 0.1594  data: 0.0135  max mem: 17061
2023-02-27 09:25:15,930	INFO	torchdistill.misc.log	Epoch: [21]  [ 3000/14658]  eta: 0:30:50  lr: 0.002  img/s: 59.88248521428138  loss: 0.7094 (0.7843)  time: 0.1574  data: 0.0127  max mem: 17061
2023-02-27 09:27:54,354	INFO	torchdistill.misc.log	Epoch: [21]  [ 4000/14658]  eta: 0:28:10  lr: 0.002  img/s: 59.845104585794594  loss: 0.7449 (0.7810)  time: 0.1595  data: 0.0132  max mem: 17061
2023-02-27 09:30:32,540	INFO	torchdistill.misc.log	Epoch: [21]  [ 5000/14658]  eta: 0:25:31  lr: 0.002  img/s: 60.19779584968147  loss: 0.8050 (0.7794)  time: 0.1595  data: 0.0136  max mem: 17061
2023-02-27 09:33:11,030	INFO	torchdistill.misc.log	Epoch: [21]  [ 6000/14658]  eta: 0:22:52  lr: 0.002  img/s: 59.924835072203905  loss: 0.7581 (0.7808)  time: 0.1581  data: 0.0129  max mem: 17061
2023-02-27 09:35:49,893	INFO	torchdistill.misc.log	Epoch: [21]  [ 7000/14658]  eta: 0:20:14  lr: 0.002  img/s: 52.62730361080701  loss: 0.8392 (0.7810)  time: 0.1606  data: 0.0136  max mem: 17061
2023-02-27 09:38:28,749	INFO	torchdistill.misc.log	Epoch: [21]  [ 8000/14658]  eta: 0:17:36  lr: 0.002  img/s: 62.28015873310491  loss: 0.7440 (0.7808)  time: 0.1588  data: 0.0128  max mem: 17061
2023-02-27 09:41:07,253	INFO	torchdistill.misc.log	Epoch: [21]  [ 9000/14658]  eta: 0:14:57  lr: 0.002  img/s: 57.89858818576176  loss: 0.6671 (0.7794)  time: 0.1581  data: 0.0127  max mem: 17061
2023-02-27 09:43:45,949	INFO	torchdistill.misc.log	Epoch: [21]  [10000/14658]  eta: 0:12:18  lr: 0.002  img/s: 60.075360896911405  loss: 0.8327 (0.7807)  time: 0.1601  data: 0.0139  max mem: 17061
2023-02-27 09:46:24,559	INFO	torchdistill.misc.log	Epoch: [21]  [11000/14658]  eta: 0:09:40  lr: 0.002  img/s: 59.58505864490753  loss: 0.7108 (0.7812)  time: 0.1592  data: 0.0128  max mem: 17061
2023-02-27 09:49:02,550	INFO	torchdistill.misc.log	Epoch: [21]  [12000/14658]  eta: 0:07:01  lr: 0.002  img/s: 59.842436326605586  loss: 0.8017 (0.7811)  time: 0.1579  data: 0.0129  max mem: 17061
2023-02-27 09:51:41,231	INFO	torchdistill.misc.log	Epoch: [21]  [13000/14658]  eta: 0:04:22  lr: 0.002  img/s: 59.93703780446852  loss: 0.7553 (0.7808)  time: 0.1580  data: 0.0134  max mem: 17061
2023-02-27 09:54:20,101	INFO	torchdistill.misc.log	Epoch: [21]  [14000/14658]  eta: 0:01:44  lr: 0.002  img/s: 52.98740313902974  loss: 0.7622 (0.7818)  time: 0.1600  data: 0.0132  max mem: 17061
2023-02-27 09:56:04,654	INFO	torchdistill.misc.log	Epoch: [21] Total time: 0:38:45
2023-02-27 09:56:08,685	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 0:59:33  model_time: 0.1151 (0.1151)  evaluator_time: 0.0285 (0.0285)  time: 0.7146  data: 0.5693  max mem: 17061
2023-02-27 09:57:54,065	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:07:03  model_time: 0.0857 (0.0879)  evaluator_time: 0.0096 (0.0167)  time: 0.0998  data: 0.0001  max mem: 17061
2023-02-27 09:59:39,561	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:17  model_time: 0.0844 (0.0877)  evaluator_time: 0.0105 (0.0169)  time: 0.1012  data: 0.0001  max mem: 17061
2023-02-27 10:01:26,498	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:32  model_time: 0.0872 (0.0875)  evaluator_time: 0.0100 (0.0176)  time: 0.1020  data: 0.0001  max mem: 17061
2023-02-27 10:03:10,305	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:45  model_time: 0.0865 (0.0873)  evaluator_time: 0.0094 (0.0174)  time: 0.1046  data: 0.0001  max mem: 17061
2023-02-27 10:04:54,149	INFO	torchdistill.misc.log	Validation: Total time: 0:08:46
2023-02-27 10:04:54,149	INFO	__main__	Averaged stats: model_time: 0.0834 (0.0872)  evaluator_time: 0.0098 (0.0170)
2023-02-27 10:04:54,339	INFO	__main__	Accumulating evaluation results...
2023-02-27 10:05:10,257	INFO	__main__	DONE (t=15.92s).
2023-02-27 10:05:10,258	INFO	__main__	IoU metric: bbox
2023-02-27 10:05:10,259	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.242
2023-02-27 10:05:10,259	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.423
2023-02-27 10:05:10,259	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.244
2023-02-27 10:05:10,260	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.090
2023-02-27 10:05:10,261	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.257
2023-02-27 10:05:10,261	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.389
2023-02-27 10:05:10,261	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.238
2023-02-27 10:05:10,262	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.368
2023-02-27 10:05:10,262	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.386
2023-02-27 10:05:10,262	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.152
2023-02-27 10:05:10,262	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.431
2023-02-27 10:05:10,262	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.590
2023-02-27 10:05:12,328	INFO	torchdistill.misc.log	Epoch: [22]  [    0/14658]  eta: 5:32:55  lr: 0.0002  img/s: 56.713313614468014  loss: 1.3150 (1.3150)  time: 1.3628  data: 1.1881  max mem: 17061
2023-02-27 10:07:50,023	INFO	torchdistill.misc.log	Epoch: [22]  [ 1000/14658]  eta: 0:36:10  lr: 0.0002  img/s: 59.46478483857133  loss: 0.7094 (0.7701)  time: 0.1579  data: 0.0140  max mem: 17061
2023-02-27 10:10:28,942	INFO	torchdistill.misc.log	Epoch: [22]  [ 2000/14658]  eta: 0:33:31  lr: 0.0002  img/s: 58.99856699013421  loss: 0.7675 (0.7748)  time: 0.1599  data: 0.0138  max mem: 17061
2023-02-27 10:13:07,623	INFO	torchdistill.misc.log	Epoch: [22]  [ 3000/14658]  eta: 0:30:51  lr: 0.0002  img/s: 59.582519324027494  loss: 0.7273 (0.7727)  time: 0.1577  data: 0.0135  max mem: 17061
2023-02-27 10:15:46,421	INFO	torchdistill.misc.log	Epoch: [22]  [ 4000/14658]  eta: 0:28:12  lr: 0.0002  img/s: 53.55684096277852  loss: 0.7305 (0.7741)  time: 0.1613  data: 0.0144  max mem: 17061
2023-02-27 10:18:25,164	INFO	torchdistill.misc.log	Epoch: [22]  [ 5000/14658]  eta: 0:25:33  lr: 0.0002  img/s: 59.031262204926655  loss: 0.7017 (0.7747)  time: 0.1576  data: 0.0133  max mem: 17061
2023-02-27 10:21:04,377	INFO	torchdistill.misc.log	Epoch: [22]  [ 6000/14658]  eta: 0:22:55  lr: 0.0002  img/s: 53.48027229099626  loss: 0.7857 (0.7757)  time: 0.1604  data: 0.0142  max mem: 17061
2023-02-27 10:23:43,378	INFO	torchdistill.misc.log	Epoch: [22]  [ 7000/14658]  eta: 0:20:16  lr: 0.0002  img/s: 61.339738878956396  loss: 0.8192 (0.7757)  time: 0.1595  data: 0.0138  max mem: 17061
2023-02-27 10:26:22,332	INFO	torchdistill.misc.log	Epoch: [22]  [ 8000/14658]  eta: 0:17:37  lr: 0.0002  img/s: 58.70274790543721  loss: 0.7824 (0.7765)  time: 0.1575  data: 0.0131  max mem: 17061
2023-02-27 10:29:00,991	INFO	torchdistill.misc.log	Epoch: [22]  [ 9000/14658]  eta: 0:14:58  lr: 0.0002  img/s: 56.98530975194709  loss: 0.8477 (0.7753)  time: 0.1585  data: 0.0139  max mem: 17061
2023-02-27 10:31:40,015	INFO	torchdistill.misc.log	Epoch: [22]  [10000/14658]  eta: 0:12:20  lr: 0.0002  img/s: 67.17482968274845  loss: 0.7152 (0.7750)  time: 0.1587  data: 0.0136  max mem: 17061
2023-02-27 10:34:18,847	INFO	torchdistill.misc.log	Epoch: [22]  [11000/14658]  eta: 0:09:41  lr: 0.0002  img/s: 55.86046550343526  loss: 0.6938 (0.7751)  time: 0.1584  data: 0.0135  max mem: 17061
2023-02-27 10:36:57,620	INFO	torchdistill.misc.log	Epoch: [22]  [12000/14658]  eta: 0:07:02  lr: 0.0002  img/s: 58.81201745022672  loss: 0.7813 (0.7753)  time: 0.1585  data: 0.0139  max mem: 17061
2023-02-27 10:39:36,698	INFO	torchdistill.misc.log	Epoch: [22]  [13000/14658]  eta: 0:04:23  lr: 0.0002  img/s: 59.335445903123585  loss: 0.7260 (0.7754)  time: 0.1581  data: 0.0133  max mem: 17061
2023-02-27 10:42:15,613	INFO	torchdistill.misc.log	Epoch: [22]  [14000/14658]  eta: 0:01:44  lr: 0.0002  img/s: 57.809410921520524  loss: 0.7855 (0.7747)  time: 0.1573  data: 0.0134  max mem: 17061
2023-02-27 10:44:00,222	INFO	torchdistill.misc.log	Epoch: [22] Total time: 0:38:49
2023-02-27 10:44:04,765	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 1:03:16  model_time: 0.1157 (0.1157)  evaluator_time: 0.0485 (0.0485)  time: 0.7592  data: 0.5931  max mem: 17061
2023-02-27 10:45:48,597	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:06:57  model_time: 0.0857 (0.0873)  evaluator_time: 0.0075 (0.0158)  time: 0.0997  data: 0.0001  max mem: 17061
2023-02-27 10:47:32,749	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:12  model_time: 0.0847 (0.0871)  evaluator_time: 0.0101 (0.0161)  time: 0.1025  data: 0.0001  max mem: 17061
2023-02-27 10:49:18,907	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:29  model_time: 0.0850 (0.0871)  evaluator_time: 0.0088 (0.0168)  time: 0.1004  data: 0.0001  max mem: 17061
2023-02-27 10:51:02,106	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:44  model_time: 0.0870 (0.0871)  evaluator_time: 0.0087 (0.0165)  time: 0.1010  data: 0.0001  max mem: 17061
2023-02-27 10:52:44,830	INFO	torchdistill.misc.log	Validation: Total time: 0:08:40
2023-02-27 10:52:44,831	INFO	__main__	Averaged stats: model_time: 0.0835 (0.0870)  evaluator_time: 0.0102 (0.0162)
2023-02-27 10:52:45,022	INFO	__main__	Accumulating evaluation results...
2023-02-27 10:52:59,452	INFO	__main__	DONE (t=14.43s).
2023-02-27 10:52:59,453	INFO	__main__	IoU metric: bbox
2023-02-27 10:52:59,454	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.246
2023-02-27 10:52:59,454	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.427
2023-02-27 10:52:59,454	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.248
2023-02-27 10:52:59,455	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.089
2023-02-27 10:52:59,456	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.260
2023-02-27 10:52:59,456	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.395
2023-02-27 10:52:59,456	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.240
2023-02-27 10:52:59,457	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.366
2023-02-27 10:52:59,457	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.385
2023-02-27 10:52:59,457	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.152
2023-02-27 10:52:59,457	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.426
2023-02-27 10:52:59,457	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.595
2023-02-27 10:53:00,255	INFO	__main__	Best mAP (bbox): 0.2433 -> 0.2458
2023-02-27 10:53:00,257	INFO	__main__	Updating ckpt at ./resource/ckpt/coco2017/supervised_compression/entropic_student/coco2017-faster_rcnn_splittable_resnet50-fp-beta0.32_fpn.pt
2023-02-27 10:53:01,761	INFO	torchdistill.misc.log	Epoch: [23]  [    0/14658]  eta: 3:22:31  lr: 0.0002  img/s: 51.87944531113506  loss: 0.6326 (0.6326)  time: 0.8290  data: 0.6657  max mem: 17061
2023-02-27 10:55:38,992	INFO	torchdistill.misc.log	Epoch: [23]  [ 1000/14658]  eta: 0:35:56  lr: 0.0002  img/s: 58.749101808988215  loss: 0.7624 (0.7785)  time: 0.1584  data: 0.0128  max mem: 17061
2023-02-27 10:58:17,580	INFO	torchdistill.misc.log	Epoch: [23]  [ 2000/14658]  eta: 0:33:23  lr: 0.0002  img/s: 59.70666989330733  loss: 0.7773 (0.7782)  time: 0.1586  data: 0.0126  max mem: 17061
2023-02-27 11:00:56,293	INFO	torchdistill.misc.log	Epoch: [23]  [ 3000/14658]  eta: 0:30:46  lr: 0.0002  img/s: 60.292658384334246  loss: 0.8082 (0.7756)  time: 0.1591  data: 0.0138  max mem: 17061
2023-02-27 11:03:35,272	INFO	torchdistill.misc.log	Epoch: [23]  [ 4000/14658]  eta: 0:28:09  lr: 0.0002  img/s: 58.17453522865381  loss: 0.7753 (0.7735)  time: 0.1579  data: 0.0128  max mem: 17061
2023-02-27 11:06:14,083	INFO	torchdistill.misc.log	Epoch: [23]  [ 5000/14658]  eta: 0:25:31  lr: 0.0002  img/s: 52.31893024648239  loss: 0.6693 (0.7747)  time: 0.1606  data: 0.0131  max mem: 17061
2023-02-27 11:08:52,710	INFO	torchdistill.misc.log	Epoch: [23]  [ 6000/14658]  eta: 0:22:53  lr: 0.0002  img/s: 60.28031043403277  loss: 0.7552 (0.7742)  time: 0.1576  data: 0.0126  max mem: 17061
2023-02-27 11:11:31,464	INFO	torchdistill.misc.log	Epoch: [23]  [ 7000/14658]  eta: 0:20:14  lr: 0.0002  img/s: 58.70408302512658  loss: 0.8021 (0.7728)  time: 0.1595  data: 0.0129  max mem: 17061
2023-02-27 11:14:10,161	INFO	torchdistill.misc.log	Epoch: [23]  [ 8000/14658]  eta: 0:17:36  lr: 0.0002  img/s: 59.04310369098229  loss: 0.7506 (0.7736)  time: 0.1584  data: 0.0127  max mem: 17061
2023-02-27 11:16:48,640	INFO	torchdistill.misc.log	Epoch: [23]  [ 9000/14658]  eta: 0:14:57  lr: 0.0002  img/s: 53.85667509855031  loss: 0.6415 (0.7735)  time: 0.1557  data: 0.0120  max mem: 17061
2023-02-27 11:19:27,031	INFO	torchdistill.misc.log	Epoch: [23]  [10000/14658]  eta: 0:12:18  lr: 0.0002  img/s: 59.97528379487051  loss: 0.7326 (0.7736)  time: 0.1584  data: 0.0129  max mem: 17061
2023-02-27 11:22:05,333	INFO	torchdistill.misc.log	Epoch: [23]  [11000/14658]  eta: 0:09:40  lr: 0.0002  img/s: 59.28617215631814  loss: 0.7070 (0.7733)  time: 0.1567  data: 0.0130  max mem: 17061
2023-02-27 11:24:43,829	INFO	torchdistill.misc.log	Epoch: [23]  [12000/14658]  eta: 0:07:01  lr: 0.0002  img/s: 59.88526392438499  loss: 0.7470 (0.7730)  time: 0.1562  data: 0.0124  max mem: 17061
2023-02-27 11:27:22,339	INFO	torchdistill.misc.log	Epoch: [23]  [13000/14658]  eta: 0:04:22  lr: 0.0002  img/s: 60.118522659270646  loss: 0.6467 (0.7732)  time: 0.1585  data: 0.0132  max mem: 17061
2023-02-27 11:30:01,066	INFO	torchdistill.misc.log	Epoch: [23]  [14000/14658]  eta: 0:01:44  lr: 0.0002  img/s: 59.59024376383004  loss: 0.7028 (0.7732)  time: 0.1587  data: 0.0129  max mem: 17061
2023-02-27 11:31:45,502	INFO	torchdistill.misc.log	Epoch: [23] Total time: 0:38:44
2023-02-27 11:31:49,569	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 1:01:12  model_time: 0.1076 (0.1076)  evaluator_time: 0.0297 (0.0297)  time: 0.7345  data: 0.5954  max mem: 17061
2023-02-27 11:33:33,931	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:06:59  model_time: 0.0855 (0.0877)  evaluator_time: 0.0083 (0.0159)  time: 0.0997  data: 0.0001  max mem: 17061
2023-02-27 11:35:18,148	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:13  model_time: 0.0877 (0.0873)  evaluator_time: 0.0093 (0.0162)  time: 0.1004  data: 0.0001  max mem: 17061
2023-02-27 11:37:01,062	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:28  model_time: 0.0852 (0.0871)  evaluator_time: 0.0099 (0.0159)  time: 0.1003  data: 0.0001  max mem: 17061
2023-02-27 11:38:46,875	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:44  model_time: 0.0869 (0.0870)  evaluator_time: 0.0092 (0.0166)  time: 0.1044  data: 0.0001  max mem: 17061
2023-02-27 11:40:29,517	INFO	torchdistill.misc.log	Validation: Total time: 0:08:40
2023-02-27 11:40:29,517	INFO	__main__	Averaged stats: model_time: 0.0832 (0.0869)  evaluator_time: 0.0092 (0.0163)
2023-02-27 11:40:29,683	INFO	__main__	Accumulating evaluation results...
2023-02-27 11:40:44,273	INFO	__main__	DONE (t=14.59s).
2023-02-27 11:40:44,274	INFO	__main__	IoU metric: bbox
2023-02-27 11:40:44,275	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.247
2023-02-27 11:40:44,275	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.428
2023-02-27 11:40:44,275	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.252
2023-02-27 11:40:44,276	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.088
2023-02-27 11:40:44,277	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.263
2023-02-27 11:40:44,277	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.397
2023-02-27 11:40:44,278	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.240
2023-02-27 11:40:44,278	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.369
2023-02-27 11:40:44,278	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.387
2023-02-27 11:40:44,278	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.153
2023-02-27 11:40:44,278	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.430
2023-02-27 11:40:44,278	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.596
2023-02-27 11:40:44,983	INFO	__main__	Best mAP (bbox): 0.2458 -> 0.2470
2023-02-27 11:40:44,985	INFO	__main__	Updating ckpt at ./resource/ckpt/coco2017/supervised_compression/entropic_student/coco2017-faster_rcnn_splittable_resnet50-fp-beta0.32_fpn.pt
2023-02-27 11:40:46,427	INFO	torchdistill.misc.log	Epoch: [24]  [    0/14658]  eta: 3:41:07  lr: 0.0002  img/s: 52.5546025799257  loss: 0.9285 (0.9285)  time: 0.9051  data: 0.7385  max mem: 17061
2023-02-27 11:43:24,098	INFO	torchdistill.misc.log	Epoch: [24]  [ 1000/14658]  eta: 0:36:03  lr: 0.0002  img/s: 59.567287942723546  loss: 0.7585 (0.7732)  time: 0.1615  data: 0.0137  max mem: 17061
2023-02-27 11:46:02,767	INFO	torchdistill.misc.log	Epoch: [24]  [ 2000/14658]  eta: 0:33:26  lr: 0.0002  img/s: 58.9691204304968  loss: 0.7499 (0.7810)  time: 0.1589  data: 0.0132  max mem: 17061
2023-02-27 11:48:41,313	INFO	torchdistill.misc.log	Epoch: [24]  [ 3000/14658]  eta: 0:30:48  lr: 0.0002  img/s: 59.30597665190841  loss: 0.6263 (0.7774)  time: 0.1570  data: 0.0123  max mem: 17061
2023-02-27 11:51:19,933	INFO	torchdistill.misc.log	Epoch: [24]  [ 4000/14658]  eta: 0:28:09  lr: 0.0002  img/s: 53.22551949493988  loss: 0.7884 (0.7772)  time: 0.1598  data: 0.0133  max mem: 17061
2023-02-27 11:53:58,784	INFO	torchdistill.misc.log	Epoch: [24]  [ 5000/14658]  eta: 0:25:31  lr: 0.0002  img/s: 60.05890902321852  loss: 0.7504 (0.7758)  time: 0.1583  data: 0.0132  max mem: 17061
2023-02-27 11:56:37,564	INFO	torchdistill.misc.log	Epoch: [24]  [ 6000/14658]  eta: 0:22:53  lr: 0.0002  img/s: 64.99270163477183  loss: 0.7823 (0.7762)  time: 0.1597  data: 0.0136  max mem: 17061
2023-02-27 11:59:16,311	INFO	torchdistill.misc.log	Epoch: [24]  [ 7000/14658]  eta: 0:20:14  lr: 0.0002  img/s: 59.40824806882302  loss: 0.6693 (0.7741)  time: 0.1591  data: 0.0133  max mem: 17061
2023-02-27 12:01:55,013	INFO	torchdistill.misc.log	Epoch: [24]  [ 8000/14658]  eta: 0:17:36  lr: 0.0002  img/s: 59.5116116559956  loss: 0.7932 (0.7738)  time: 0.1611  data: 0.0141  max mem: 17061
2023-02-27 12:04:33,531	INFO	torchdistill.misc.log	Epoch: [24]  [ 9000/14658]  eta: 0:14:57  lr: 0.0002  img/s: 58.63934835910153  loss: 0.7617 (0.7731)  time: 0.1585  data: 0.0130  max mem: 17061
2023-02-27 12:07:12,137	INFO	torchdistill.misc.log	Epoch: [24]  [10000/14658]  eta: 0:12:18  lr: 0.0002  img/s: 63.692040780300026  loss: 0.7118 (0.7722)  time: 0.1587  data: 0.0127  max mem: 17061
2023-02-27 12:09:51,876	INFO	torchdistill.misc.log	Epoch: [24]  [11000/14658]  eta: 0:09:40  lr: 0.0002  img/s: 52.49113322069958  loss: 0.6732 (0.7715)  time: 0.1596  data: 0.0125  max mem: 17061
2023-02-27 12:12:31,518	INFO	torchdistill.misc.log	Epoch: [24]  [12000/14658]  eta: 0:07:02  lr: 0.0002  img/s: 60.37358667098492  loss: 0.8046 (0.7715)  time: 0.1567  data: 0.0128  max mem: 17061
2023-02-27 12:15:09,207	INFO	torchdistill.misc.log	Epoch: [24]  [13000/14658]  eta: 0:04:23  lr: 0.0002  img/s: 59.68256272066736  loss: 0.7097 (0.7707)  time: 0.1571  data: 0.0125  max mem: 17061
2023-02-27 12:17:47,950	INFO	torchdistill.misc.log	Epoch: [24]  [14000/14658]  eta: 0:01:44  lr: 0.0002  img/s: 60.85216599656516  loss: 0.8083 (0.7716)  time: 0.1595  data: 0.0132  max mem: 17061
2023-02-27 12:19:32,576	INFO	torchdistill.misc.log	Epoch: [24] Total time: 0:38:47
2023-02-27 12:19:36,801	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 1:06:02  model_time: 0.1267 (0.1267)  evaluator_time: 0.0331 (0.0331)  time: 0.7925  data: 0.6311  max mem: 17061
2023-02-27 12:21:21,344	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:07:00  model_time: 0.0843 (0.0876)  evaluator_time: 0.0082 (0.0162)  time: 0.1001  data: 0.0001  max mem: 17061
2023-02-27 12:23:06,233	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:15  model_time: 0.0854 (0.0875)  evaluator_time: 0.0102 (0.0164)  time: 0.1018  data: 0.0001  max mem: 17061
2023-02-27 12:24:49,773	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:29  model_time: 0.0878 (0.0873)  evaluator_time: 0.0101 (0.0162)  time: 0.1025  data: 0.0001  max mem: 17061
2023-02-27 12:26:33,836	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:44  model_time: 0.0894 (0.0873)  evaluator_time: 0.0095 (0.0162)  time: 0.1053  data: 0.0001  max mem: 17061
2023-02-27 12:28:16,781	INFO	torchdistill.misc.log	Validation: Total time: 0:08:40
2023-02-27 12:28:16,782	INFO	__main__	Averaged stats: model_time: 0.0829 (0.0872)  evaluator_time: 0.0095 (0.0160)
2023-02-27 12:28:16,959	INFO	__main__	Accumulating evaluation results...
2023-02-27 12:28:34,597	INFO	__main__	DONE (t=17.64s).
2023-02-27 12:28:34,598	INFO	__main__	IoU metric: bbox
2023-02-27 12:28:34,599	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.246
2023-02-27 12:28:34,599	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.427
2023-02-27 12:28:34,599	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.248
2023-02-27 12:28:34,600	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.088
2023-02-27 12:28:34,601	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.260
2023-02-27 12:28:34,601	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.397
2023-02-27 12:28:34,602	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.240
2023-02-27 12:28:34,602	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.369
2023-02-27 12:28:34,602	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.387
2023-02-27 12:28:34,602	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.151
2023-02-27 12:28:34,602	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.429
2023-02-27 12:28:34,602	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.600
2023-02-27 12:28:36,701	INFO	torchdistill.misc.log	Epoch: [25]  [    0/14658]  eta: 5:42:36  lr: 0.0002  img/s: 56.38992812284154  loss: 0.7772 (0.7772)  time: 1.4024  data: 1.2351  max mem: 17061
2023-02-27 12:31:12,986	INFO	torchdistill.misc.log	Epoch: [25]  [ 1000/14658]  eta: 0:35:51  lr: 0.0002  img/s: 53.831359242770624  loss: 0.7997 (0.7784)  time: 0.1553  data: 0.0117  max mem: 17061
2023-02-27 12:33:50,477	INFO	torchdistill.misc.log	Epoch: [25]  [ 2000/14658]  eta: 0:33:13  lr: 0.0002  img/s: 56.96199583409018  loss: 0.8470 (0.7808)  time: 0.1590  data: 0.0131  max mem: 17061
2023-02-27 12:36:29,228	INFO	torchdistill.misc.log	Epoch: [25]  [ 3000/14658]  eta: 0:30:41  lr: 0.0002  img/s: 53.49374341380514  loss: 0.7718 (0.7794)  time: 0.1587  data: 0.0130  max mem: 17061
2023-02-27 12:39:07,526	INFO	torchdistill.misc.log	Epoch: [25]  [ 4000/14658]  eta: 0:28:04  lr: 0.0002  img/s: 59.5806149753985  loss: 0.7472 (0.7786)  time: 0.1577  data: 0.0129  max mem: 17061
2023-02-27 12:41:45,956	INFO	torchdistill.misc.log	Epoch: [25]  [ 5000/14658]  eta: 0:25:26  lr: 0.0002  img/s: 57.819471990984454  loss: 0.8416 (0.7777)  time: 0.1598  data: 0.0140  max mem: 17061
2023-02-27 12:44:24,173	INFO	torchdistill.misc.log	Epoch: [25]  [ 6000/14658]  eta: 0:22:48  lr: 0.0002  img/s: 61.96422246557331  loss: 0.6213 (0.7769)  time: 0.1570  data: 0.0122  max mem: 17061
2023-02-27 12:47:02,981	INFO	torchdistill.misc.log	Epoch: [25]  [ 7000/14658]  eta: 0:20:11  lr: 0.0002  img/s: 67.1911059136383  loss: 0.8469 (0.7757)  time: 0.1585  data: 0.0137  max mem: 17061
2023-02-27 12:49:41,078	INFO	torchdistill.misc.log	Epoch: [25]  [ 8000/14658]  eta: 0:17:33  lr: 0.0002  img/s: 53.458034214995585  loss: 0.8315 (0.7753)  time: 0.1585  data: 0.0128  max mem: 17061
2023-02-27 12:52:19,383	INFO	torchdistill.misc.log	Epoch: [25]  [ 9000/14658]  eta: 0:14:55  lr: 0.0002  img/s: 62.864268585131896  loss: 0.7525 (0.7748)  time: 0.1576  data: 0.0125  max mem: 17061
2023-02-27 12:54:57,704	INFO	torchdistill.misc.log	Epoch: [25]  [10000/14658]  eta: 0:12:16  lr: 0.0002  img/s: 60.07277961483306  loss: 0.6252 (0.7734)  time: 0.1587  data: 0.0132  max mem: 17061
2023-02-27 12:57:35,937	INFO	torchdistill.misc.log	Epoch: [25]  [11000/14658]  eta: 0:09:38  lr: 0.0002  img/s: 60.22750965666777  loss: 0.7432 (0.7727)  time: 0.1576  data: 0.0131  max mem: 17061
2023-02-27 13:00:14,430	INFO	torchdistill.misc.log	Epoch: [25]  [12000/14658]  eta: 0:07:00  lr: 0.0002  img/s: 59.857274864692265  loss: 0.6719 (0.7729)  time: 0.1567  data: 0.0123  max mem: 17061
2023-02-27 13:02:53,060	INFO	torchdistill.misc.log	Epoch: [25]  [13000/14658]  eta: 0:04:22  lr: 0.0002  img/s: 62.16373859478487  loss: 0.8357 (0.7732)  time: 0.1577  data: 0.0131  max mem: 17061
2023-02-27 13:05:31,513	INFO	torchdistill.misc.log	Epoch: [25]  [14000/14658]  eta: 0:01:44  lr: 0.0002  img/s: 58.2830601947144  loss: 0.6527 (0.7725)  time: 0.1580  data: 0.0126  max mem: 17061
2023-02-27 13:07:15,851	INFO	torchdistill.misc.log	Epoch: [25] Total time: 0:38:40
2023-02-27 13:07:19,876	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 1:01:00  model_time: 0.1275 (0.1275)  evaluator_time: 0.0301 (0.0301)  time: 0.7321  data: 0.5719  max mem: 17061
2023-02-27 13:09:04,476	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:07:00  model_time: 0.0846 (0.0879)  evaluator_time: 0.0083 (0.0159)  time: 0.1020  data: 0.0001  max mem: 17061
2023-02-27 13:10:48,744	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:14  model_time: 0.0880 (0.0875)  evaluator_time: 0.0098 (0.0161)  time: 0.1029  data: 0.0001  max mem: 17061
2023-02-27 13:12:32,221	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:28  model_time: 0.0869 (0.0874)  evaluator_time: 0.0090 (0.0159)  time: 0.1027  data: 0.0001  max mem: 17061
2023-02-27 13:14:15,403	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:44  model_time: 0.0859 (0.0872)  evaluator_time: 0.0090 (0.0159)  time: 0.1009  data: 0.0001  max mem: 17061
2023-02-27 13:15:57,952	INFO	torchdistill.misc.log	Validation: Total time: 0:08:38
2023-02-27 13:15:57,953	INFO	__main__	Averaged stats: model_time: 0.0841 (0.0871)  evaluator_time: 0.0088 (0.0157)
2023-02-27 13:15:58,128	INFO	__main__	Accumulating evaluation results...
2023-02-27 13:16:12,701	INFO	__main__	DONE (t=14.57s).
2023-02-27 13:16:12,701	INFO	__main__	IoU metric: bbox
2023-02-27 13:16:12,702	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.246
2023-02-27 13:16:12,703	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.428
2023-02-27 13:16:12,703	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.248
2023-02-27 13:16:12,704	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.087
2023-02-27 13:16:12,704	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.262
2023-02-27 13:16:12,705	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.401
2023-02-27 13:16:12,705	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.241
2023-02-27 13:16:12,705	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.368
2023-02-27 13:16:12,705	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.386
2023-02-27 13:16:12,705	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.147
2023-02-27 13:16:12,706	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.427
2023-02-27 13:16:12,706	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.600
2023-02-27 13:16:13,451	INFO	__main__	Training time 20:40:58
2023-02-27 13:16:14,280	INFO	torchdistill.common.main_util	Loading model parameters
2023-02-27 13:16:14,346	INFO	__main__	[Student: faster_rcnn_model]
2023-02-27 13:16:18,804	INFO	torchdistill.misc.log	Test:  [   0/5000]  eta: 1:40:52  model_time: 0.1305 (0.1305)  evaluator_time: 0.0256 (0.0256)  time: 1.2105  data: 1.0524  max mem: 17061
2023-02-27 13:18:04,475	INFO	torchdistill.misc.log	Test:  [1000/5000]  eta: 0:07:07  model_time: 0.0858 (0.0874)  evaluator_time: 0.0080 (0.0175)  time: 0.1006  data: 0.0001  max mem: 17061
2023-02-27 13:19:47,913	INFO	torchdistill.misc.log	Test:  [2000/5000]  eta: 0:05:15  model_time: 0.0846 (0.0871)  evaluator_time: 0.0088 (0.0167)  time: 0.0965  data: 0.0001  max mem: 17061
2023-02-27 13:21:30,118	INFO	torchdistill.misc.log	Test:  [3000/5000]  eta: 0:03:28  model_time: 0.0871 (0.0869)  evaluator_time: 0.0085 (0.0161)  time: 0.1018  data: 0.0001  max mem: 17061
2023-02-27 13:23:13,111	INFO	torchdistill.misc.log	Test:  [4000/5000]  eta: 0:01:43  model_time: 0.0851 (0.0869)  evaluator_time: 0.0089 (0.0159)  time: 0.1037  data: 0.0001  max mem: 17061
2023-02-27 13:24:55,660	INFO	torchdistill.misc.log	Test: Total time: 0:08:38
2023-02-27 13:24:55,661	INFO	__main__	Averaged stats: model_time: 0.0830 (0.0869)  evaluator_time: 0.0090 (0.0157)
2023-02-27 13:24:55,859	INFO	__main__	Accumulating evaluation results...
2023-02-27 13:25:10,017	INFO	__main__	DONE (t=14.16s).
2023-02-27 13:25:10,018	INFO	__main__	IoU metric: bbox
2023-02-27 13:25:10,019	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.247
2023-02-27 13:25:10,019	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.428
2023-02-27 13:25:10,019	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.252
2023-02-27 13:25:10,020	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.088
2023-02-27 13:25:10,021	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.263
2023-02-27 13:25:10,022	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.397
2023-02-27 13:25:10,022	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.240
2023-02-27 13:25:10,022	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.369
2023-02-27 13:25:10,022	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.387
2023-02-27 13:25:10,022	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.153
2023-02-27 13:25:10,022	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.430
2023-02-27 13:25:10,022	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.596
2023-02-27 13:25:10,024	INFO	sc2bench.analysis	Bottleneck size [KB]: mean 65.51440625 std 8.558312894936448 for 5000 samples
