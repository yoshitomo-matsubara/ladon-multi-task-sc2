2023-02-28 10:10:01,357	INFO	torchdistill.common.main_util	Not using distributed mode
2023-02-28 10:10:01,357	INFO	__main__	Namespace(adjust_lr=False, config='configs/coco2017/proposed/faster_rcnn_splittable_resnet50-fp-beta5.12_fpn.yaml', device='cuda', dist_url='env://', iou_types=None, json=None, log='logs/coco2017/proposed/faster_rcnn_splittable_resnet50-fp-beta5.12.txt', log_config=False, no_dp_eval=False, seed=None, start_epoch=0, student_only=False, test_only=False, world_size=1)
2023-02-28 10:10:25,854	INFO	torchdistill.common.main_util	Loading model parameters
2023-02-28 10:10:26,147	INFO	torchdistill.common.main_util	ckpt file is not found at `./resource/ckpt/coco2017/supervised_compression/entropic_student/coco2017-faster_rcnn_splittable_resnet50-fp-beta5.12_fpn.pt`
2023-02-28 10:10:32,455	INFO	__main__	Start training
2023-02-28 10:10:32,687	INFO	torchdistill.datasets.sampler	Using [0, 0.5, 0.6299605249474366, 0.7937005259840997, 1.0, 1.2599210498948732, 1.5874010519681994, 2.0, inf] as bins for aspect ratio quantization
2023-02-28 10:10:32,687	INFO	torchdistill.datasets.sampler	Count of instances per bin: [  104   982 24236  2332  8225 74466  5763  1158]
2023-02-28 10:10:32,690	INFO	torchdistill.models.util	[student model]
2023-02-28 10:10:32,690	INFO	torchdistill.models.util	Using the original student model
2023-02-28 10:10:32,690	INFO	torchdistill.models.util	Frozen module(s): {'backbone.body'}
2023-02-28 10:10:32,691	INFO	torchdistill.core.training	Loss = 1.0 * OrgLoss
2023-02-28 10:10:32,700	INFO	__main__	Updating entropy bottleneck
2023-02-28 10:10:34,832	INFO	torchdistill.misc.log	Epoch: [0]  [    0/14658]  eta: 8:38:52  lr: 0.02  img/s: 7.622365860672924  loss: 5.6206 (5.6206)  time: 2.1240  data: 1.0639  max mem: 9330
2023-02-28 10:13:18,803	INFO	torchdistill.misc.log	Epoch: [0]  [ 1000/14658]  eta: 0:37:46  lr: 0.02  img/s: 60.16142288521533  loss: 1.1967 (1.2742)  time: 0.1560  data: 0.0115  max mem: 9585
2023-02-28 10:15:54,867	INFO	torchdistill.misc.log	Epoch: [0]  [ 2000/14658]  eta: 0:33:57  lr: 0.02  img/s: 60.55270186380239  loss: 1.1004 (1.2213)  time: 0.1552  data: 0.0119  max mem: 9585
2023-02-28 10:18:31,518	INFO	torchdistill.misc.log	Epoch: [0]  [ 3000/14658]  eta: 0:30:59  lr: 0.02  img/s: 57.545197454282906  loss: 0.9484 (1.1855)  time: 0.1551  data: 0.0124  max mem: 9585
2023-02-28 10:21:07,809	INFO	torchdistill.misc.log	Epoch: [0]  [ 4000/14658]  eta: 0:28:11  lr: 0.02  img/s: 60.469658332987926  loss: 1.0594 (1.1588)  time: 0.1552  data: 0.0121  max mem: 9585
2023-02-28 10:23:44,569	INFO	torchdistill.misc.log	Epoch: [0]  [ 5000/14658]  eta: 0:25:29  lr: 0.02  img/s: 60.11701472000458  loss: 0.9555 (1.1391)  time: 0.1559  data: 0.0124  max mem: 9585
2023-02-28 10:26:21,396	INFO	torchdistill.misc.log	Epoch: [0]  [ 6000/14658]  eta: 0:22:48  lr: 0.02  img/s: 59.28166821844574  loss: 0.9941 (1.1237)  time: 0.1572  data: 0.0127  max mem: 9585
2023-02-28 10:28:57,869	INFO	torchdistill.misc.log	Epoch: [0]  [ 7000/14658]  eta: 0:20:08  lr: 0.02  img/s: 59.09291066789944  loss: 1.0356 (1.1104)  time: 0.1568  data: 0.0128  max mem: 9585
2023-02-28 10:31:34,669	INFO	torchdistill.misc.log	Epoch: [0]  [ 8000/14658]  eta: 0:17:30  lr: 0.02  img/s: 60.30056806235208  loss: 1.0790 (1.1009)  time: 0.1557  data: 0.0128  max mem: 9585
2023-02-28 10:34:11,502	INFO	torchdistill.misc.log	Epoch: [0]  [ 9000/14658]  eta: 0:14:51  lr: 0.02  img/s: 60.56374055790699  loss: 0.9303 (1.0908)  time: 0.1551  data: 0.0121  max mem: 9585
2023-02-28 10:36:48,213	INFO	torchdistill.misc.log	Epoch: [0]  [10000/14658]  eta: 0:12:13  lr: 0.02  img/s: 60.52550483869513  loss: 0.9701 (1.0826)  time: 0.1577  data: 0.0135  max mem: 9585
2023-02-28 10:39:24,770	INFO	torchdistill.misc.log	Epoch: [0]  [11000/14658]  eta: 0:09:35  lr: 0.02  img/s: 60.136839388638776  loss: 0.8057 (1.0733)  time: 0.1572  data: 0.0125  max mem: 9585
2023-02-28 10:42:01,786	INFO	torchdistill.misc.log	Epoch: [0]  [12000/14658]  eta: 0:06:58  lr: 0.02  img/s: 59.48892730189967  loss: 0.8447 (1.0667)  time: 0.1568  data: 0.0126  max mem: 9585
2023-02-28 10:44:38,568	INFO	torchdistill.misc.log	Epoch: [0]  [13000/14658]  eta: 0:04:20  lr: 0.02  img/s: 60.48175692969902  loss: 0.8644 (1.0599)  time: 0.1563  data: 0.0129  max mem: 9585
2023-02-28 10:47:15,405	INFO	torchdistill.misc.log	Epoch: [0]  [14000/14658]  eta: 0:01:43  lr: 0.02  img/s: 60.57150284133987  loss: 0.9877 (1.0561)  time: 0.1575  data: 0.0129  max mem: 9585
2023-02-28 10:48:58,668	INFO	torchdistill.misc.log	Epoch: [0] Total time: 0:38:25
2023-02-28 10:49:06,199	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 2:17:21  model_time: 1.1201 (1.1201)  evaluator_time: 0.0220 (0.0220)  time: 1.6483  data: 0.5008  max mem: 17050
2023-02-28 10:50:59,473	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:07:39  model_time: 0.0839 (0.0980)  evaluator_time: 0.0081 (0.0155)  time: 0.0976  data: 0.0001  max mem: 17059
2023-02-28 10:52:40,693	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:24  model_time: 0.0789 (0.0909)  evaluator_time: 0.0098 (0.0161)  time: 0.0939  data: 0.0002  max mem: 17059
2023-02-28 10:54:20,111	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:30  model_time: 0.0839 (0.0883)  evaluator_time: 0.0088 (0.0158)  time: 0.0980  data: 0.0001  max mem: 17059
2023-02-28 10:55:58,884	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:43  model_time: 0.0828 (0.0869)  evaluator_time: 0.0091 (0.0157)  time: 0.0992  data: 0.0001  max mem: 17059
2023-02-28 10:57:39,619	INFO	torchdistill.misc.log	Validation: Total time: 0:08:35
2023-02-28 10:57:39,620	INFO	__main__	Averaged stats: model_time: 0.0785 (0.0860)  evaluator_time: 0.0099 (0.0161)
2023-02-28 10:57:39,868	INFO	__main__	Accumulating evaluation results...
2023-02-28 10:57:54,769	INFO	__main__	DONE (t=14.90s).
2023-02-28 10:57:54,770	INFO	__main__	IoU metric: bbox
2023-02-28 10:57:54,770	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.133
2023-02-28 10:57:54,771	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.282
2023-02-28 10:57:54,771	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.109
2023-02-28 10:57:54,772	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.028
2023-02-28 10:57:54,773	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.138
2023-02-28 10:57:54,773	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.231
2023-02-28 10:57:54,774	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.156
2023-02-28 10:57:54,774	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.244
2023-02-28 10:57:54,774	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.255
2023-02-28 10:57:54,774	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.060
2023-02-28 10:57:54,774	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.271
2023-02-28 10:57:54,774	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.423
2023-02-28 10:57:54,775	INFO	__main__	Best mAP (bbox): 0.0000 -> 0.1327
2023-02-28 10:57:54,775	INFO	__main__	Updating ckpt at ./resource/ckpt/coco2017/supervised_compression/entropic_student/coco2017-faster_rcnn_splittable_resnet50-fp-beta5.12_fpn.pt
2023-02-28 10:57:55,892	INFO	torchdistill.misc.log	Epoch: [1]  [    0/14658]  eta: 2:58:56  lr: 0.02  img/s: 53.93510639323867  loss: 0.8399 (0.8399)  time: 0.7325  data: 0.5740  max mem: 17059
2023-02-28 11:00:31,506	INFO	torchdistill.misc.log	Epoch: [1]  [ 1000/14658]  eta: 0:35:33  lr: 0.02  img/s: 60.725299107247885  loss: 1.0076 (0.9823)  time: 0.1560  data: 0.0128  max mem: 17059
2023-02-28 11:03:08,075	INFO	torchdistill.misc.log	Epoch: [1]  [ 2000/14658]  eta: 0:32:59  lr: 0.02  img/s: 59.44782304428322  loss: 0.9146 (0.9779)  time: 0.1581  data: 0.0131  max mem: 17059
2023-02-28 11:05:45,297	INFO	torchdistill.misc.log	Epoch: [1]  [ 3000/14658]  eta: 0:30:26  lr: 0.02  img/s: 60.3209477497236  loss: 0.9108 (0.9691)  time: 0.1563  data: 0.0122  max mem: 17059
2023-02-28 11:08:22,608	INFO	torchdistill.misc.log	Epoch: [1]  [ 4000/14658]  eta: 0:27:51  lr: 0.02  img/s: 60.070628715875706  loss: 0.8586 (0.9674)  time: 0.1574  data: 0.0125  max mem: 17059
2023-02-28 11:10:59,637	INFO	torchdistill.misc.log	Epoch: [1]  [ 5000/14658]  eta: 0:25:14  lr: 0.02  img/s: 58.62756581844104  loss: 0.8597 (0.9647)  time: 0.1581  data: 0.0133  max mem: 17059
2023-02-28 11:13:36,824	INFO	torchdistill.misc.log	Epoch: [1]  [ 6000/14658]  eta: 0:22:38  lr: 0.02  img/s: 59.318033482419075  loss: 0.9373 (0.9621)  time: 0.1580  data: 0.0130  max mem: 17059
2023-02-28 11:16:14,182	INFO	torchdistill.misc.log	Epoch: [1]  [ 7000/14658]  eta: 0:20:02  lr: 0.02  img/s: 60.402060779308684  loss: 0.9994 (0.9638)  time: 0.1556  data: 0.0131  max mem: 17059
2023-02-28 11:18:51,195	INFO	torchdistill.misc.log	Epoch: [1]  [ 8000/14658]  eta: 0:17:25  lr: 0.02  img/s: 53.601329073482425  loss: 0.9220 (0.9626)  time: 0.1606  data: 0.0144  max mem: 17059
2023-02-28 11:21:28,371	INFO	torchdistill.misc.log	Epoch: [1]  [ 9000/14658]  eta: 0:14:48  lr: 0.02  img/s: 60.70706153308957  loss: 0.8823 (0.9616)  time: 0.1583  data: 0.0131  max mem: 17059
2023-02-28 11:24:05,766	INFO	torchdistill.misc.log	Epoch: [1]  [10000/14658]  eta: 0:12:11  lr: 0.02  img/s: 68.11519793428107  loss: 0.8529 (0.9610)  time: 0.1562  data: 0.0133  max mem: 17059
2023-02-28 11:26:43,049	INFO	torchdistill.misc.log	Epoch: [1]  [11000/14658]  eta: 0:09:34  lr: 0.02  img/s: 59.50992292221635  loss: 0.8855 (0.9597)  time: 0.1591  data: 0.0133  max mem: 17059
2023-02-28 11:29:20,538	INFO	torchdistill.misc.log	Epoch: [1]  [12000/14658]  eta: 0:06:57  lr: 0.02  img/s: 59.66346073489274  loss: 0.8962 (0.9596)  time: 0.1575  data: 0.0134  max mem: 17059
2023-02-28 11:31:58,125	INFO	torchdistill.misc.log	Epoch: [1]  [13000/14658]  eta: 0:04:20  lr: 0.02  img/s: 60.095911510384205  loss: 0.8345 (0.9586)  time: 0.1579  data: 0.0121  max mem: 17059
2023-02-28 11:34:35,336	INFO	torchdistill.misc.log	Epoch: [1]  [14000/14658]  eta: 0:01:43  lr: 0.02  img/s: 61.034025385345764  loss: 0.9361 (0.9579)  time: 0.1592  data: 0.0132  max mem: 17059
2023-02-28 11:36:18,861	INFO	torchdistill.misc.log	Epoch: [1] Total time: 0:38:23
2023-02-28 11:36:23,252	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 0:50:34  model_time: 0.0947 (0.0947)  evaluator_time: 0.0257 (0.0257)  time: 0.6068  data: 0.4842  max mem: 17059
2023-02-28 11:38:02,279	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:06:38  model_time: 0.0832 (0.0829)  evaluator_time: 0.0077 (0.0154)  time: 0.0973  data: 0.0001  max mem: 17059
2023-02-28 11:39:41,798	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:04:58  model_time: 0.0792 (0.0828)  evaluator_time: 0.0099 (0.0157)  time: 0.0967  data: 0.0001  max mem: 17059
2023-02-28 11:41:20,214	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:18  model_time: 0.0851 (0.0827)  evaluator_time: 0.0090 (0.0155)  time: 0.0973  data: 0.0001  max mem: 17059
2023-02-28 11:43:01,215	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:39  model_time: 0.0826 (0.0826)  evaluator_time: 0.0090 (0.0161)  time: 0.0994  data: 0.0001  max mem: 17059
2023-02-28 11:44:38,942	INFO	torchdistill.misc.log	Validation: Total time: 0:08:16
2023-02-28 11:44:38,943	INFO	__main__	Averaged stats: model_time: 0.0794 (0.0825)  evaluator_time: 0.0100 (0.0159)
2023-02-28 11:44:39,188	INFO	__main__	Accumulating evaluation results...
2023-02-28 11:44:55,496	INFO	__main__	DONE (t=16.31s).
2023-02-28 11:44:55,496	INFO	__main__	IoU metric: bbox
2023-02-28 11:44:55,498	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.154
2023-02-28 11:44:55,498	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.310
2023-02-28 11:44:55,498	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.136
2023-02-28 11:44:55,499	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.037
2023-02-28 11:44:55,500	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.162
2023-02-28 11:44:55,501	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.267
2023-02-28 11:44:55,501	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.173
2023-02-28 11:44:55,501	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.269
2023-02-28 11:44:55,501	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.281
2023-02-28 11:44:55,501	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.071
2023-02-28 11:44:55,501	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.299
2023-02-28 11:44:55,501	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.476
2023-02-28 11:44:56,280	INFO	__main__	Best mAP (bbox): 0.1327 -> 0.1542
2023-02-28 11:44:56,280	INFO	__main__	Updating ckpt at ./resource/ckpt/coco2017/supervised_compression/entropic_student/coco2017-faster_rcnn_splittable_resnet50-fp-beta5.12_fpn.pt
2023-02-28 11:44:57,594	INFO	torchdistill.misc.log	Epoch: [2]  [    0/14658]  eta: 3:08:06  lr: 0.02  img/s: 53.484449318422364  loss: 0.9024 (0.9024)  time: 0.7700  data: 0.6103  max mem: 17059
2023-02-28 11:47:34,970	INFO	torchdistill.misc.log	Epoch: [2]  [ 1000/14658]  eta: 0:35:57  lr: 0.02  img/s: 59.165014203017634  loss: 0.8064 (0.9239)  time: 0.1569  data: 0.0127  max mem: 17059
2023-02-28 11:50:13,768	INFO	torchdistill.misc.log	Epoch: [2]  [ 2000/14658]  eta: 0:33:24  lr: 0.02  img/s: 59.95138772257698  loss: 0.8894 (0.9325)  time: 0.1559  data: 0.0124  max mem: 17059
2023-02-28 11:52:52,470	INFO	torchdistill.misc.log	Epoch: [2]  [ 3000/14658]  eta: 0:30:47  lr: 0.02  img/s: 59.68351814103727  loss: 0.8964 (0.9378)  time: 0.1559  data: 0.0129  max mem: 17059
2023-02-28 11:55:31,218	INFO	torchdistill.misc.log	Epoch: [2]  [ 4000/14658]  eta: 0:28:09  lr: 0.02  img/s: 60.04268103921853  loss: 1.0014 (0.9379)  time: 0.1609  data: 0.0136  max mem: 17059
2023-02-28 11:58:10,818	INFO	torchdistill.misc.log	Epoch: [2]  [ 5000/14658]  eta: 0:25:33  lr: 0.02  img/s: 60.038491130506976  loss: 0.8621 (0.9368)  time: 0.1608  data: 0.0134  max mem: 17059
2023-02-28 12:00:49,219	INFO	torchdistill.misc.log	Epoch: [2]  [ 6000/14658]  eta: 0:22:54  lr: 0.02  img/s: 60.07159660134557  loss: 0.8715 (0.9359)  time: 0.1587  data: 0.0140  max mem: 17059
2023-02-28 12:03:27,926	INFO	torchdistill.misc.log	Epoch: [2]  [ 7000/14658]  eta: 0:20:15  lr: 0.02  img/s: 60.43709248625711  loss: 0.8880 (0.9347)  time: 0.1548  data: 0.0125  max mem: 17059
2023-02-28 12:06:06,777	INFO	torchdistill.misc.log	Epoch: [2]  [ 8000/14658]  eta: 0:17:36  lr: 0.02  img/s: 53.67652765935664  loss: 0.8213 (0.9348)  time: 0.1597  data: 0.0131  max mem: 17059
2023-02-28 12:08:45,512	INFO	torchdistill.misc.log	Epoch: [2]  [ 9000/14658]  eta: 0:14:58  lr: 0.02  img/s: 60.09268273463496  loss: 0.9213 (0.9337)  time: 0.1601  data: 0.0134  max mem: 17059
2023-02-28 12:11:24,039	INFO	torchdistill.misc.log	Epoch: [2]  [10000/14658]  eta: 0:12:19  lr: 0.02  img/s: 59.91991256955506  loss: 0.8419 (0.9327)  time: 0.1592  data: 0.0133  max mem: 17059
2023-02-28 12:14:02,327	INFO	torchdistill.misc.log	Epoch: [2]  [11000/14658]  eta: 0:09:40  lr: 0.02  img/s: 60.183867473077775  loss: 0.8847 (0.9312)  time: 0.1586  data: 0.0133  max mem: 17059
2023-02-28 12:16:41,249	INFO	torchdistill.misc.log	Epoch: [2]  [12000/14658]  eta: 0:07:01  lr: 0.02  img/s: 59.64246266839438  loss: 0.7599 (0.9312)  time: 0.1578  data: 0.0122  max mem: 17059
2023-02-28 12:19:19,647	INFO	torchdistill.misc.log	Epoch: [2]  [13000/14658]  eta: 0:04:23  lr: 0.02  img/s: 60.35110892880589  loss: 0.8281 (0.9305)  time: 0.1583  data: 0.0134  max mem: 17059
2023-02-28 12:21:58,411	INFO	torchdistill.misc.log	Epoch: [2]  [14000/14658]  eta: 0:01:44  lr: 0.02  img/s: 59.816299972546965  loss: 0.8537 (0.9297)  time: 0.1591  data: 0.0134  max mem: 17059
2023-02-28 12:23:42,777	INFO	torchdistill.misc.log	Epoch: [2] Total time: 0:38:45
2023-02-28 12:23:46,754	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 0:55:45  model_time: 0.1096 (0.1096)  evaluator_time: 0.0287 (0.0287)  time: 0.6691  data: 0.5290  max mem: 17059
2023-02-28 12:25:27,731	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:06:46  model_time: 0.0843 (0.0840)  evaluator_time: 0.0092 (0.0162)  time: 0.0982  data: 0.0001  max mem: 17059
2023-02-28 12:27:08,593	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:03  model_time: 0.0821 (0.0837)  evaluator_time: 0.0102 (0.0164)  time: 0.0976  data: 0.0001  max mem: 17059
2023-02-28 12:28:48,045	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:21  model_time: 0.0821 (0.0836)  evaluator_time: 0.0091 (0.0161)  time: 0.0974  data: 0.0001  max mem: 17059
2023-02-28 12:30:29,736	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:40  model_time: 0.0826 (0.0840)  evaluator_time: 0.0082 (0.0159)  time: 0.0998  data: 0.0001  max mem: 17059
2023-02-28 12:32:07,771	INFO	torchdistill.misc.log	Validation: Total time: 0:08:21
2023-02-28 12:32:07,771	INFO	__main__	Averaged stats: model_time: 0.0795 (0.0837)  evaluator_time: 0.0098 (0.0157)
2023-02-28 12:32:07,999	INFO	__main__	Accumulating evaluation results...
2023-02-28 12:32:23,031	INFO	__main__	DONE (t=15.03s).
2023-02-28 12:32:23,031	INFO	__main__	IoU metric: bbox
2023-02-28 12:32:23,032	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.167
2023-02-28 12:32:23,033	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.326
2023-02-28 12:32:23,033	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.157
2023-02-28 12:32:23,034	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.042
2023-02-28 12:32:23,034	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.170
2023-02-28 12:32:23,035	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.292
2023-02-28 12:32:23,035	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.185
2023-02-28 12:32:23,035	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.287
2023-02-28 12:32:23,035	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.300
2023-02-28 12:32:23,035	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.080
2023-02-28 12:32:23,035	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.331
2023-02-28 12:32:23,035	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.492
2023-02-28 12:32:23,897	INFO	__main__	Best mAP (bbox): 0.1542 -> 0.1673
2023-02-28 12:32:23,898	INFO	__main__	Updating ckpt at ./resource/ckpt/coco2017/supervised_compression/entropic_student/coco2017-faster_rcnn_splittable_resnet50-fp-beta5.12_fpn.pt
2023-02-28 12:32:25,318	INFO	torchdistill.misc.log	Epoch: [3]  [    0/14658]  eta: 3:29:18  lr: 0.02  img/s: 53.791231023261034  loss: 0.9240 (0.9240)  time: 0.8568  data: 0.6961  max mem: 17059
2023-02-28 12:35:02,612	INFO	torchdistill.misc.log	Epoch: [3]  [ 1000/14658]  eta: 0:35:57  lr: 0.02  img/s: 59.87457798905091  loss: 0.7904 (0.9028)  time: 0.1566  data: 0.0131  max mem: 17059
2023-02-28 12:37:40,978	INFO	torchdistill.misc.log	Epoch: [3]  [ 2000/14658]  eta: 0:33:22  lr: 0.02  img/s: 59.840195172755706  loss: 0.7804 (0.9116)  time: 0.1587  data: 0.0135  max mem: 17059
2023-02-28 12:40:19,523	INFO	torchdistill.misc.log	Epoch: [3]  [ 3000/14658]  eta: 0:30:45  lr: 0.02  img/s: 59.411088132808295  loss: 1.0581 (0.9126)  time: 0.1581  data: 0.0134  max mem: 17059
2023-02-28 12:42:57,853	INFO	torchdistill.misc.log	Epoch: [3]  [ 4000/14658]  eta: 0:28:07  lr: 0.02  img/s: 59.863682263065684  loss: 0.8374 (0.9136)  time: 0.1575  data: 0.0130  max mem: 17059
2023-02-28 12:45:36,152	INFO	torchdistill.misc.log	Epoch: [3]  [ 5000/14658]  eta: 0:25:28  lr: 0.02  img/s: 60.11346059102269  loss: 0.8041 (0.9158)  time: 0.1558  data: 0.0127  max mem: 17059
2023-02-28 12:48:13,846	INFO	torchdistill.misc.log	Epoch: [3]  [ 6000/14658]  eta: 0:22:49  lr: 0.02  img/s: 59.90076530748866  loss: 0.8882 (0.9152)  time: 0.1558  data: 0.0125  max mem: 17059
2023-02-28 12:50:51,697	INFO	torchdistill.misc.log	Epoch: [3]  [ 7000/14658]  eta: 0:20:11  lr: 0.02  img/s: 59.64977849833963  loss: 0.9389 (0.9162)  time: 0.1594  data: 0.0128  max mem: 17059
2023-02-28 12:53:30,313	INFO	torchdistill.misc.log	Epoch: [3]  [ 8000/14658]  eta: 0:17:33  lr: 0.02  img/s: 58.08983605422156  loss: 0.9468 (0.9162)  time: 0.1593  data: 0.0135  max mem: 17059
2023-02-28 12:56:08,758	INFO	torchdistill.misc.log	Epoch: [3]  [ 9000/14658]  eta: 0:14:55  lr: 0.02  img/s: 53.643575531528825  loss: 0.8869 (0.9167)  time: 0.1599  data: 0.0143  max mem: 17059
2023-02-28 12:58:47,264	INFO	torchdistill.misc.log	Epoch: [3]  [10000/14658]  eta: 0:12:17  lr: 0.02  img/s: 57.75478371926104  loss: 0.8618 (0.9159)  time: 0.1583  data: 0.0135  max mem: 17059
2023-02-28 13:01:25,730	INFO	torchdistill.misc.log	Epoch: [3]  [11000/14658]  eta: 0:09:38  lr: 0.02  img/s: 57.148653735120746  loss: 0.7760 (0.9156)  time: 0.1580  data: 0.0136  max mem: 17059
2023-02-28 13:04:04,244	INFO	torchdistill.misc.log	Epoch: [3]  [12000/14658]  eta: 0:07:00  lr: 0.02  img/s: 60.136839388638776  loss: 0.8976 (0.9160)  time: 0.1586  data: 0.0138  max mem: 17059
2023-02-28 13:06:42,036	INFO	torchdistill.misc.log	Epoch: [3]  [13000/14658]  eta: 0:04:22  lr: 0.02  img/s: 60.23367218900284  loss: 0.9064 (0.9160)  time: 0.1593  data: 0.0135  max mem: 17059
2023-02-28 13:09:20,186	INFO	torchdistill.misc.log	Epoch: [3]  [14000/14658]  eta: 0:01:44  lr: 0.02  img/s: 60.60957775786827  loss: 0.9046 (0.9159)  time: 0.1601  data: 0.0135  max mem: 17059
2023-02-28 13:11:05,505	INFO	torchdistill.misc.log	Epoch: [3] Total time: 0:38:41
2023-02-28 13:11:09,452	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 0:55:15  model_time: 0.1076 (0.1076)  evaluator_time: 0.0296 (0.0296)  time: 0.6630  data: 0.5241  max mem: 17059
2023-02-28 13:12:50,345	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:06:45  model_time: 0.0834 (0.0842)  evaluator_time: 0.0096 (0.0160)  time: 0.0967  data: 0.0001  max mem: 17059
2023-02-28 13:14:30,370	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:02  model_time: 0.0791 (0.0836)  evaluator_time: 0.0115 (0.0161)  time: 0.0947  data: 0.0001  max mem: 17059
2023-02-28 13:16:09,224	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:20  model_time: 0.0854 (0.0833)  evaluator_time: 0.0096 (0.0158)  time: 0.0998  data: 0.0001  max mem: 17059
2023-02-28 13:17:47,778	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:39  model_time: 0.0813 (0.0831)  evaluator_time: 0.0083 (0.0157)  time: 0.0991  data: 0.0001  max mem: 17059
2023-02-28 13:19:28,587	INFO	torchdistill.misc.log	Validation: Total time: 0:08:19
2023-02-28 13:19:28,588	INFO	__main__	Averaged stats: model_time: 0.0792 (0.0835)  evaluator_time: 0.0098 (0.0155)
2023-02-28 13:19:28,756	INFO	__main__	Accumulating evaluation results...
2023-02-28 13:19:45,325	INFO	__main__	DONE (t=16.57s).
2023-02-28 13:19:45,326	INFO	__main__	IoU metric: bbox
2023-02-28 13:19:45,327	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.171
2023-02-28 13:19:45,327	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.332
2023-02-28 13:19:45,327	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.158
2023-02-28 13:19:45,328	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.044
2023-02-28 13:19:45,329	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.173
2023-02-28 13:19:45,330	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.295
2023-02-28 13:19:45,330	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.189
2023-02-28 13:19:45,330	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.296
2023-02-28 13:19:45,330	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.310
2023-02-28 13:19:45,330	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.087
2023-02-28 13:19:45,330	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.333
2023-02-28 13:19:45,330	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.514
2023-02-28 13:19:46,113	INFO	__main__	Best mAP (bbox): 0.1673 -> 0.1712
2023-02-28 13:19:46,114	INFO	__main__	Updating ckpt at ./resource/ckpt/coco2017/supervised_compression/entropic_student/coco2017-faster_rcnn_splittable_resnet50-fp-beta5.12_fpn.pt
2023-02-28 13:19:47,492	INFO	torchdistill.misc.log	Epoch: [4]  [    0/14658]  eta: 3:21:04  lr: 0.02  img/s: 54.16836630091033  loss: 0.8357 (0.8357)  time: 0.8231  data: 0.6658  max mem: 17059
2023-02-28 13:22:25,520	INFO	torchdistill.misc.log	Epoch: [4]  [ 1000/14658]  eta: 0:36:07  lr: 0.02  img/s: 59.234261302452026  loss: 0.7791 (0.9232)  time: 0.1570  data: 0.0125  max mem: 17059
2023-02-28 13:25:04,562	INFO	torchdistill.misc.log	Epoch: [4]  [ 2000/14658]  eta: 0:33:30  lr: 0.02  img/s: 60.31346637092106  loss: 0.8967 (0.9125)  time: 0.1561  data: 0.0128  max mem: 17059
2023-02-28 13:27:43,352	INFO	torchdistill.misc.log	Epoch: [4]  [ 3000/14658]  eta: 0:30:51  lr: 0.02  img/s: 56.103303387656894  loss: 0.9091 (0.9117)  time: 0.1610  data: 0.0145  max mem: 17059
2023-02-28 13:30:22,014	INFO	torchdistill.misc.log	Epoch: [4]  [ 4000/14658]  eta: 0:28:12  lr: 0.02  img/s: 66.40352574948894  loss: 0.8796 (0.9047)  time: 0.1580  data: 0.0134  max mem: 17059
2023-02-28 13:33:00,672	INFO	torchdistill.misc.log	Epoch: [4]  [ 5000/14658]  eta: 0:25:33  lr: 0.02  img/s: 53.69525287843752  loss: 0.9124 (0.9051)  time: 0.1560  data: 0.0126  max mem: 17059
2023-02-28 13:35:39,388	INFO	torchdistill.misc.log	Epoch: [4]  [ 6000/14658]  eta: 0:22:54  lr: 0.02  img/s: 57.723586130966204  loss: 0.9764 (0.9051)  time: 0.1605  data: 0.0136  max mem: 17059
2023-02-28 13:38:18,043	INFO	torchdistill.misc.log	Epoch: [4]  [ 7000/14658]  eta: 0:20:15  lr: 0.02  img/s: 60.13015787681666  loss: 0.8929 (0.9056)  time: 0.1580  data: 0.0139  max mem: 17059
2023-02-28 13:40:56,768	INFO	torchdistill.misc.log	Epoch: [4]  [ 8000/14658]  eta: 0:17:36  lr: 0.02  img/s: 59.54022915080763  loss: 0.9108 (0.9068)  time: 0.1599  data: 0.0136  max mem: 17059
2023-02-28 13:43:35,581	INFO	torchdistill.misc.log	Epoch: [4]  [ 9000/14658]  eta: 0:14:58  lr: 0.02  img/s: 60.05396446993045  loss: 0.8830 (0.9075)  time: 0.1622  data: 0.0146  max mem: 17059
2023-02-28 13:46:14,306	INFO	torchdistill.misc.log	Epoch: [4]  [10000/14658]  eta: 0:12:19  lr: 0.02  img/s: 54.273944507167094  loss: 0.9618 (0.9073)  time: 0.1598  data: 0.0131  max mem: 17059
2023-02-28 13:48:53,283	INFO	torchdistill.misc.log	Epoch: [4]  [11000/14658]  eta: 0:09:40  lr: 0.02  img/s: 59.597335081054105  loss: 0.8450 (0.9066)  time: 0.1557  data: 0.0130  max mem: 17059
2023-02-28 13:51:31,829	INFO	torchdistill.misc.log	Epoch: [4]  [12000/14658]  eta: 0:07:01  lr: 0.02  img/s: 58.60677862488756  loss: 0.9676 (0.9053)  time: 0.1608  data: 0.0137  max mem: 17059
2023-02-28 13:54:10,758	INFO	torchdistill.misc.log	Epoch: [4]  [13000/14658]  eta: 0:04:23  lr: 0.02  img/s: 59.724523868854796  loss: 0.8920 (0.9054)  time: 0.1578  data: 0.0132  max mem: 17059
2023-02-28 13:56:49,492	INFO	torchdistill.misc.log	Epoch: [4]  [14000/14658]  eta: 0:01:44  lr: 0.02  img/s: 59.39762653298213  loss: 0.9374 (0.9052)  time: 0.1593  data: 0.0132  max mem: 17059
2023-02-28 13:58:34,094	INFO	torchdistill.misc.log	Epoch: [4] Total time: 0:38:47
2023-02-28 13:58:38,090	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 0:57:02  model_time: 0.1021 (0.1021)  evaluator_time: 0.0281 (0.0281)  time: 0.6846  data: 0.5524  max mem: 17059
2023-02-28 14:00:17,532	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:06:40  model_time: 0.0815 (0.0837)  evaluator_time: 0.0083 (0.0150)  time: 0.0959  data: 0.0001  max mem: 17059
2023-02-28 14:01:56,610	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:04:58  model_time: 0.0838 (0.0832)  evaluator_time: 0.0092 (0.0153)  time: 0.0984  data: 0.0001  max mem: 17059
2023-02-28 14:03:34,740	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:18  model_time: 0.0836 (0.0831)  evaluator_time: 0.0081 (0.0150)  time: 0.0969  data: 0.0001  max mem: 17059
2023-02-28 14:05:11,951	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:38  model_time: 0.0780 (0.0828)  evaluator_time: 0.0083 (0.0149)  time: 0.0954  data: 0.0001  max mem: 17059
2023-02-28 14:06:49,189	INFO	torchdistill.misc.log	Validation: Total time: 0:08:11
2023-02-28 14:06:49,189	INFO	__main__	Averaged stats: model_time: 0.0790 (0.0828)  evaluator_time: 0.0092 (0.0147)
2023-02-28 14:06:49,362	INFO	__main__	Accumulating evaluation results...
2023-02-28 14:07:03,871	INFO	__main__	DONE (t=14.51s).
2023-02-28 14:07:03,872	INFO	__main__	IoU metric: bbox
2023-02-28 14:07:03,873	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.176
2023-02-28 14:07:03,873	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.334
2023-02-28 14:07:03,873	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.165
2023-02-28 14:07:03,874	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.044
2023-02-28 14:07:03,875	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.183
2023-02-28 14:07:03,875	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.304
2023-02-28 14:07:03,875	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.190
2023-02-28 14:07:03,875	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.291
2023-02-28 14:07:03,876	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.303
2023-02-28 14:07:03,876	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.077
2023-02-28 14:07:03,876	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.327
2023-02-28 14:07:03,876	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.506
2023-02-28 14:07:04,764	INFO	__main__	Best mAP (bbox): 0.1712 -> 0.1760
2023-02-28 14:07:04,765	INFO	__main__	Updating ckpt at ./resource/ckpt/coco2017/supervised_compression/entropic_student/coco2017-faster_rcnn_splittable_resnet50-fp-beta5.12_fpn.pt
2023-02-28 14:07:06,153	INFO	torchdistill.misc.log	Epoch: [5]  [    0/14658]  eta: 3:30:57  lr: 0.02  img/s: 53.8575395411398  loss: 1.2346 (1.2346)  time: 0.8635  data: 0.7014  max mem: 17059
2023-02-28 14:09:44,193	INFO	torchdistill.misc.log	Epoch: [5]  [ 1000/14658]  eta: 0:36:08  lr: 0.02  img/s: 59.10165374704311  loss: 0.8903 (0.9014)  time: 0.1597  data: 0.0130  max mem: 17059
2023-02-28 14:12:23,125	INFO	torchdistill.misc.log	Epoch: [5]  [ 2000/14658]  eta: 0:33:30  lr: 0.02  img/s: 59.81576681528015  loss: 0.9294 (0.8981)  time: 0.1594  data: 0.0129  max mem: 17059
2023-02-28 14:15:01,830	INFO	torchdistill.misc.log	Epoch: [5]  [ 3000/14658]  eta: 0:30:51  lr: 0.02  img/s: 59.89520526793986  loss: 0.9315 (0.8934)  time: 0.1602  data: 0.0144  max mem: 17059
2023-02-28 14:17:41,032	INFO	torchdistill.misc.log	Epoch: [5]  [ 4000/14658]  eta: 0:28:13  lr: 0.02  img/s: 60.13198975651105  loss: 0.9278 (0.8943)  time: 0.1603  data: 0.0139  max mem: 17059
2023-02-28 14:20:19,787	INFO	torchdistill.misc.log	Epoch: [5]  [ 5000/14658]  eta: 0:25:34  lr: 0.02  img/s: 60.1357616250103  loss: 0.8666 (0.8939)  time: 0.1606  data: 0.0136  max mem: 17059
2023-02-28 14:22:58,929	INFO	torchdistill.misc.log	Epoch: [5]  [ 6000/14658]  eta: 0:22:55  lr: 0.02  img/s: 58.547365629296685  loss: 0.9663 (0.8957)  time: 0.1584  data: 0.0136  max mem: 17059
2023-02-28 14:25:37,855	INFO	torchdistill.misc.log	Epoch: [5]  [ 7000/14658]  eta: 0:20:16  lr: 0.02  img/s: 59.60209885358827  loss: 0.7807 (0.8965)  time: 0.1574  data: 0.0126  max mem: 17059
2023-02-28 14:28:16,513	INFO	torchdistill.misc.log	Epoch: [5]  [ 8000/14658]  eta: 0:17:37  lr: 0.02  img/s: 52.92447074633363  loss: 0.8800 (0.8977)  time: 0.1611  data: 0.0135  max mem: 17059
2023-02-28 14:30:55,223	INFO	torchdistill.misc.log	Epoch: [5]  [ 9000/14658]  eta: 0:14:58  lr: 0.02  img/s: 59.86955691674146  loss: 0.8620 (0.8985)  time: 0.1606  data: 0.0139  max mem: 17059
2023-02-28 14:33:34,358	INFO	torchdistill.misc.log	Epoch: [5]  [10000/14658]  eta: 0:12:20  lr: 0.02  img/s: 59.79359589144842  loss: 0.7849 (0.8990)  time: 0.1579  data: 0.0128  max mem: 17059
2023-02-28 14:36:13,280	INFO	torchdistill.misc.log	Epoch: [5]  [11000/14658]  eta: 0:09:41  lr: 0.02  img/s: 56.7295179388687  loss: 0.7857 (0.8995)  time: 0.1605  data: 0.0132  max mem: 17059
2023-02-28 14:38:52,447	INFO	torchdistill.misc.log	Epoch: [5]  [12000/14658]  eta: 0:07:02  lr: 0.02  img/s: 59.72505540079919  loss: 0.8631 (0.9001)  time: 0.1607  data: 0.0142  max mem: 17059
2023-02-28 14:41:31,210	INFO	torchdistill.misc.log	Epoch: [5]  [13000/14658]  eta: 0:04:23  lr: 0.02  img/s: 59.60686338774517  loss: 0.8427 (0.8999)  time: 0.1572  data: 0.0134  max mem: 17059
2023-02-28 14:44:08,019	INFO	torchdistill.misc.log	Epoch: [5]  [14000/14658]  eta: 0:01:44  lr: 0.02  img/s: 60.25411487532368  loss: 0.7952 (0.8992)  time: 0.1556  data: 0.0121  max mem: 17059
2023-02-28 14:45:51,062	INFO	torchdistill.misc.log	Epoch: [5] Total time: 0:38:45
2023-02-28 14:45:57,450	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 0:57:03  model_time: 0.1224 (0.1224)  evaluator_time: 0.0280 (0.0280)  time: 0.6847  data: 0.5328  max mem: 17059
2023-02-28 14:47:38,191	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:06:45  model_time: 0.0840 (0.0832)  evaluator_time: 0.0090 (0.0168)  time: 0.0984  data: 0.0001  max mem: 17059
2023-02-28 14:49:19,153	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:03  model_time: 0.0795 (0.0830)  evaluator_time: 0.0099 (0.0171)  time: 0.0938  data: 0.0001  max mem: 17059
2023-02-28 14:50:58,698	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:21  model_time: 0.0837 (0.0828)  evaluator_time: 0.0092 (0.0169)  time: 0.0974  data: 0.0001  max mem: 17059
2023-02-28 14:52:38,205	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:40  model_time: 0.0836 (0.0827)  evaluator_time: 0.0094 (0.0167)  time: 0.0989  data: 0.0001  max mem: 17059
2023-02-28 14:54:19,541	INFO	torchdistill.misc.log	Validation: Total time: 0:08:22
2023-02-28 14:54:19,542	INFO	__main__	Averaged stats: model_time: 0.0793 (0.0825)  evaluator_time: 0.0099 (0.0171)
2023-02-28 14:54:19,773	INFO	__main__	Accumulating evaluation results...
2023-02-28 14:54:36,479	INFO	__main__	DONE (t=16.71s).
2023-02-28 14:54:36,479	INFO	__main__	IoU metric: bbox
2023-02-28 14:54:36,480	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.178
2023-02-28 14:54:36,480	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.340
2023-02-28 14:54:36,480	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.167
2023-02-28 14:54:36,481	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.050
2023-02-28 14:54:36,482	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.187
2023-02-28 14:54:36,483	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.303
2023-02-28 14:54:36,483	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.193
2023-02-28 14:54:36,483	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.302
2023-02-28 14:54:36,483	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.316
2023-02-28 14:54:36,483	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.092
2023-02-28 14:54:36,483	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.342
2023-02-28 14:54:36,483	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.536
2023-02-28 14:54:37,247	INFO	__main__	Best mAP (bbox): 0.1760 -> 0.1778
2023-02-28 14:54:37,249	INFO	__main__	Updating ckpt at ./resource/ckpt/coco2017/supervised_compression/entropic_student/coco2017-faster_rcnn_splittable_resnet50-fp-beta5.12_fpn.pt
2023-02-28 14:54:38,677	INFO	torchdistill.misc.log	Epoch: [6]  [    0/14658]  eta: 3:30:14  lr: 0.02  img/s: 55.246273632979396  loss: 1.1226 (1.1226)  time: 0.8606  data: 0.7042  max mem: 17059
2023-02-28 14:57:15,803	INFO	torchdistill.misc.log	Epoch: [6]  [ 1000/14658]  eta: 0:35:55  lr: 0.02  img/s: 60.74607691917765  loss: 0.9031 (0.8855)  time: 0.1585  data: 0.0130  max mem: 17059
2023-02-28 14:59:53,198	INFO	torchdistill.misc.log	Epoch: [6]  [ 2000/14658]  eta: 0:33:15  lr: 0.02  img/s: 60.537188919639604  loss: 0.9569 (0.8906)  time: 0.1572  data: 0.0134  max mem: 17059
2023-02-28 15:02:30,767	INFO	torchdistill.misc.log	Epoch: [6]  [ 3000/14658]  eta: 0:30:37  lr: 0.02  img/s: 61.79191673280874  loss: 0.8897 (0.8904)  time: 0.1579  data: 0.0133  max mem: 17059
2023-02-28 15:05:07,651	INFO	torchdistill.misc.log	Epoch: [6]  [ 4000/14658]  eta: 0:27:57  lr: 0.02  img/s: 59.878210779152646  loss: 0.8928 (0.8922)  time: 0.1563  data: 0.0124  max mem: 17059
2023-02-28 15:07:43,863	INFO	torchdistill.misc.log	Epoch: [6]  [ 5000/14658]  eta: 0:25:17  lr: 0.02  img/s: 53.182495680978874  loss: 0.8842 (0.8913)  time: 0.1563  data: 0.0120  max mem: 17059
2023-02-28 15:10:19,819	INFO	torchdistill.misc.log	Epoch: [6]  [ 6000/14658]  eta: 0:22:39  lr: 0.02  img/s: 60.200819914779096  loss: 0.8083 (0.8921)  time: 0.1553  data: 0.0117  max mem: 17059
2023-02-28 15:12:55,380	INFO	torchdistill.misc.log	Epoch: [6]  [ 7000/14658]  eta: 0:20:00  lr: 0.02  img/s: 59.597123375504644  loss: 0.9147 (0.8934)  time: 0.1576  data: 0.0122  max mem: 17059
2023-02-28 15:15:30,973	INFO	torchdistill.misc.log	Epoch: [6]  [ 8000/14658]  eta: 0:17:22  lr: 0.02  img/s: 53.35195555597956  loss: 0.8958 (0.8933)  time: 0.1576  data: 0.0117  max mem: 17059
2023-02-28 15:18:06,710	INFO	torchdistill.misc.log	Epoch: [6]  [ 9000/14658]  eta: 0:14:45  lr: 0.02  img/s: 59.17711814636951  loss: 0.8283 (0.8940)  time: 0.1560  data: 0.0116  max mem: 17059
2023-02-28 15:20:42,783	INFO	torchdistill.misc.log	Epoch: [6]  [10000/14658]  eta: 0:12:08  lr: 0.02  img/s: 59.34940419653643  loss: 0.7192 (0.8943)  time: 0.1559  data: 0.0125  max mem: 17059
2023-02-28 15:23:18,398	INFO	torchdistill.misc.log	Epoch: [6]  [11000/14658]  eta: 0:09:32  lr: 0.02  img/s: 59.653702218895724  loss: 0.9336 (0.8950)  time: 0.1551  data: 0.0120  max mem: 17059
2023-02-28 15:25:54,645	INFO	torchdistill.misc.log	Epoch: [6]  [12000/14658]  eta: 0:06:55  lr: 0.02  img/s: 59.986434666328186  loss: 0.7361 (0.8949)  time: 0.1559  data: 0.0119  max mem: 17059
2023-02-28 15:28:31,118	INFO	torchdistill.misc.log	Epoch: [6]  [13000/14658]  eta: 0:04:19  lr: 0.02  img/s: 59.74323948978356  loss: 0.8825 (0.8943)  time: 0.1579  data: 0.0126  max mem: 17059
2023-02-28 15:31:07,617	INFO	torchdistill.misc.log	Epoch: [6]  [14000/14658]  eta: 0:01:42  lr: 0.02  img/s: 60.493860368684366  loss: 0.9419 (0.8948)  time: 0.1565  data: 0.0122  max mem: 17059
2023-02-28 15:32:50,724	INFO	torchdistill.misc.log	Epoch: [6] Total time: 0:38:12
2023-02-28 15:32:54,951	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 0:57:27  model_time: 0.1045 (0.1045)  evaluator_time: 0.0272 (0.0272)  time: 0.6896  data: 0.5558  max mem: 17059
2023-02-28 15:34:34,488	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:06:40  model_time: 0.0826 (0.0819)  evaluator_time: 0.0100 (0.0168)  time: 0.0978  data: 0.0001  max mem: 17059
2023-02-28 15:36:14,932	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:00  model_time: 0.0796 (0.0820)  evaluator_time: 0.0088 (0.0172)  time: 0.0969  data: 0.0001  max mem: 17059
2023-02-28 15:37:55,653	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:20  model_time: 0.0833 (0.0824)  evaluator_time: 0.0085 (0.0170)  time: 0.0978  data: 0.0001  max mem: 17059
2023-02-28 15:39:35,350	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:40  model_time: 0.0818 (0.0824)  evaluator_time: 0.0100 (0.0169)  time: 0.0992  data: 0.0001  max mem: 17059
2023-02-28 15:41:13,253	INFO	torchdistill.misc.log	Validation: Total time: 0:08:18
2023-02-28 15:41:13,253	INFO	__main__	Averaged stats: model_time: 0.0796 (0.0823)  evaluator_time: 0.0098 (0.0166)
2023-02-28 15:41:13,438	INFO	__main__	Accumulating evaluation results...
2023-02-28 15:41:28,755	INFO	__main__	DONE (t=15.32s).
2023-02-28 15:41:28,755	INFO	__main__	IoU metric: bbox
2023-02-28 15:41:28,756	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.177
2023-02-28 15:41:28,757	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.340
2023-02-28 15:41:28,757	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.170
2023-02-28 15:41:28,758	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.046
2023-02-28 15:41:28,758	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.185
2023-02-28 15:41:28,759	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.300
2023-02-28 15:41:28,759	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.191
2023-02-28 15:41:28,759	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.294
2023-02-28 15:41:28,759	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.306
2023-02-28 15:41:28,759	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.084
2023-02-28 15:41:28,759	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.330
2023-02-28 15:41:28,760	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.504
2023-02-28 15:41:30,786	INFO	torchdistill.misc.log	Epoch: [7]  [    0/14658]  eta: 4:36:59  lr: 0.02  img/s: 54.78650291122003  loss: 0.9406 (0.9406)  time: 1.1338  data: 0.9503  max mem: 17059
2023-02-28 15:44:07,639	INFO	torchdistill.misc.log	Epoch: [7]  [ 1000/14658]  eta: 0:35:55  lr: 0.02  img/s: 60.47456258605899  loss: 0.8333 (0.8801)  time: 0.1570  data: 0.0131  max mem: 17059
2023-02-28 15:46:44,070	INFO	torchdistill.misc.log	Epoch: [7]  [ 2000/14658]  eta: 0:33:08  lr: 0.02  img/s: 66.06776811012072  loss: 0.8722 (0.8846)  time: 0.1576  data: 0.0124  max mem: 17059
2023-02-28 15:49:20,529	INFO	torchdistill.misc.log	Epoch: [7]  [ 3000/14658]  eta: 0:30:29  lr: 0.02  img/s: 60.37717162665746  loss: 0.8798 (0.8875)  time: 0.1572  data: 0.0124  max mem: 17059
2023-02-28 15:51:58,046	INFO	torchdistill.misc.log	Epoch: [7]  [ 4000/14658]  eta: 0:27:53  lr: 0.02  img/s: 62.702859470712006  loss: 0.8164 (0.8893)  time: 0.1595  data: 0.0126  max mem: 17059
2023-02-28 15:54:36,215	INFO	torchdistill.misc.log	Epoch: [7]  [ 5000/14658]  eta: 0:25:18  lr: 0.02  img/s: 59.080008944465085  loss: 0.8336 (0.8878)  time: 0.1578  data: 0.0125  max mem: 17059
2023-02-28 15:57:14,473	INFO	torchdistill.misc.log	Epoch: [7]  [ 6000/14658]  eta: 0:22:43  lr: 0.02  img/s: 59.749409707506956  loss: 0.9436 (0.8886)  time: 0.1592  data: 0.0135  max mem: 17059
2023-02-28 15:59:52,814	INFO	torchdistill.misc.log	Epoch: [7]  [ 7000/14658]  eta: 0:20:06  lr: 0.02  img/s: 62.08943027750587  loss: 0.8930 (0.8889)  time: 0.1566  data: 0.0130  max mem: 17059
2023-02-28 16:02:31,583	INFO	torchdistill.misc.log	Epoch: [7]  [ 8000/14658]  eta: 0:17:30  lr: 0.02  img/s: 58.9741989004654  loss: 0.7690 (0.8881)  time: 0.1574  data: 0.0127  max mem: 17059
2023-02-28 16:05:10,111	INFO	torchdistill.misc.log	Epoch: [7]  [ 9000/14658]  eta: 0:14:52  lr: 0.02  img/s: 59.21763976076057  loss: 0.8363 (0.8887)  time: 0.1583  data: 0.0125  max mem: 17059
2023-02-28 16:07:48,806	INFO	torchdistill.misc.log	Epoch: [7]  [10000/14658]  eta: 0:12:15  lr: 0.02  img/s: 59.20081864535366  loss: 0.8693 (0.8894)  time: 0.1602  data: 0.0134  max mem: 17059
2023-02-28 16:10:27,477	INFO	torchdistill.misc.log	Epoch: [7]  [11000/14658]  eta: 0:09:37  lr: 0.02  img/s: 60.14880515974524  loss: 0.8471 (0.8893)  time: 0.1582  data: 0.0138  max mem: 17059
2023-02-28 16:13:06,366	INFO	torchdistill.misc.log	Epoch: [7]  [12000/14658]  eta: 0:07:00  lr: 0.02  img/s: 59.104881013193356  loss: 0.7857 (0.8896)  time: 0.1573  data: 0.0135  max mem: 17059
2023-02-28 16:15:45,067	INFO	torchdistill.misc.log	Epoch: [7]  [13000/14658]  eta: 0:04:22  lr: 0.02  img/s: 59.1848422151786  loss: 0.9168 (0.8899)  time: 0.1574  data: 0.0124  max mem: 17059
2023-02-28 16:18:23,721	INFO	torchdistill.misc.log	Epoch: [7]  [14000/14658]  eta: 0:01:44  lr: 0.02  img/s: 60.54243184237591  loss: 0.8013 (0.8903)  time: 0.1572  data: 0.0131  max mem: 17059
2023-02-28 16:20:08,287	INFO	torchdistill.misc.log	Epoch: [7] Total time: 0:38:38
2023-02-28 16:20:14,793	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 0:59:02  model_time: 0.0983 (0.0983)  evaluator_time: 0.0281 (0.0281)  time: 0.7085  data: 0.5801  max mem: 17059
2023-02-28 16:21:56,168	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:06:47  model_time: 0.0812 (0.0840)  evaluator_time: 0.0094 (0.0166)  time: 0.0993  data: 0.0001  max mem: 17059
2023-02-28 16:23:37,569	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:05  model_time: 0.0851 (0.0838)  evaluator_time: 0.0133 (0.0168)  time: 0.1014  data: 0.0001  max mem: 17059
2023-02-28 16:25:17,749	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:22  model_time: 0.0821 (0.0836)  evaluator_time: 0.0104 (0.0166)  time: 0.0971  data: 0.0001  max mem: 17059
2023-02-28 16:26:56,800	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:40  model_time: 0.0799 (0.0833)  evaluator_time: 0.0097 (0.0164)  time: 0.0980  data: 0.0001  max mem: 17059
2023-02-28 16:28:38,447	INFO	torchdistill.misc.log	Validation: Total time: 0:08:24
2023-02-28 16:28:38,448	INFO	__main__	Averaged stats: model_time: 0.0789 (0.0831)  evaluator_time: 0.0099 (0.0168)
2023-02-28 16:28:38,654	INFO	__main__	Accumulating evaluation results...
2023-02-28 16:28:56,373	INFO	__main__	DONE (t=17.72s).
2023-02-28 16:28:56,373	INFO	__main__	IoU metric: bbox
2023-02-28 16:28:56,374	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.179
2023-02-28 16:28:56,374	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.342
2023-02-28 16:28:56,374	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.170
2023-02-28 16:28:56,375	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.042
2023-02-28 16:28:56,376	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.187
2023-02-28 16:28:56,377	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.306
2023-02-28 16:28:56,377	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.194
2023-02-28 16:28:56,377	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.303
2023-02-28 16:28:56,377	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.319
2023-02-28 16:28:56,377	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.089
2023-02-28 16:28:56,377	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.345
2023-02-28 16:28:56,377	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.521
2023-02-28 16:28:57,157	INFO	__main__	Best mAP (bbox): 0.1778 -> 0.1789
2023-02-28 16:28:57,159	INFO	__main__	Updating ckpt at ./resource/ckpt/coco2017/supervised_compression/entropic_student/coco2017-faster_rcnn_splittable_resnet50-fp-beta5.12_fpn.pt
2023-02-28 16:28:58,643	INFO	torchdistill.misc.log	Epoch: [8]  [    0/14658]  eta: 3:30:45  lr: 0.02  img/s: 50.58848574211271  loss: 0.9375 (0.9375)  time: 0.8627  data: 0.6901  max mem: 17059
2023-02-28 16:31:35,776	INFO	torchdistill.misc.log	Epoch: [8]  [ 1000/14658]  eta: 0:35:55  lr: 0.02  img/s: 59.16344939945129  loss: 0.7551 (0.8804)  time: 0.1543  data: 0.0115  max mem: 17059
2023-02-28 16:34:12,634	INFO	torchdistill.misc.log	Epoch: [8]  [ 2000/14658]  eta: 0:33:11  lr: 0.02  img/s: 60.30176011156598  loss: 0.9307 (0.8848)  time: 0.1571  data: 0.0125  max mem: 17059
2023-02-28 16:36:50,664	INFO	torchdistill.misc.log	Epoch: [8]  [ 3000/14658]  eta: 0:30:36  lr: 0.02  img/s: 59.46984364421349  loss: 0.8168 (0.8865)  time: 0.1577  data: 0.0129  max mem: 17059
2023-02-28 16:39:29,337	INFO	torchdistill.misc.log	Epoch: [8]  [ 4000/14658]  eta: 0:28:02  lr: 0.02  img/s: 56.53196034693066  loss: 0.8871 (0.8894)  time: 0.1594  data: 0.0126  max mem: 17059
2023-02-28 16:42:07,890	INFO	torchdistill.misc.log	Epoch: [8]  [ 5000/14658]  eta: 0:25:25  lr: 0.02  img/s: 59.67683084075416  loss: 0.9584 (0.8903)  time: 0.1559  data: 0.0131  max mem: 17059
2023-02-28 16:44:46,148	INFO	torchdistill.misc.log	Epoch: [8]  [ 6000/14658]  eta: 0:22:48  lr: 0.02  img/s: 59.987078112346055  loss: 0.8760 (0.8889)  time: 0.1578  data: 0.0127  max mem: 17059
2023-02-28 16:47:24,545	INFO	torchdistill.misc.log	Epoch: [8]  [ 7000/14658]  eta: 0:20:10  lr: 0.02  img/s: 60.066112329380175  loss: 0.7730 (0.8866)  time: 0.1593  data: 0.0125  max mem: 17059
2023-02-28 16:50:03,244	INFO	torchdistill.misc.log	Epoch: [8]  [ 8000/14658]  eta: 0:17:33  lr: 0.02  img/s: 53.04226696891233  loss: 0.7915 (0.8859)  time: 0.1571  data: 0.0124  max mem: 17059
2023-02-28 16:52:41,556	INFO	torchdistill.misc.log	Epoch: [8]  [ 9000/14658]  eta: 0:14:54  lr: 0.02  img/s: 57.61742958895265  loss: 0.9441 (0.8852)  time: 0.1588  data: 0.0133  max mem: 17059
2023-02-28 16:55:20,202	INFO	torchdistill.misc.log	Epoch: [8]  [10000/14658]  eta: 0:12:16  lr: 0.02  img/s: 59.462150384813725  loss: 0.8714 (0.8863)  time: 0.1569  data: 0.0132  max mem: 17059
2023-02-28 16:57:58,652	INFO	torchdistill.misc.log	Epoch: [8]  [11000/14658]  eta: 0:09:38  lr: 0.02  img/s: 59.74345223469755  loss: 0.7837 (0.8861)  time: 0.1559  data: 0.0125  max mem: 17059
2023-02-28 17:00:36,953	INFO	torchdistill.misc.log	Epoch: [8]  [12000/14658]  eta: 0:07:00  lr: 0.02  img/s: 55.93869062404663  loss: 0.8903 (0.8866)  time: 0.1585  data: 0.0125  max mem: 17059
2023-02-28 17:03:15,543	INFO	torchdistill.misc.log	Epoch: [8]  [13000/14658]  eta: 0:04:22  lr: 0.02  img/s: 58.72853672367804  loss: 0.9205 (0.8865)  time: 0.1575  data: 0.0133  max mem: 17059
2023-02-28 17:05:54,311	INFO	torchdistill.misc.log	Epoch: [8]  [14000/14658]  eta: 0:01:44  lr: 0.02  img/s: 60.221996880715174  loss: 0.7947 (0.8866)  time: 0.1576  data: 0.0125  max mem: 17059
2023-02-28 17:07:38,689	INFO	torchdistill.misc.log	Epoch: [8] Total time: 0:38:40
2023-02-28 17:07:42,989	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 0:56:38  model_time: 0.1096 (0.1096)  evaluator_time: 0.0280 (0.0280)  time: 0.6797  data: 0.5407  max mem: 17059
2023-02-28 17:09:24,994	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:06:50  model_time: 0.0799 (0.0836)  evaluator_time: 0.0097 (0.0176)  time: 0.0960  data: 0.0001  max mem: 17059
2023-02-28 17:11:06,939	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:06  model_time: 0.0834 (0.0832)  evaluator_time: 0.0108 (0.0180)  time: 0.1006  data: 0.0001  max mem: 17059
2023-02-28 17:12:47,925	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:23  model_time: 0.0842 (0.0831)  evaluator_time: 0.0108 (0.0178)  time: 0.0995  data: 0.0001  max mem: 17059
2023-02-28 17:14:28,380	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:41  model_time: 0.0835 (0.0829)  evaluator_time: 0.0101 (0.0177)  time: 0.0987  data: 0.0001  max mem: 17059
2023-02-28 17:16:11,216	INFO	torchdistill.misc.log	Validation: Total time: 0:08:28
2023-02-28 17:16:11,217	INFO	__main__	Averaged stats: model_time: 0.0795 (0.0828)  evaluator_time: 0.0107 (0.0181)
2023-02-28 17:16:11,420	INFO	__main__	Accumulating evaluation results...
2023-02-28 17:16:30,343	INFO	__main__	DONE (t=18.92s).
2023-02-28 17:16:30,344	INFO	__main__	IoU metric: bbox
2023-02-28 17:16:30,345	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.176
2023-02-28 17:16:30,345	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.339
2023-02-28 17:16:30,345	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.167
2023-02-28 17:16:30,346	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.044
2023-02-28 17:16:30,347	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.181
2023-02-28 17:16:30,347	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.303
2023-02-28 17:16:30,347	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.193
2023-02-28 17:16:30,347	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.300
2023-02-28 17:16:30,347	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.315
2023-02-28 17:16:30,348	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.084
2023-02-28 17:16:30,348	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.346
2023-02-28 17:16:30,348	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.526
2023-02-28 17:16:32,506	INFO	torchdistill.misc.log	Epoch: [9]  [    0/14658]  eta: 4:50:36  lr: 0.02  img/s: 57.16423133208287  loss: 0.6376 (0.6376)  time: 1.1896  data: 1.0316  max mem: 17059
2023-02-28 17:19:09,756	INFO	torchdistill.misc.log	Epoch: [9]  [ 1000/14658]  eta: 0:36:01  lr: 0.02  img/s: 63.561256054570215  loss: 0.9879 (0.8738)  time: 0.1548  data: 0.0125  max mem: 17059
2023-02-28 17:21:48,222	INFO	torchdistill.misc.log	Epoch: [9]  [ 2000/14658]  eta: 0:33:24  lr: 0.02  img/s: 58.060184279967125  loss: 0.9334 (0.8770)  time: 0.1594  data: 0.0129  max mem: 17059
2023-02-28 17:24:26,790	INFO	torchdistill.misc.log	Epoch: [9]  [ 3000/14658]  eta: 0:30:47  lr: 0.02  img/s: 59.45898934841201  loss: 0.8762 (0.8778)  time: 0.1577  data: 0.0129  max mem: 17059
2023-02-28 17:27:05,289	INFO	torchdistill.misc.log	Epoch: [9]  [ 4000/14658]  eta: 0:28:08  lr: 0.02  img/s: 58.490927695238895  loss: 0.7884 (0.8767)  time: 0.1581  data: 0.0134  max mem: 17059
2023-02-28 17:29:44,064	INFO	torchdistill.misc.log	Epoch: [9]  [ 5000/14658]  eta: 0:25:30  lr: 0.02  img/s: 59.75898670694003  loss: 0.7930 (0.8787)  time: 0.1600  data: 0.0132  max mem: 17059
2023-02-28 17:32:22,455	INFO	torchdistill.misc.log	Epoch: [9]  [ 6000/14658]  eta: 0:22:52  lr: 0.02  img/s: 60.39140701491678  loss: 0.8056 (0.8803)  time: 0.1577  data: 0.0132  max mem: 17059
2023-02-28 17:35:00,759	INFO	torchdistill.misc.log	Epoch: [9]  [ 7000/14658]  eta: 0:20:13  lr: 0.02  img/s: 59.81384752781288  loss: 0.7851 (0.8804)  time: 0.1590  data: 0.0136  max mem: 17059
2023-02-28 17:37:39,292	INFO	torchdistill.misc.log	Epoch: [9]  [ 8000/14658]  eta: 0:17:35  lr: 0.02  img/s: 60.04805357261097  loss: 0.8382 (0.8805)  time: 0.1594  data: 0.0128  max mem: 17059
2023-02-28 17:40:17,827	INFO	torchdistill.misc.log	Epoch: [9]  [ 9000/14658]  eta: 0:14:56  lr: 0.02  img/s: 60.56461508193644  loss: 0.8888 (0.8799)  time: 0.1596  data: 0.0136  max mem: 17059
2023-02-28 17:42:56,490	INFO	torchdistill.misc.log	Epoch: [9]  [10000/14658]  eta: 0:12:18  lr: 0.02  img/s: 59.811288669441446  loss: 0.7556 (0.8811)  time: 0.1582  data: 0.0126  max mem: 17059
2023-02-28 17:45:34,919	INFO	torchdistill.misc.log	Epoch: [9]  [11000/14658]  eta: 0:09:39  lr: 0.02  img/s: 59.12654404742186  loss: 0.9531 (0.8817)  time: 0.1598  data: 0.0139  max mem: 17059
2023-02-28 17:48:13,362	INFO	torchdistill.misc.log	Epoch: [9]  [12000/14658]  eta: 0:07:01  lr: 0.02  img/s: 59.69275544857939  loss: 0.8287 (0.8826)  time: 0.1585  data: 0.0140  max mem: 17059
2023-02-28 17:50:52,128	INFO	torchdistill.misc.log	Epoch: [9]  [13000/14658]  eta: 0:04:22  lr: 0.02  img/s: 59.557666570819  loss: 0.8541 (0.8832)  time: 0.1582  data: 0.0128  max mem: 17059
2023-02-28 17:53:30,421	INFO	torchdistill.misc.log	Epoch: [9]  [14000/14658]  eta: 0:01:44  lr: 0.02  img/s: 60.021952074642776  loss: 0.6402 (0.8835)  time: 0.1574  data: 0.0130  max mem: 17059
2023-02-28 17:55:14,772	INFO	torchdistill.misc.log	Epoch: [9] Total time: 0:38:43
2023-02-28 17:55:18,712	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 0:56:44  model_time: 0.0944 (0.0944)  evaluator_time: 0.0250 (0.0250)  time: 0.6809  data: 0.5596  max mem: 17059
2023-02-28 17:56:56,795	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:06:34  model_time: 0.0810 (0.0838)  evaluator_time: 0.0074 (0.0135)  time: 0.0951  data: 0.0001  max mem: 17059
2023-02-28 17:58:34,663	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:04:54  model_time: 0.0773 (0.0834)  evaluator_time: 0.0086 (0.0138)  time: 0.0937  data: 0.0001  max mem: 17059
2023-02-28 18:00:11,660	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:15  model_time: 0.0810 (0.0833)  evaluator_time: 0.0072 (0.0136)  time: 0.0924  data: 0.0001  max mem: 17059
2023-02-28 18:01:48,101	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:37  model_time: 0.0830 (0.0831)  evaluator_time: 0.0071 (0.0135)  time: 0.0976  data: 0.0001  max mem: 17059
2023-02-28 18:03:24,507	INFO	torchdistill.misc.log	Validation: Total time: 0:08:06
2023-02-28 18:03:24,507	INFO	__main__	Averaged stats: model_time: 0.0797 (0.0830)  evaluator_time: 0.0084 (0.0134)
2023-02-28 18:03:24,724	INFO	__main__	Accumulating evaluation results...
2023-02-28 18:03:36,249	INFO	__main__	DONE (t=11.52s).
2023-02-28 18:03:36,249	INFO	__main__	IoU metric: bbox
2023-02-28 18:03:36,250	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.186
2023-02-28 18:03:36,251	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.347
2023-02-28 18:03:36,251	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.183
2023-02-28 18:03:36,252	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.045
2023-02-28 18:03:36,252	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.192
2023-02-28 18:03:36,253	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.319
2023-02-28 18:03:36,253	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.197
2023-02-28 18:03:36,253	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.290
2023-02-28 18:03:36,253	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.301
2023-02-28 18:03:36,253	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.077
2023-02-28 18:03:36,253	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.319
2023-02-28 18:03:36,253	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.504
2023-02-28 18:03:37,294	INFO	__main__	Best mAP (bbox): 0.1789 -> 0.1862
2023-02-28 18:03:37,296	INFO	__main__	Updating ckpt at ./resource/ckpt/coco2017/supervised_compression/entropic_student/coco2017-faster_rcnn_splittable_resnet50-fp-beta5.12_fpn.pt
2023-02-28 18:03:38,771	INFO	torchdistill.misc.log	Epoch: [10]  [    0/14658]  eta: 3:42:50  lr: 0.02  img/s: 50.99388002291762  loss: 0.7874 (0.7874)  time: 0.9122  data: 0.7453  max mem: 17059
2023-02-28 18:06:16,122	INFO	torchdistill.misc.log	Epoch: [10]  [ 1000/14658]  eta: 0:35:59  lr: 0.02  img/s: 60.1212155961248  loss: 0.8304 (0.8710)  time: 0.1568  data: 0.0128  max mem: 17059
2023-02-28 18:08:54,879	INFO	torchdistill.misc.log	Epoch: [10]  [ 2000/14658]  eta: 0:33:25  lr: 0.02  img/s: 59.58167293183017  loss: 0.6973 (0.8717)  time: 0.1591  data: 0.0130  max mem: 17059
2023-02-28 18:11:33,822	INFO	torchdistill.misc.log	Epoch: [10]  [ 3000/14658]  eta: 0:30:48  lr: 0.02  img/s: 53.306525254900215  loss: 0.8397 (0.8772)  time: 0.1594  data: 0.0133  max mem: 17059
2023-02-28 18:14:12,877	INFO	torchdistill.misc.log	Epoch: [10]  [ 4000/14658]  eta: 0:28:11  lr: 0.02  img/s: 58.851730766532434  loss: 0.8244 (0.8765)  time: 0.1597  data: 0.0132  max mem: 17059
2023-02-28 18:16:51,756	INFO	torchdistill.misc.log	Epoch: [10]  [ 5000/14658]  eta: 0:25:33  lr: 0.02  img/s: 60.63586422251778  loss: 0.6752 (0.8787)  time: 0.1577  data: 0.0133  max mem: 17059
2023-02-28 18:19:30,969	INFO	torchdistill.misc.log	Epoch: [10]  [ 6000/14658]  eta: 0:22:55  lr: 0.02  img/s: 59.255914654498  loss: 0.8553 (0.8808)  time: 0.1592  data: 0.0136  max mem: 17059
2023-02-28 18:22:09,908	INFO	torchdistill.misc.log	Epoch: [10]  [ 7000/14658]  eta: 0:20:16  lr: 0.02  img/s: 59.47311124699794  loss: 0.9032 (0.8822)  time: 0.1591  data: 0.0131  max mem: 17059
2023-02-28 18:24:48,522	INFO	torchdistill.misc.log	Epoch: [10]  [ 8000/14658]  eta: 0:17:37  lr: 0.02  img/s: 57.17251038510951  loss: 0.7531 (0.8815)  time: 0.1551  data: 0.0125  max mem: 17059
2023-02-28 18:27:27,538	INFO	torchdistill.misc.log	Epoch: [10]  [ 9000/14658]  eta: 0:14:58  lr: 0.02  img/s: 60.491461103990105  loss: 0.7661 (0.8827)  time: 0.1574  data: 0.0128  max mem: 17059
2023-02-28 18:30:06,303	INFO	torchdistill.misc.log	Epoch: [10]  [10000/14658]  eta: 0:12:19  lr: 0.02  img/s: 57.378895221679  loss: 0.8990 (0.8823)  time: 0.1590  data: 0.0130  max mem: 17059
2023-02-28 18:32:45,379	INFO	torchdistill.misc.log	Epoch: [10]  [11000/14658]  eta: 0:09:41  lr: 0.02  img/s: 53.76227236167056  loss: 0.8571 (0.8833)  time: 0.1582  data: 0.0131  max mem: 17059
2023-02-28 18:35:24,035	INFO	torchdistill.misc.log	Epoch: [10]  [12000/14658]  eta: 0:07:02  lr: 0.02  img/s: 59.79348934016665  loss: 0.7666 (0.8825)  time: 0.1579  data: 0.0126  max mem: 17059
2023-02-28 18:38:02,309	INFO	torchdistill.misc.log	Epoch: [10]  [13000/14658]  eta: 0:04:23  lr: 0.02  img/s: 59.53114460342946  loss: 0.8385 (0.8824)  time: 0.1574  data: 0.0133  max mem: 17059
2023-02-28 18:40:41,076	INFO	torchdistill.misc.log	Epoch: [10]  [14000/14658]  eta: 0:01:44  lr: 0.02  img/s: 56.035657684889074  loss: 0.7453 (0.8826)  time: 0.1584  data: 0.0133  max mem: 17059
2023-02-28 18:42:25,415	INFO	torchdistill.misc.log	Epoch: [10] Total time: 0:38:47
2023-02-28 18:42:29,424	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 0:58:09  model_time: 0.0839 (0.0839)  evaluator_time: 0.0278 (0.0278)  time: 0.6980  data: 0.5836  max mem: 17059
2023-02-28 18:44:09,367	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:06:42  model_time: 0.0801 (0.0833)  evaluator_time: 0.0086 (0.0158)  time: 0.0976  data: 0.0001  max mem: 17059
2023-02-28 18:45:52,925	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:06  model_time: 0.0797 (0.0835)  evaluator_time: 0.0101 (0.0174)  time: 0.1000  data: 0.0001  max mem: 17059
2023-02-28 18:47:31,735	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:21  model_time: 0.0828 (0.0832)  evaluator_time: 0.0094 (0.0167)  time: 0.0944  data: 0.0001  max mem: 17059
2023-02-28 18:49:11,361	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:40  model_time: 0.0825 (0.0832)  evaluator_time: 0.0097 (0.0165)  time: 0.1009  data: 0.0001  max mem: 17059
2023-02-28 18:50:49,624	INFO	torchdistill.misc.log	Validation: Total time: 0:08:20
2023-02-28 18:50:49,625	INFO	__main__	Averaged stats: model_time: 0.0800 (0.0831)  evaluator_time: 0.0093 (0.0161)
2023-02-28 18:50:49,848	INFO	__main__	Accumulating evaluation results...
2023-02-28 18:51:04,885	INFO	__main__	DONE (t=15.04s).
2023-02-28 18:51:04,885	INFO	__main__	IoU metric: bbox
2023-02-28 18:51:04,886	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.184
2023-02-28 18:51:04,887	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.346
2023-02-28 18:51:04,887	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.172
2023-02-28 18:51:04,888	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.049
2023-02-28 18:51:04,888	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.183
2023-02-28 18:51:04,889	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.317
2023-02-28 18:51:04,889	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.197
2023-02-28 18:51:04,889	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.297
2023-02-28 18:51:04,889	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.309
2023-02-28 18:51:04,889	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.084
2023-02-28 18:51:04,890	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.329
2023-02-28 18:51:04,890	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.517
2023-02-28 18:51:06,608	INFO	torchdistill.misc.log	Epoch: [11]  [    0/14658]  eta: 4:43:26  lr: 0.02  img/s: 55.43456611454193  loss: 0.7474 (0.7474)  time: 1.1602  data: 0.9911  max mem: 17059
2023-02-28 18:53:44,534	INFO	torchdistill.misc.log	Epoch: [11]  [ 1000/14658]  eta: 0:36:10  lr: 0.02  img/s: 58.66631232581641  loss: 0.8841 (0.8738)  time: 0.1588  data: 0.0128  max mem: 17059
2023-02-28 18:56:23,418	INFO	torchdistill.misc.log	Epoch: [11]  [ 2000/14658]  eta: 0:33:31  lr: 0.02  img/s: 59.91563278978908  loss: 0.7753 (0.8785)  time: 0.1566  data: 0.0125  max mem: 17059
2023-02-28 18:59:02,497	INFO	torchdistill.misc.log	Epoch: [11]  [ 3000/14658]  eta: 0:30:53  lr: 0.02  img/s: 59.26721834126697  loss: 0.8808 (0.8754)  time: 0.1590  data: 0.0130  max mem: 17059
2023-02-28 19:01:41,203	INFO	torchdistill.misc.log	Epoch: [11]  [ 4000/14658]  eta: 0:28:13  lr: 0.02  img/s: 63.87232552119025  loss: 0.8764 (0.8762)  time: 0.1602  data: 0.0139  max mem: 17059
2023-02-28 19:04:20,010	INFO	torchdistill.misc.log	Epoch: [11]  [ 5000/14658]  eta: 0:25:34  lr: 0.02  img/s: 59.910283924739055  loss: 0.8297 (0.8760)  time: 0.1605  data: 0.0136  max mem: 17059
2023-02-28 19:06:58,937	INFO	torchdistill.misc.log	Epoch: [11]  [ 6000/14658]  eta: 0:22:55  lr: 0.02  img/s: 59.646597482197265  loss: 0.8202 (0.8778)  time: 0.1600  data: 0.0138  max mem: 17059
2023-02-28 19:09:37,721	INFO	torchdistill.misc.log	Epoch: [11]  [ 7000/14658]  eta: 0:20:16  lr: 0.02  img/s: 58.38548820699315  loss: 0.8238 (0.8790)  time: 0.1589  data: 0.0132  max mem: 17059
2023-02-28 19:12:16,553	INFO	torchdistill.misc.log	Epoch: [11]  [ 8000/14658]  eta: 0:17:37  lr: 0.02  img/s: 63.72578929776049  loss: 0.7654 (0.8790)  time: 0.1603  data: 0.0132  max mem: 17059
2023-02-28 19:14:55,611	INFO	torchdistill.misc.log	Epoch: [11]  [ 9000/14658]  eta: 0:14:58  lr: 0.02  img/s: 59.36420925994728  loss: 0.9103 (0.8780)  time: 0.1599  data: 0.0137  max mem: 17059
2023-02-28 19:17:34,342	INFO	torchdistill.misc.log	Epoch: [11]  [10000/14658]  eta: 0:12:20  lr: 0.02  img/s: 52.227560680253895  loss: 0.8065 (0.8777)  time: 0.1600  data: 0.0130  max mem: 17059
2023-02-28 19:20:13,418	INFO	torchdistill.misc.log	Epoch: [11]  [11000/14658]  eta: 0:09:41  lr: 0.02  img/s: 60.59447335820599  loss: 0.7750 (0.8782)  time: 0.1577  data: 0.0138  max mem: 17059
2023-02-28 19:22:52,178	INFO	torchdistill.misc.log	Epoch: [11]  [12000/14658]  eta: 0:07:02  lr: 0.02  img/s: 59.98246705422199  loss: 0.9457 (0.8796)  time: 0.1570  data: 0.0138  max mem: 17059
2023-02-28 19:25:31,001	INFO	torchdistill.misc.log	Epoch: [11]  [13000/14658]  eta: 0:04:23  lr: 0.02  img/s: 60.05450188193645  loss: 0.8327 (0.8813)  time: 0.1586  data: 0.0129  max mem: 17059
2023-02-28 19:28:09,993	INFO	torchdistill.misc.log	Epoch: [11]  [14000/14658]  eta: 0:01:44  lr: 0.02  img/s: 59.16783105803853  loss: 0.7907 (0.8815)  time: 0.1596  data: 0.0138  max mem: 17059
2023-02-28 19:29:54,527	INFO	torchdistill.misc.log	Epoch: [11] Total time: 0:38:49
2023-02-28 19:29:58,540	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 0:58:20  model_time: 0.1109 (0.1109)  evaluator_time: 0.0280 (0.0280)  time: 0.7002  data: 0.5584  max mem: 17059
2023-02-28 19:31:40,008	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:06:48  model_time: 0.0816 (0.0835)  evaluator_time: 0.0098 (0.0172)  time: 0.0968  data: 0.0001  max mem: 17059
2023-02-28 19:33:24,441	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:09  model_time: 0.0771 (0.0832)  evaluator_time: 0.0125 (0.0190)  time: 0.0939  data: 0.0001  max mem: 17059
2023-02-28 19:35:04,830	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:24  model_time: 0.0820 (0.0831)  evaluator_time: 0.0114 (0.0182)  time: 0.0991  data: 0.0001  max mem: 17059
2023-02-28 19:36:44,869	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:41  model_time: 0.0826 (0.0829)  evaluator_time: 0.0102 (0.0179)  time: 0.1008  data: 0.0001  max mem: 17059
2023-02-28 19:38:24,475	INFO	torchdistill.misc.log	Validation: Total time: 0:08:26
2023-02-28 19:38:24,476	INFO	__main__	Averaged stats: model_time: 0.0803 (0.0829)  evaluator_time: 0.0104 (0.0175)
2023-02-28 19:38:24,689	INFO	__main__	Accumulating evaluation results...
2023-02-28 19:38:41,749	INFO	__main__	DONE (t=17.06s).
2023-02-28 19:38:41,749	INFO	__main__	IoU metric: bbox
2023-02-28 19:38:41,750	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.190
2023-02-28 19:38:41,751	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.352
2023-02-28 19:38:41,751	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.184
2023-02-28 19:38:41,752	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.051
2023-02-28 19:38:41,752	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.196
2023-02-28 19:38:41,753	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.322
2023-02-28 19:38:41,753	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.203
2023-02-28 19:38:41,753	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.311
2023-02-28 19:38:41,753	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.327
2023-02-28 19:38:41,753	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.099
2023-02-28 19:38:41,753	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.356
2023-02-28 19:38:41,754	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.535
2023-02-28 19:38:42,475	INFO	__main__	Best mAP (bbox): 0.1862 -> 0.1896
2023-02-28 19:38:42,476	INFO	__main__	Updating ckpt at ./resource/ckpt/coco2017/supervised_compression/entropic_student/coco2017-faster_rcnn_splittable_resnet50-fp-beta5.12_fpn.pt
2023-02-28 19:38:43,884	INFO	torchdistill.misc.log	Epoch: [12]  [    0/14658]  eta: 3:27:30  lr: 0.02  img/s: 51.748788575129936  loss: 1.0802 (1.0802)  time: 0.8494  data: 0.6839  max mem: 17059
2023-02-28 19:41:21,638	INFO	torchdistill.misc.log	Epoch: [12]  [ 1000/14658]  eta: 0:36:03  lr: 0.02  img/s: 60.820730332394405  loss: 0.7581 (0.8835)  time: 0.1560  data: 0.0122  max mem: 17059
2023-02-28 19:44:00,462	INFO	torchdistill.misc.log	Epoch: [12]  [ 2000/14658]  eta: 0:33:27  lr: 0.02  img/s: 59.00126427140865  loss: 0.8227 (0.8813)  time: 0.1565  data: 0.0132  max mem: 17059
2023-02-28 19:46:39,215	INFO	torchdistill.misc.log	Epoch: [12]  [ 3000/14658]  eta: 0:30:49  lr: 0.02  img/s: 60.16368816554573  loss: 0.8911 (0.8797)  time: 0.1596  data: 0.0126  max mem: 17059
2023-02-28 19:49:18,052	INFO	torchdistill.misc.log	Epoch: [12]  [ 4000/14658]  eta: 0:28:11  lr: 0.02  img/s: 57.2347286187016  loss: 0.8074 (0.8799)  time: 0.1589  data: 0.0136  max mem: 17059
2023-02-28 19:51:57,142	INFO	torchdistill.misc.log	Epoch: [12]  [ 5000/14658]  eta: 0:25:33  lr: 0.02  img/s: 52.534607983892556  loss: 0.7626 (0.8798)  time: 0.1596  data: 0.0130  max mem: 17059
2023-02-28 19:54:36,305	INFO	torchdistill.misc.log	Epoch: [12]  [ 6000/14658]  eta: 0:22:55  lr: 0.02  img/s: 59.18839178774724  loss: 0.9526 (0.8812)  time: 0.1610  data: 0.0138  max mem: 17059
2023-02-28 19:57:15,211	INFO	torchdistill.misc.log	Epoch: [12]  [ 7000/14658]  eta: 0:20:16  lr: 0.02  img/s: 60.22880692710315  loss: 0.8912 (0.8795)  time: 0.1575  data: 0.0129  max mem: 17059
2023-02-28 19:59:54,155	INFO	torchdistill.misc.log	Epoch: [12]  [ 8000/14658]  eta: 0:17:37  lr: 0.02  img/s: 56.1005831683698  loss: 0.9260 (0.8798)  time: 0.1606  data: 0.0141  max mem: 17059
2023-02-28 20:02:32,871	INFO	torchdistill.misc.log	Epoch: [12]  [ 9000/14658]  eta: 0:14:58  lr: 0.02  img/s: 55.16471108524494  loss: 0.9099 (0.8807)  time: 0.1590  data: 0.0133  max mem: 17059
2023-02-28 20:05:11,755	INFO	torchdistill.misc.log	Epoch: [12]  [10000/14658]  eta: 0:12:19  lr: 0.02  img/s: 57.80403317220398  loss: 0.8385 (0.8801)  time: 0.1619  data: 0.0144  max mem: 17059
2023-02-28 20:07:50,573	INFO	torchdistill.misc.log	Epoch: [12]  [11000/14658]  eta: 0:09:41  lr: 0.02  img/s: 59.644264952646395  loss: 0.8127 (0.8794)  time: 0.1592  data: 0.0137  max mem: 17059
2023-02-28 20:10:29,502	INFO	torchdistill.misc.log	Epoch: [12]  [12000/14658]  eta: 0:07:02  lr: 0.02  img/s: 53.55949106847846  loss: 0.8885 (0.8802)  time: 0.1589  data: 0.0133  max mem: 17059
2023-02-28 20:13:08,020	INFO	torchdistill.misc.log	Epoch: [12]  [13000/14658]  eta: 0:04:23  lr: 0.02  img/s: 53.55282356076844  loss: 0.8445 (0.8805)  time: 0.1601  data: 0.0130  max mem: 17059
2023-02-28 20:15:46,681	INFO	torchdistill.misc.log	Epoch: [12]  [14000/14658]  eta: 0:01:44  lr: 0.02  img/s: 58.94218807364429  loss: 0.8782 (0.8797)  time: 0.1590  data: 0.0137  max mem: 17059
2023-02-28 20:17:31,248	INFO	torchdistill.misc.log	Epoch: [12] Total time: 0:38:48
2023-02-28 20:17:35,264	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 0:57:52  model_time: 0.1015 (0.1015)  evaluator_time: 0.0328 (0.0328)  time: 0.6945  data: 0.5584  max mem: 17059
2023-02-28 20:19:19,017	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:06:57  model_time: 0.0826 (0.0841)  evaluator_time: 0.0105 (0.0189)  time: 0.0982  data: 0.0001  max mem: 17059
2023-02-28 20:20:59,666	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:07  model_time: 0.0824 (0.0838)  evaluator_time: 0.0102 (0.0176)  time: 0.0982  data: 0.0001  max mem: 17059
2023-02-28 20:22:39,459	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:23  model_time: 0.0827 (0.0837)  evaluator_time: 0.0091 (0.0170)  time: 0.0978  data: 0.0001  max mem: 17059
2023-02-28 20:24:18,474	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:40  model_time: 0.0833 (0.0834)  evaluator_time: 0.0082 (0.0166)  time: 0.0995  data: 0.0001  max mem: 17059
2023-02-28 20:25:56,630	INFO	torchdistill.misc.log	Validation: Total time: 0:08:22
2023-02-28 20:25:56,631	INFO	__main__	Averaged stats: model_time: 0.0800 (0.0831)  evaluator_time: 0.0114 (0.0164)
2023-02-28 20:25:56,863	INFO	__main__	Accumulating evaluation results...
2023-02-28 20:26:13,217	INFO	__main__	DONE (t=16.35s).
2023-02-28 20:26:13,218	INFO	__main__	IoU metric: bbox
2023-02-28 20:26:13,219	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.189
2023-02-28 20:26:13,219	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.351
2023-02-28 20:26:13,219	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.184
2023-02-28 20:26:13,220	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.046
2023-02-28 20:26:13,221	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.190
2023-02-28 20:26:13,221	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.328
2023-02-28 20:26:13,221	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.203
2023-02-28 20:26:13,222	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.307
2023-02-28 20:26:13,222	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.322
2023-02-28 20:26:13,222	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.092
2023-02-28 20:26:13,222	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.347
2023-02-28 20:26:13,222	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.530
2023-02-28 20:26:15,287	INFO	torchdistill.misc.log	Epoch: [13]  [    0/14658]  eta: 5:03:59  lr: 0.02  img/s: 54.474133480526646  loss: 1.0498 (1.0498)  time: 1.2444  data: 1.0729  max mem: 17059
2023-02-28 20:28:54,189	INFO	torchdistill.misc.log	Epoch: [13]  [ 1000/14658]  eta: 0:36:25  lr: 0.02  img/s: 53.15435697267704  loss: 0.9127 (0.8761)  time: 0.1609  data: 0.0134  max mem: 17059
2023-02-28 20:31:32,785	INFO	torchdistill.misc.log	Epoch: [13]  [ 2000/14658]  eta: 0:33:36  lr: 0.02  img/s: 60.30381921667508  loss: 0.8506 (0.8807)  time: 0.1592  data: 0.0132  max mem: 17059
2023-02-28 20:34:12,235	INFO	torchdistill.misc.log	Epoch: [13]  [ 3000/14658]  eta: 0:30:57  lr: 0.02  img/s: 59.67110006170831  loss: 0.6971 (0.8822)  time: 0.1594  data: 0.0143  max mem: 17059
2023-02-28 20:36:49,238	INFO	torchdistill.misc.log	Epoch: [13]  [ 4000/14658]  eta: 0:28:12  lr: 0.02  img/s: 59.33911850163316  loss: 0.9336 (0.8802)  time: 0.1547  data: 0.0115  max mem: 17059
2023-02-28 20:39:25,233	INFO	torchdistill.misc.log	Epoch: [13]  [ 5000/14658]  eta: 0:25:27  lr: 0.02  img/s: 52.99903650843292  loss: 0.8057 (0.8776)  time: 0.1564  data: 0.0122  max mem: 17059
2023-02-28 20:42:01,673	INFO	torchdistill.misc.log	Epoch: [13]  [ 6000/14658]  eta: 0:22:47  lr: 0.02  img/s: 67.45829798355481  loss: 0.9352 (0.8797)  time: 0.1557  data: 0.0127  max mem: 17059
2023-02-28 20:44:37,623	INFO	torchdistill.misc.log	Epoch: [13]  [ 7000/14658]  eta: 0:20:07  lr: 0.02  img/s: 60.01969745482124  loss: 0.8742 (0.8799)  time: 0.1537  data: 0.0121  max mem: 17059
2023-02-28 20:47:13,689	INFO	torchdistill.misc.log	Epoch: [13]  [ 8000/14658]  eta: 0:17:28  lr: 0.02  img/s: 61.78281467787878  loss: 0.8061 (0.8783)  time: 0.1562  data: 0.0121  max mem: 17059
2023-02-28 20:49:50,133	INFO	torchdistill.misc.log	Epoch: [13]  [ 9000/14658]  eta: 0:14:50  lr: 0.02  img/s: 60.60859245879431  loss: 0.9543 (0.8780)  time: 0.1583  data: 0.0129  max mem: 17059
2023-02-28 20:52:26,583	INFO	torchdistill.misc.log	Epoch: [13]  [10000/14658]  eta: 0:12:12  lr: 0.02  img/s: 59.61131097360572  loss: 0.9043 (0.8770)  time: 0.1555  data: 0.0125  max mem: 17059
2023-02-28 20:55:03,791	INFO	torchdistill.misc.log	Epoch: [13]  [11000/14658]  eta: 0:09:35  lr: 0.02  img/s: 53.499969705956445  loss: 0.9585 (0.8773)  time: 0.1582  data: 0.0136  max mem: 17059
2023-02-28 20:57:40,869	INFO	torchdistill.misc.log	Epoch: [13]  [12000/14658]  eta: 0:06:57  lr: 0.02  img/s: 59.4569875325154  loss: 0.8232 (0.8781)  time: 0.1576  data: 0.0124  max mem: 17059
2023-02-28 21:00:17,850	INFO	torchdistill.misc.log	Epoch: [13]  [13000/14658]  eta: 0:04:20  lr: 0.02  img/s: 57.62653321288603  loss: 0.8627 (0.8777)  time: 0.1582  data: 0.0130  max mem: 17059
2023-02-28 21:02:54,881	INFO	torchdistill.misc.log	Epoch: [13]  [14000/14658]  eta: 0:01:43  lr: 0.02  img/s: 59.862721065861706  loss: 0.8752 (0.8773)  time: 0.1594  data: 0.0139  max mem: 17059
2023-02-28 21:04:38,457	INFO	torchdistill.misc.log	Epoch: [13] Total time: 0:38:24
2023-02-28 21:04:42,439	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 0:57:30  model_time: 0.1046 (0.1046)  evaluator_time: 0.0288 (0.0288)  time: 0.6901  data: 0.5551  max mem: 17059
2023-02-28 21:06:20,966	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:06:36  model_time: 0.0823 (0.0828)  evaluator_time: 0.0081 (0.0150)  time: 0.0935  data: 0.0001  max mem: 17059
2023-02-28 21:08:02,448	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:00  model_time: 0.0819 (0.0826)  evaluator_time: 0.0093 (0.0166)  time: 0.0945  data: 0.0001  max mem: 17059
2023-02-28 21:09:40,403	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:19  model_time: 0.0824 (0.0826)  evaluator_time: 0.0092 (0.0160)  time: 0.0964  data: 0.0001  max mem: 17059
2023-02-28 21:11:18,579	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:39  model_time: 0.0816 (0.0826)  evaluator_time: 0.0090 (0.0157)  time: 0.0961  data: 0.0001  max mem: 17059
2023-02-28 21:12:57,046	INFO	torchdistill.misc.log	Validation: Total time: 0:08:15
2023-02-28 21:12:57,047	INFO	__main__	Averaged stats: model_time: 0.0797 (0.0827)  evaluator_time: 0.0099 (0.0154)
2023-02-28 21:12:57,281	INFO	__main__	Accumulating evaluation results...
2023-02-28 21:13:11,847	INFO	__main__	DONE (t=14.57s).
2023-02-28 21:13:11,848	INFO	__main__	IoU metric: bbox
2023-02-28 21:13:11,849	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.189
2023-02-28 21:13:11,849	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.352
2023-02-28 21:13:11,849	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.185
2023-02-28 21:13:11,850	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.045
2023-02-28 21:13:11,851	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.193
2023-02-28 21:13:11,852	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.330
2023-02-28 21:13:11,852	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.199
2023-02-28 21:13:11,852	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.305
2023-02-28 21:13:11,852	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.318
2023-02-28 21:13:11,852	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.087
2023-02-28 21:13:11,852	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.341
2023-02-28 21:13:11,852	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.539
2023-02-28 21:13:13,896	INFO	torchdistill.misc.log	Epoch: [14]  [    0/14658]  eta: 5:09:23  lr: 0.02  img/s: 55.91641142377208  loss: 0.6000 (0.6000)  time: 1.2664  data: 1.1124  max mem: 17059
2023-02-28 21:15:49,343	INFO	torchdistill.misc.log	Epoch: [14]  [ 1000/14658]  eta: 0:35:38  lr: 0.02  img/s: 59.8170464086881  loss: 0.8756 (0.8755)  time: 0.1569  data: 0.0122  max mem: 17059
2023-02-28 21:18:25,094	INFO	torchdistill.misc.log	Epoch: [14]  [ 2000/14658]  eta: 0:32:56  lr: 0.02  img/s: 59.71336388308048  loss: 0.9645 (0.8730)  time: 0.1563  data: 0.0118  max mem: 17059
2023-02-28 21:21:00,960	INFO	torchdistill.misc.log	Epoch: [14]  [ 3000/14658]  eta: 0:30:19  lr: 0.02  img/s: 53.701182390259206  loss: 0.8898 (0.8714)  time: 0.1571  data: 0.0122  max mem: 17059
2023-02-28 21:23:36,780	INFO	torchdistill.misc.log	Epoch: [14]  [ 4000/14658]  eta: 0:27:42  lr: 0.02  img/s: 60.41163062852205  loss: 0.9035 (0.8710)  time: 0.1566  data: 0.0118  max mem: 17059
2023-02-28 21:26:12,996	INFO	torchdistill.misc.log	Epoch: [14]  [ 5000/14658]  eta: 0:25:07  lr: 0.02  img/s: 59.82141876593393  loss: 0.8209 (0.8691)  time: 0.1545  data: 0.0117  max mem: 17059
2023-02-28 21:28:48,990	INFO	torchdistill.misc.log	Epoch: [14]  [ 6000/14658]  eta: 0:22:30  lr: 0.02  img/s: 60.200819914779096  loss: 0.8243 (0.8717)  time: 0.1591  data: 0.0129  max mem: 17059
2023-02-28 21:31:25,367	INFO	torchdistill.misc.log	Epoch: [14]  [ 7000/14658]  eta: 0:19:55  lr: 0.02  img/s: 60.12972686252092  loss: 0.8107 (0.8715)  time: 0.1571  data: 0.0127  max mem: 17059
2023-02-28 21:34:02,592	INFO	torchdistill.misc.log	Epoch: [14]  [ 8000/14658]  eta: 0:17:20  lr: 0.02  img/s: 59.64203861734065  loss: 0.8458 (0.8728)  time: 0.1571  data: 0.0135  max mem: 17059
2023-02-28 21:36:39,659	INFO	torchdistill.misc.log	Epoch: [14]  [ 9000/14658]  eta: 0:14:44  lr: 0.02  img/s: 61.74370637799086  loss: 0.7791 (0.8725)  time: 0.1551  data: 0.0126  max mem: 17059
2023-02-28 21:39:16,481	INFO	torchdistill.misc.log	Epoch: [14]  [10000/14658]  eta: 0:12:08  lr: 0.02  img/s: 60.47161993876142  loss: 0.9173 (0.8734)  time: 0.1569  data: 0.0134  max mem: 17059
2023-02-28 21:41:53,167	INFO	torchdistill.misc.log	Epoch: [14]  [11000/14658]  eta: 0:09:32  lr: 0.02  img/s: 64.75789343667495  loss: 0.8411 (0.8733)  time: 0.1574  data: 0.0125  max mem: 17059
2023-02-28 21:44:31,070	INFO	torchdistill.misc.log	Epoch: [14]  [12000/14658]  eta: 0:06:56  lr: 0.02  img/s: 59.80329364796464  loss: 0.8251 (0.8735)  time: 0.1601  data: 0.0129  max mem: 17059
2023-02-28 21:47:09,767	INFO	torchdistill.misc.log	Epoch: [14]  [13000/14658]  eta: 0:04:19  lr: 0.02  img/s: 59.79018643877527  loss: 0.8297 (0.8746)  time: 0.1583  data: 0.0128  max mem: 17059
2023-02-28 21:49:48,616	INFO	torchdistill.misc.log	Epoch: [14]  [14000/14658]  eta: 0:01:43  lr: 0.02  img/s: 61.73200625517432  loss: 0.9433 (0.8759)  time: 0.1601  data: 0.0135  max mem: 17059
2023-02-28 21:51:33,230	INFO	torchdistill.misc.log	Epoch: [14] Total time: 0:38:20
2023-02-28 21:51:37,222	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 0:57:47  model_time: 0.1036 (0.1036)  evaluator_time: 0.0279 (0.0279)  time: 0.6934  data: 0.5603  max mem: 17059
2023-02-28 21:53:18,409	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:06:47  model_time: 0.0822 (0.0832)  evaluator_time: 0.0082 (0.0172)  time: 0.0978  data: 0.0001  max mem: 17059
2023-02-28 21:55:02,652	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:09  model_time: 0.0834 (0.0832)  evaluator_time: 0.0099 (0.0188)  time: 0.1009  data: 0.0001  max mem: 17059
2023-02-28 21:56:42,969	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:24  model_time: 0.0821 (0.0830)  evaluator_time: 0.0089 (0.0181)  time: 0.0981  data: 0.0001  max mem: 17059
2023-02-28 21:58:23,589	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:41  model_time: 0.0773 (0.0830)  evaluator_time: 0.0076 (0.0178)  time: 0.0973  data: 0.0001  max mem: 17059
2023-02-28 22:00:04,022	INFO	torchdistill.misc.log	Validation: Total time: 0:08:27
2023-02-28 22:00:04,022	INFO	__main__	Averaged stats: model_time: 0.0794 (0.0831)  evaluator_time: 0.0105 (0.0175)
2023-02-28 22:00:04,249	INFO	__main__	Accumulating evaluation results...
2023-02-28 22:00:20,345	INFO	__main__	DONE (t=16.10s).
2023-02-28 22:00:20,345	INFO	__main__	IoU metric: bbox
2023-02-28 22:00:20,346	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.188
2023-02-28 22:00:20,346	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.352
2023-02-28 22:00:20,347	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.181
2023-02-28 22:00:20,348	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.048
2023-02-28 22:00:20,348	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.195
2023-02-28 22:00:20,349	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.323
2023-02-28 22:00:20,349	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.202
2023-02-28 22:00:20,349	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.304
2023-02-28 22:00:20,349	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.317
2023-02-28 22:00:20,350	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.089
2023-02-28 22:00:20,350	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.341
2023-02-28 22:00:20,350	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.528
2023-02-28 22:00:22,364	INFO	torchdistill.misc.log	Epoch: [15]  [    0/14658]  eta: 5:09:29  lr: 0.02  img/s: 54.17343866294041  loss: 0.6358 (0.6358)  time: 1.2668  data: 1.0907  max mem: 17059
2023-02-28 22:02:59,600	INFO	torchdistill.misc.log	Epoch: [15]  [ 1000/14658]  eta: 0:36:02  lr: 0.02  img/s: 62.1670785888177  loss: 0.7560 (0.8705)  time: 0.1559  data: 0.0117  max mem: 17059
2023-02-28 22:05:36,891	INFO	torchdistill.misc.log	Epoch: [15]  [ 2000/14658]  eta: 0:33:17  lr: 0.02  img/s: 59.77783043153715  loss: 0.8638 (0.8751)  time: 0.1583  data: 0.0132  max mem: 17059
2023-02-28 22:08:15,367	INFO	torchdistill.misc.log	Epoch: [15]  [ 3000/14658]  eta: 0:30:42  lr: 0.02  img/s: 59.74409047853058  loss: 0.7604 (0.8751)  time: 0.1588  data: 0.0134  max mem: 17059
2023-02-28 22:10:53,945	INFO	torchdistill.misc.log	Epoch: [15]  [ 4000/14658]  eta: 0:28:05  lr: 0.02  img/s: 58.30827885574474  loss: 0.7162 (0.8765)  time: 0.1604  data: 0.0130  max mem: 17059
2023-02-28 22:13:32,754	INFO	torchdistill.misc.log	Epoch: [15]  [ 5000/14658]  eta: 0:25:28  lr: 0.02  img/s: 59.37460871904037  loss: 0.9048 (0.8758)  time: 0.1614  data: 0.0135  max mem: 17059
2023-02-28 22:16:11,460	INFO	torchdistill.misc.log	Epoch: [15]  [ 6000/14658]  eta: 0:22:51  lr: 0.02  img/s: 53.616574680979575  loss: 0.9203 (0.8760)  time: 0.1592  data: 0.0135  max mem: 17059
2023-02-28 22:18:50,208	INFO	torchdistill.misc.log	Epoch: [15]  [ 7000/14658]  eta: 0:20:13  lr: 0.02  img/s: 60.533475732078685  loss: 0.8338 (0.8755)  time: 0.1613  data: 0.0140  max mem: 17059
2023-02-28 22:21:28,643	INFO	torchdistill.misc.log	Epoch: [15]  [ 8000/14658]  eta: 0:17:34  lr: 0.02  img/s: 60.14805042089111  loss: 0.7940 (0.8737)  time: 0.1580  data: 0.0126  max mem: 17059
2023-02-28 22:24:07,216	INFO	torchdistill.misc.log	Epoch: [15]  [ 9000/14658]  eta: 0:14:56  lr: 0.02  img/s: 59.67481433002305  loss: 0.8443 (0.8732)  time: 0.1595  data: 0.0137  max mem: 17059
2023-02-28 22:26:45,889	INFO	torchdistill.misc.log	Epoch: [15]  [10000/14658]  eta: 0:12:18  lr: 0.02  img/s: 60.43143244099934  loss: 0.8247 (0.8748)  time: 0.1587  data: 0.0133  max mem: 17059
2023-02-28 22:29:24,751	INFO	torchdistill.misc.log	Epoch: [15]  [11000/14658]  eta: 0:09:39  lr: 0.02  img/s: 52.539543506547396  loss: 0.8350 (0.8744)  time: 0.1595  data: 0.0132  max mem: 17059
2023-02-28 22:32:03,598	INFO	torchdistill.misc.log	Epoch: [15]  [12000/14658]  eta: 0:07:01  lr: 0.02  img/s: 61.49938233817077  loss: 0.8335 (0.8758)  time: 0.1570  data: 0.0133  max mem: 17059
2023-02-28 22:34:42,221	INFO	torchdistill.misc.log	Epoch: [15]  [13000/14658]  eta: 0:04:22  lr: 0.02  img/s: 53.02131317472758  loss: 0.8729 (0.8760)  time: 0.1589  data: 0.0135  max mem: 17059
2023-02-28 22:37:20,942	INFO	torchdistill.misc.log	Epoch: [15]  [14000/14658]  eta: 0:01:44  lr: 0.02  img/s: 54.085855394653706  loss: 0.8381 (0.8765)  time: 0.1602  data: 0.0130  max mem: 17059
2023-02-28 22:39:05,623	INFO	torchdistill.misc.log	Epoch: [15] Total time: 0:38:44
2023-02-28 22:39:09,636	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 1:02:30  model_time: 0.1183 (0.1183)  evaluator_time: 0.0399 (0.0399)  time: 0.7501  data: 0.5898  max mem: 17059
2023-02-28 22:40:49,369	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:06:41  model_time: 0.0820 (0.0840)  evaluator_time: 0.0074 (0.0150)  time: 0.0966  data: 0.0001  max mem: 17059
2023-02-28 22:42:29,043	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:00  model_time: 0.0823 (0.0837)  evaluator_time: 0.0105 (0.0152)  time: 0.0976  data: 0.0001  max mem: 17059
2023-02-28 22:44:10,554	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:21  model_time: 0.0861 (0.0836)  evaluator_time: 0.0087 (0.0159)  time: 0.0995  data: 0.0001  max mem: 17059
2023-02-28 22:45:48,172	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:39  model_time: 0.0821 (0.0833)  evaluator_time: 0.0077 (0.0155)  time: 0.0988  data: 0.0001  max mem: 17059
2023-02-28 22:47:25,834	INFO	torchdistill.misc.log	Validation: Total time: 0:08:16
2023-02-28 22:47:25,835	INFO	__main__	Averaged stats: model_time: 0.0797 (0.0832)  evaluator_time: 0.0085 (0.0152)
2023-02-28 22:47:26,058	INFO	__main__	Accumulating evaluation results...
2023-02-28 22:47:39,394	INFO	__main__	DONE (t=13.34s).
2023-02-28 22:47:39,394	INFO	__main__	IoU metric: bbox
2023-02-28 22:47:39,395	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.192
2023-02-28 22:47:39,396	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.355
2023-02-28 22:47:39,396	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.189
2023-02-28 22:47:39,397	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.048
2023-02-28 22:47:39,398	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.199
2023-02-28 22:47:39,399	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.329
2023-02-28 22:47:39,399	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.204
2023-02-28 22:47:39,400	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.305
2023-02-28 22:47:39,400	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.316
2023-02-28 22:47:39,400	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.088
2023-02-28 22:47:39,400	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.336
2023-02-28 22:47:39,400	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.527
2023-02-28 22:47:40,190	INFO	__main__	Best mAP (bbox): 0.1896 -> 0.1919
2023-02-28 22:47:40,192	INFO	__main__	Updating ckpt at ./resource/ckpt/coco2017/supervised_compression/entropic_student/coco2017-faster_rcnn_splittable_resnet50-fp-beta5.12_fpn.pt
2023-02-28 22:47:41,636	INFO	torchdistill.misc.log	Epoch: [16]  [    0/14658]  eta: 3:34:25  lr: 0.002  img/s: 52.64563420588549  loss: 0.5690 (0.5690)  time: 0.8777  data: 0.7140  max mem: 17059
2023-02-28 22:50:19,105	INFO	torchdistill.misc.log	Epoch: [16]  [ 1000/14658]  eta: 0:36:00  lr: 0.002  img/s: 58.93162902038888  loss: 0.7622 (0.8324)  time: 0.1547  data: 0.0121  max mem: 17059
2023-02-28 22:52:56,283	INFO	torchdistill.misc.log	Epoch: [16]  [ 2000/14658]  eta: 0:33:15  lr: 0.002  img/s: 58.595520785128656  loss: 0.7767 (0.8314)  time: 0.1572  data: 0.0125  max mem: 17059
2023-02-28 22:55:35,039	INFO	torchdistill.misc.log	Epoch: [16]  [ 3000/14658]  eta: 0:30:42  lr: 0.002  img/s: 60.12983461551557  loss: 0.7354 (0.8300)  time: 0.1588  data: 0.0130  max mem: 17059
2023-02-28 22:58:14,140	INFO	torchdistill.misc.log	Epoch: [16]  [ 4000/14658]  eta: 0:28:07  lr: 0.002  img/s: 59.17555270249298  loss: 0.7787 (0.8289)  time: 0.1595  data: 0.0135  max mem: 17059
2023-02-28 23:00:53,324	INFO	torchdistill.misc.log	Epoch: [16]  [ 5000/14658]  eta: 0:25:30  lr: 0.002  img/s: 61.62611206206243  loss: 0.7942 (0.8268)  time: 0.1588  data: 0.0130  max mem: 17059
2023-02-28 23:03:32,373	INFO	torchdistill.misc.log	Epoch: [16]  [ 6000/14658]  eta: 0:22:52  lr: 0.002  img/s: 58.19178728378233  loss: 0.8472 (0.8282)  time: 0.1595  data: 0.0134  max mem: 17059
2023-02-28 23:06:11,110	INFO	torchdistill.misc.log	Epoch: [16]  [ 7000/14658]  eta: 0:20:14  lr: 0.002  img/s: 60.35805678124488  loss: 0.8466 (0.8270)  time: 0.1576  data: 0.0128  max mem: 17059
2023-02-28 23:08:50,190	INFO	torchdistill.misc.log	Epoch: [16]  [ 8000/14658]  eta: 0:17:36  lr: 0.002  img/s: 58.987572933642035  loss: 0.8902 (0.8261)  time: 0.1594  data: 0.0136  max mem: 17059
2023-02-28 23:11:29,221	INFO	torchdistill.misc.log	Epoch: [16]  [ 9000/14658]  eta: 0:14:57  lr: 0.002  img/s: 58.97326605469114  loss: 0.8485 (0.8258)  time: 0.1607  data: 0.0139  max mem: 17059
2023-02-28 23:14:08,755	INFO	torchdistill.misc.log	Epoch: [16]  [10000/14658]  eta: 0:12:19  lr: 0.002  img/s: 59.39625968048856  loss: 0.7657 (0.8261)  time: 0.1621  data: 0.0136  max mem: 17059
2023-02-28 23:16:48,043	INFO	torchdistill.misc.log	Epoch: [16]  [11000/14658]  eta: 0:09:40  lr: 0.002  img/s: 59.4389772532014  loss: 0.8560 (0.8259)  time: 0.1611  data: 0.0134  max mem: 17059
2023-02-28 23:19:27,625	INFO	torchdistill.misc.log	Epoch: [16]  [12000/14658]  eta: 0:07:02  lr: 0.002  img/s: 57.77218554904736  loss: 0.7426 (0.8259)  time: 0.1568  data: 0.0128  max mem: 17059
2023-02-28 23:22:06,864	INFO	torchdistill.misc.log	Epoch: [16]  [13000/14658]  eta: 0:04:23  lr: 0.002  img/s: 59.215445160151766  loss: 0.8252 (0.8251)  time: 0.1595  data: 0.0131  max mem: 17059
2023-02-28 23:24:46,032	INFO	torchdistill.misc.log	Epoch: [16]  [14000/14658]  eta: 0:01:44  lr: 0.002  img/s: 52.94033599656683  loss: 0.8063 (0.8251)  time: 0.1595  data: 0.0128  max mem: 17059
2023-02-28 23:26:30,859	INFO	torchdistill.misc.log	Epoch: [16] Total time: 0:38:50
2023-02-28 23:26:34,877	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 0:57:51  model_time: 0.1067 (0.1067)  evaluator_time: 0.0300 (0.0300)  time: 0.6943  data: 0.5561  max mem: 17059
2023-02-28 23:28:16,449	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:06:48  model_time: 0.0817 (0.0842)  evaluator_time: 0.0090 (0.0166)  time: 0.0982  data: 0.0001  max mem: 17059
2023-02-28 23:29:57,937	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:05  model_time: 0.0778 (0.0839)  evaluator_time: 0.0108 (0.0168)  time: 0.0962  data: 0.0002  max mem: 17059
2023-02-28 23:31:40,863	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:24  model_time: 0.0856 (0.0837)  evaluator_time: 0.0099 (0.0175)  time: 0.0995  data: 0.0001  max mem: 17059
2023-02-28 23:33:20,853	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:41  model_time: 0.0808 (0.0835)  evaluator_time: 0.0091 (0.0172)  time: 0.0986  data: 0.0001  max mem: 17059
2023-02-28 23:34:59,679	INFO	torchdistill.misc.log	Validation: Total time: 0:08:25
2023-02-28 23:34:59,680	INFO	__main__	Averaged stats: model_time: 0.0802 (0.0832)  evaluator_time: 0.0098 (0.0169)
2023-02-28 23:34:59,925	INFO	__main__	Accumulating evaluation results...
2023-02-28 23:35:16,132	INFO	__main__	DONE (t=16.21s).
2023-02-28 23:35:16,132	INFO	__main__	IoU metric: bbox
2023-02-28 23:35:16,133	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.220
2023-02-28 23:35:16,134	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.388
2023-02-28 23:35:16,134	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.222
2023-02-28 23:35:16,135	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.064
2023-02-28 23:35:16,135	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.230
2023-02-28 23:35:16,136	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.368
2023-02-28 23:35:16,136	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.225
2023-02-28 23:35:16,136	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.342
2023-02-28 23:35:16,136	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.358
2023-02-28 23:35:16,136	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.113
2023-02-28 23:35:16,136	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.395
2023-02-28 23:35:16,137	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.579
2023-02-28 23:35:16,787	INFO	__main__	Best mAP (bbox): 0.1919 -> 0.2200
2023-02-28 23:35:16,789	INFO	__main__	Updating ckpt at ./resource/ckpt/coco2017/supervised_compression/entropic_student/coco2017-faster_rcnn_splittable_resnet50-fp-beta5.12_fpn.pt
2023-02-28 23:35:18,171	INFO	torchdistill.misc.log	Epoch: [17]  [    0/14658]  eta: 3:22:17  lr: 0.002  img/s: 52.893769290670804  loss: 0.6262 (0.6262)  time: 0.8281  data: 0.6660  max mem: 17059
2023-02-28 23:37:55,359	INFO	torchdistill.misc.log	Epoch: [17]  [ 1000/14658]  eta: 0:35:55  lr: 0.002  img/s: 66.09249363291306  loss: 0.8203 (0.8109)  time: 0.1597  data: 0.0126  max mem: 17059
2023-02-28 23:40:33,849	INFO	torchdistill.misc.log	Epoch: [17]  [ 2000/14658]  eta: 0:33:22  lr: 0.002  img/s: 59.26522941710499  loss: 1.0025 (0.8137)  time: 0.1612  data: 0.0137  max mem: 17059
2023-02-28 23:43:12,522	INFO	torchdistill.misc.log	Epoch: [17]  [ 3000/14658]  eta: 0:30:45  lr: 0.002  img/s: 57.3174403072014  loss: 0.8373 (0.8189)  time: 0.1585  data: 0.0129  max mem: 17059
2023-02-28 23:45:51,228	INFO	torchdistill.misc.log	Epoch: [17]  [ 4000/14658]  eta: 0:28:08  lr: 0.002  img/s: 59.198729733067516  loss: 0.8242 (0.8213)  time: 0.1607  data: 0.0146  max mem: 17059
2023-02-28 23:48:30,174	INFO	torchdistill.misc.log	Epoch: [17]  [ 5000/14658]  eta: 0:25:31  lr: 0.002  img/s: 60.584189163813896  loss: 0.7534 (0.8209)  time: 0.1598  data: 0.0135  max mem: 17059
2023-02-28 23:51:09,042	INFO	torchdistill.misc.log	Epoch: [17]  [ 6000/14658]  eta: 0:22:53  lr: 0.002  img/s: 59.31425864318215  loss: 0.7502 (0.8196)  time: 0.1577  data: 0.0131  max mem: 17059
2023-02-28 23:53:47,950	INFO	torchdistill.misc.log	Epoch: [17]  [ 7000/14658]  eta: 0:20:14  lr: 0.002  img/s: 58.980625973359395  loss: 0.7594 (0.8189)  time: 0.1598  data: 0.0137  max mem: 17059
2023-02-28 23:56:26,698	INFO	torchdistill.misc.log	Epoch: [17]  [ 8000/14658]  eta: 0:17:36  lr: 0.002  img/s: 59.70815731688655  loss: 0.8486 (0.8186)  time: 0.1590  data: 0.0132  max mem: 17059
2023-02-28 23:59:05,632	INFO	torchdistill.misc.log	Epoch: [17]  [ 9000/14658]  eta: 0:14:57  lr: 0.002  img/s: 62.61744024603257  loss: 0.8269 (0.8184)  time: 0.1585  data: 0.0132  max mem: 17059
2023-03-01 00:01:44,157	INFO	torchdistill.misc.log	Epoch: [17]  [10000/14658]  eta: 0:12:19  lr: 0.002  img/s: 61.81456973162572  loss: 0.8695 (0.8178)  time: 0.1592  data: 0.0138  max mem: 17059
2023-03-01 00:04:22,992	INFO	torchdistill.misc.log	Epoch: [17]  [11000/14658]  eta: 0:09:40  lr: 0.002  img/s: 60.28345109960098  loss: 0.8336 (0.8185)  time: 0.1588  data: 0.0130  max mem: 17059
2023-03-01 00:07:02,357	INFO	torchdistill.misc.log	Epoch: [17]  [12000/14658]  eta: 0:07:01  lr: 0.002  img/s: 60.731124255214404  loss: 0.8733 (0.8184)  time: 0.1600  data: 0.0133  max mem: 17059
2023-03-01 00:09:41,285	INFO	torchdistill.misc.log	Epoch: [17]  [13000/14658]  eta: 0:04:23  lr: 0.002  img/s: 59.826965114164366  loss: 0.7506 (0.8177)  time: 0.1609  data: 0.0141  max mem: 17059
2023-03-01 00:12:20,213	INFO	torchdistill.misc.log	Epoch: [17]  [14000/14658]  eta: 0:01:44  lr: 0.002  img/s: 59.137277295166186  loss: 0.7348 (0.8175)  time: 0.1580  data: 0.0124  max mem: 17059
2023-03-01 00:14:04,818	INFO	torchdistill.misc.log	Epoch: [17] Total time: 0:38:47
2023-03-01 00:14:08,910	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 1:03:36  model_time: 0.1069 (0.1069)  evaluator_time: 0.0413 (0.0413)  time: 0.7633  data: 0.6089  max mem: 17059
2023-03-01 00:15:49,977	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:06:46  model_time: 0.0800 (0.0842)  evaluator_time: 0.0086 (0.0161)  time: 0.0979  data: 0.0001  max mem: 17059
2023-03-01 00:17:30,100	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:02  model_time: 0.0784 (0.0834)  evaluator_time: 0.0101 (0.0164)  time: 0.0926  data: 0.0001  max mem: 17059
2023-03-01 00:19:10,120	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:21  model_time: 0.0860 (0.0835)  evaluator_time: 0.0089 (0.0161)  time: 0.1016  data: 0.0001  max mem: 17059
2023-03-01 00:20:51,974	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:40  model_time: 0.0818 (0.0832)  evaluator_time: 0.0092 (0.0167)  time: 0.0972  data: 0.0001  max mem: 17059
2023-03-01 00:22:30,766	INFO	torchdistill.misc.log	Validation: Total time: 0:08:22
2023-03-01 00:22:30,766	INFO	__main__	Averaged stats: model_time: 0.0797 (0.0832)  evaluator_time: 0.0091 (0.0164)
2023-03-01 00:22:31,000	INFO	__main__	Accumulating evaluation results...
2023-03-01 00:22:46,012	INFO	__main__	DONE (t=15.01s).
2023-03-01 00:22:46,013	INFO	__main__	IoU metric: bbox
2023-03-01 00:22:46,014	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.224
2023-03-01 00:22:46,014	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.393
2023-03-01 00:22:46,014	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.226
2023-03-01 00:22:46,015	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.065
2023-03-01 00:22:46,016	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.235
2023-03-01 00:22:46,017	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.376
2023-03-01 00:22:46,017	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.225
2023-03-01 00:22:46,017	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.342
2023-03-01 00:22:46,017	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.358
2023-03-01 00:22:46,017	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.111
2023-03-01 00:22:46,017	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.391
2023-03-01 00:22:46,017	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.585
2023-03-01 00:22:46,829	INFO	__main__	Best mAP (bbox): 0.2200 -> 0.2239
2023-03-01 00:22:46,831	INFO	__main__	Updating ckpt at ./resource/ckpt/coco2017/supervised_compression/entropic_student/coco2017-faster_rcnn_splittable_resnet50-fp-beta5.12_fpn.pt
2023-03-01 00:22:48,529	INFO	torchdistill.misc.log	Epoch: [18]  [    0/14658]  eta: 3:41:13  lr: 0.002  img/s: 53.25660739113597  loss: 1.0063 (1.0063)  time: 0.9056  data: 0.7397  max mem: 17059
2023-03-01 00:25:26,970	INFO	torchdistill.misc.log	Epoch: [18]  [ 1000/14658]  eta: 0:36:14  lr: 0.002  img/s: 60.37847535246115  loss: 0.7714 (0.8135)  time: 0.1608  data: 0.0138  max mem: 17059
2023-03-01 00:28:06,479	INFO	torchdistill.misc.log	Epoch: [18]  [ 2000/14658]  eta: 0:33:36  lr: 0.002  img/s: 63.49630521130785  loss: 0.7272 (0.8102)  time: 0.1564  data: 0.0125  max mem: 17059
2023-03-01 00:30:46,119	INFO	torchdistill.misc.log	Epoch: [18]  [ 3000/14658]  eta: 0:30:58  lr: 0.002  img/s: 53.14484373044948  loss: 0.7311 (0.8135)  time: 0.1605  data: 0.0133  max mem: 17059
2023-03-01 00:33:25,420	INFO	torchdistill.misc.log	Epoch: [18]  [ 4000/14658]  eta: 0:28:18  lr: 0.002  img/s: 59.39415695333174  loss: 0.6936 (0.8096)  time: 0.1585  data: 0.0132  max mem: 17059
2023-03-01 00:36:04,910	INFO	torchdistill.misc.log	Epoch: [18]  [ 5000/14658]  eta: 0:25:39  lr: 0.002  img/s: 58.975442740739176  loss: 0.7568 (0.8102)  time: 0.1599  data: 0.0135  max mem: 17059
2023-03-01 00:38:44,649	INFO	torchdistill.misc.log	Epoch: [18]  [ 6000/14658]  eta: 0:23:00  lr: 0.002  img/s: 59.734411911836176  loss: 0.8949 (0.8107)  time: 0.1611  data: 0.0135  max mem: 17059
2023-03-01 00:41:24,627	INFO	torchdistill.misc.log	Epoch: [18]  [ 7000/14658]  eta: 0:20:21  lr: 0.002  img/s: 60.98565981221442  loss: 0.8969 (0.8127)  time: 0.1593  data: 0.0135  max mem: 17059
2023-03-01 00:44:03,884	INFO	torchdistill.misc.log	Epoch: [18]  [ 8000/14658]  eta: 0:17:42  lr: 0.002  img/s: 60.2909250335105  loss: 0.7574 (0.8121)  time: 0.1583  data: 0.0130  max mem: 17059
2023-03-01 00:46:43,346	INFO	torchdistill.misc.log	Epoch: [18]  [ 9000/14658]  eta: 0:15:02  lr: 0.002  img/s: 59.49831547141976  loss: 0.8224 (0.8117)  time: 0.1598  data: 0.0135  max mem: 17059
2023-03-01 00:49:22,676	INFO	torchdistill.misc.log	Epoch: [18]  [10000/14658]  eta: 0:12:22  lr: 0.002  img/s: 59.564961611858166  loss: 0.8572 (0.8129)  time: 0.1592  data: 0.0137  max mem: 17059
2023-03-01 00:52:01,877	INFO	torchdistill.misc.log	Epoch: [18]  [11000/14658]  eta: 0:09:43  lr: 0.002  img/s: 59.00665957390685  loss: 0.7265 (0.8130)  time: 0.1595  data: 0.0131  max mem: 17059
2023-03-01 00:54:40,846	INFO	torchdistill.misc.log	Epoch: [18]  [12000/14658]  eta: 0:07:03  lr: 0.002  img/s: 59.299164089422995  loss: 0.7756 (0.8131)  time: 0.1588  data: 0.0133  max mem: 17059
2023-03-01 00:57:19,646	INFO	torchdistill.misc.log	Epoch: [18]  [13000/14658]  eta: 0:04:24  lr: 0.002  img/s: 58.52010261901731  loss: 0.8003 (0.8131)  time: 0.1583  data: 0.0135  max mem: 17059
2023-03-01 00:59:59,199	INFO	torchdistill.misc.log	Epoch: [18]  [14000/14658]  eta: 0:01:44  lr: 0.002  img/s: 52.7535641291702  loss: 0.8700 (0.8134)  time: 0.1621  data: 0.0134  max mem: 17059
2023-03-01 01:01:44,239	INFO	torchdistill.misc.log	Epoch: [18] Total time: 0:38:56
2023-03-01 01:01:48,289	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 0:59:10  model_time: 0.1153 (0.1153)  evaluator_time: 0.0284 (0.0284)  time: 0.7100  data: 0.5646  max mem: 17059
2023-03-01 01:03:29,156	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:06:45  model_time: 0.0814 (0.0836)  evaluator_time: 0.0084 (0.0165)  time: 0.0969  data: 0.0001  max mem: 17059
2023-03-01 01:05:09,946	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:03  model_time: 0.0792 (0.0833)  evaluator_time: 0.0104 (0.0167)  time: 0.0963  data: 0.0001  max mem: 17059
2023-03-01 01:06:49,758	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:21  model_time: 0.0840 (0.0832)  evaluator_time: 0.0096 (0.0165)  time: 0.0980  data: 0.0001  max mem: 17059
2023-03-01 01:08:29,823	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:40  model_time: 0.0817 (0.0832)  evaluator_time: 0.0106 (0.0164)  time: 0.0976  data: 0.0001  max mem: 17059
2023-03-01 01:10:12,044	INFO	torchdistill.misc.log	Validation: Total time: 0:08:24
2023-03-01 01:10:12,045	INFO	__main__	Averaged stats: model_time: 0.0800 (0.0831)  evaluator_time: 0.0102 (0.0168)
2023-03-01 01:10:12,275	INFO	__main__	Accumulating evaluation results...
2023-03-01 01:10:28,361	INFO	__main__	DONE (t=16.09s).
2023-03-01 01:10:28,361	INFO	__main__	IoU metric: bbox
2023-03-01 01:10:28,362	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.223
2023-03-01 01:10:28,363	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.393
2023-03-01 01:10:28,363	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.226
2023-03-01 01:10:28,364	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.065
2023-03-01 01:10:28,364	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.233
2023-03-01 01:10:28,365	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.369
2023-03-01 01:10:28,365	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.226
2023-03-01 01:10:28,365	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.345
2023-03-01 01:10:28,365	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.361
2023-03-01 01:10:28,365	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.119
2023-03-01 01:10:28,366	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.397
2023-03-01 01:10:28,366	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.582
2023-03-01 01:10:30,399	INFO	torchdistill.misc.log	Epoch: [19]  [    0/14658]  eta: 5:26:20  lr: 0.002  img/s: 55.097318075608825  loss: 1.0277 (1.0277)  time: 1.3358  data: 1.1628  max mem: 17059
2023-03-01 01:13:09,077	INFO	torchdistill.misc.log	Epoch: [19]  [ 1000/14658]  eta: 0:36:23  lr: 0.002  img/s: 53.476948184414525  loss: 0.7294 (0.8203)  time: 0.1590  data: 0.0127  max mem: 17059
2023-03-01 01:15:48,105	INFO	torchdistill.misc.log	Epoch: [19]  [ 2000/14658]  eta: 0:33:38  lr: 0.002  img/s: 60.13942617897137  loss: 0.7990 (0.8147)  time: 0.1581  data: 0.0131  max mem: 17059
2023-03-01 01:18:27,157	INFO	torchdistill.misc.log	Epoch: [19]  [ 3000/14658]  eta: 0:30:57  lr: 0.002  img/s: 52.93849848068434  loss: 0.8484 (0.8123)  time: 0.1578  data: 0.0135  max mem: 17059
2023-03-01 01:21:05,816	INFO	torchdistill.misc.log	Epoch: [19]  [ 4000/14658]  eta: 0:28:16  lr: 0.002  img/s: 59.95760101208643  loss: 0.7440 (0.8133)  time: 0.1594  data: 0.0134  max mem: 17059
2023-03-01 01:23:44,945	INFO	torchdistill.misc.log	Epoch: [19]  [ 5000/14658]  eta: 0:25:36  lr: 0.002  img/s: 58.89707975770256  loss: 0.8249 (0.8138)  time: 0.1595  data: 0.0129  max mem: 17059
2023-03-01 01:26:23,659	INFO	torchdistill.misc.log	Epoch: [19]  [ 6000/14658]  eta: 0:22:57  lr: 0.002  img/s: 59.55185296273487  loss: 0.7998 (0.8141)  time: 0.1568  data: 0.0127  max mem: 17059
2023-03-01 01:29:02,304	INFO	torchdistill.misc.log	Epoch: [19]  [ 7000/14658]  eta: 0:20:17  lr: 0.002  img/s: 59.8231252250871  loss: 0.6803 (0.8124)  time: 0.1575  data: 0.0128  max mem: 17059
2023-03-01 01:31:40,928	INFO	torchdistill.misc.log	Epoch: [19]  [ 8000/14658]  eta: 0:17:38  lr: 0.002  img/s: 57.53730342588957  loss: 0.8392 (0.8119)  time: 0.1593  data: 0.0128  max mem: 17059
2023-03-01 01:34:19,668	INFO	torchdistill.misc.log	Epoch: [19]  [ 9000/14658]  eta: 0:14:59  lr: 0.002  img/s: 57.430355850019595  loss: 0.7987 (0.8119)  time: 0.1593  data: 0.0136  max mem: 17059
2023-03-01 01:36:58,727	INFO	torchdistill.misc.log	Epoch: [19]  [10000/14658]  eta: 0:12:20  lr: 0.002  img/s: 59.06461748609833  loss: 0.7208 (0.8118)  time: 0.1589  data: 0.0127  max mem: 17059
2023-03-01 01:39:37,494	INFO	torchdistill.misc.log	Epoch: [19]  [11000/14658]  eta: 0:09:41  lr: 0.002  img/s: 58.776887531136246  loss: 0.7345 (0.8112)  time: 0.1560  data: 0.0127  max mem: 17059
2023-03-01 01:42:16,471	INFO	torchdistill.misc.log	Epoch: [19]  [12000/14658]  eta: 0:07:02  lr: 0.002  img/s: 59.136130840133234  loss: 0.7382 (0.8114)  time: 0.1594  data: 0.0132  max mem: 17059
2023-03-01 01:44:55,723	INFO	torchdistill.misc.log	Epoch: [19]  [13000/14658]  eta: 0:04:23  lr: 0.002  img/s: 58.60309376479074  loss: 0.8544 (0.8120)  time: 0.1597  data: 0.0133  max mem: 17059
2023-03-01 01:47:34,346	INFO	torchdistill.misc.log	Epoch: [19]  [14000/14658]  eta: 0:01:44  lr: 0.002  img/s: 60.247082756528  loss: 0.7423 (0.8115)  time: 0.1586  data: 0.0129  max mem: 17059
2023-03-01 01:49:19,277	INFO	torchdistill.misc.log	Epoch: [19] Total time: 0:38:50
2023-03-01 01:49:23,270	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 0:56:36  model_time: 0.0956 (0.0956)  evaluator_time: 0.0290 (0.0290)  time: 0.6794  data: 0.5534  max mem: 17059
2023-03-01 01:51:04,416	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:06:46  model_time: 0.0775 (0.0836)  evaluator_time: 0.0092 (0.0168)  time: 0.0958  data: 0.0001  max mem: 17059
2023-03-01 01:52:45,711	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:04  model_time: 0.0823 (0.0834)  evaluator_time: 0.0101 (0.0170)  time: 0.0983  data: 0.0001  max mem: 17059
2023-03-01 01:54:25,676	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:21  model_time: 0.0817 (0.0832)  evaluator_time: 0.0105 (0.0168)  time: 0.0989  data: 0.0001  max mem: 17059
2023-03-01 01:56:04,964	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:40  model_time: 0.0802 (0.0829)  evaluator_time: 0.0091 (0.0167)  time: 0.0974  data: 0.0001  max mem: 17059
2023-03-01 01:57:47,115	INFO	torchdistill.misc.log	Validation: Total time: 0:08:24
2023-03-01 01:57:47,115	INFO	__main__	Averaged stats: model_time: 0.0793 (0.0828)  evaluator_time: 0.0104 (0.0171)
2023-03-01 01:57:47,352	INFO	__main__	Accumulating evaluation results...
2023-03-01 01:58:03,993	INFO	__main__	DONE (t=16.64s).
2023-03-01 01:58:03,993	INFO	__main__	IoU metric: bbox
2023-03-01 01:58:03,994	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.223
2023-03-01 01:58:03,994	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.393
2023-03-01 01:58:03,994	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.225
2023-03-01 01:58:03,995	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.064
2023-03-01 01:58:03,996	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.234
2023-03-01 01:58:03,997	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.372
2023-03-01 01:58:03,997	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.227
2023-03-01 01:58:03,997	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.345
2023-03-01 01:58:03,997	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.362
2023-03-01 01:58:03,997	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.117
2023-03-01 01:58:03,997	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.396
2023-03-01 01:58:03,997	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.581
2023-03-01 01:58:06,142	INFO	torchdistill.misc.log	Epoch: [20]  [    0/14658]  eta: 5:32:43  lr: 0.002  img/s: 53.96156128532166  loss: 0.9253 (0.9253)  time: 1.3619  data: 1.1845  max mem: 17059
2023-03-01 02:00:44,128	INFO	torchdistill.misc.log	Epoch: [20]  [ 1000/14658]  eta: 0:36:14  lr: 0.002  img/s: 59.624551764333766  loss: 0.7103 (0.8043)  time: 0.1590  data: 0.0127  max mem: 17059
2023-03-01 02:03:23,554	INFO	torchdistill.misc.log	Epoch: [20]  [ 2000/14658]  eta: 0:33:36  lr: 0.002  img/s: 57.127637441496596  loss: 0.7362 (0.8022)  time: 0.1615  data: 0.0128  max mem: 17059
2023-03-01 02:06:02,862	INFO	torchdistill.misc.log	Epoch: [20]  [ 3000/14658]  eta: 0:30:57  lr: 0.002  img/s: 59.871266123405945  loss: 0.8993 (0.8071)  time: 0.1602  data: 0.0133  max mem: 17059
2023-03-01 02:08:41,888	INFO	torchdistill.misc.log	Epoch: [20]  [ 4000/14658]  eta: 0:28:17  lr: 0.002  img/s: 59.321389298455905  loss: 0.7728 (0.8062)  time: 0.1580  data: 0.0129  max mem: 17059
2023-03-01 02:11:21,057	INFO	torchdistill.misc.log	Epoch: [20]  [ 5000/14658]  eta: 0:25:37  lr: 0.002  img/s: 59.74153758501585  loss: 0.8157 (0.8091)  time: 0.1595  data: 0.0131  max mem: 17059
2023-03-01 02:14:00,338	INFO	torchdistill.misc.log	Epoch: [20]  [ 6000/14658]  eta: 0:22:58  lr: 0.002  img/s: 59.97185359149102  loss: 0.7174 (0.8090)  time: 0.1600  data: 0.0132  max mem: 17059
2023-03-01 02:16:39,203	INFO	torchdistill.misc.log	Epoch: [20]  [ 7000/14658]  eta: 0:20:18  lr: 0.002  img/s: 59.289210082251806  loss: 0.8028 (0.8087)  time: 0.1571  data: 0.0131  max mem: 17059
2023-03-01 02:19:18,634	INFO	torchdistill.misc.log	Epoch: [20]  [ 8000/14658]  eta: 0:17:40  lr: 0.002  img/s: 57.19433961620934  loss: 0.8235 (0.8098)  time: 0.1586  data: 0.0129  max mem: 17059
2023-03-01 02:21:57,541	INFO	torchdistill.misc.log	Epoch: [20]  [ 9000/14658]  eta: 0:15:00  lr: 0.002  img/s: 58.30746827832361  loss: 0.8411 (0.8093)  time: 0.1579  data: 0.0128  max mem: 17059
2023-03-01 02:24:36,263	INFO	torchdistill.misc.log	Epoch: [20]  [10000/14658]  eta: 0:12:21  lr: 0.002  img/s: 59.946460856826384  loss: 0.8055 (0.8093)  time: 0.1586  data: 0.0130  max mem: 17059
2023-03-01 02:27:15,844	INFO	torchdistill.misc.log	Epoch: [20]  [11000/14658]  eta: 0:09:42  lr: 0.002  img/s: 59.876501175958346  loss: 0.7287 (0.8102)  time: 0.1661  data: 0.0137  max mem: 17059
2023-03-01 02:29:53,412	INFO	torchdistill.misc.log	Epoch: [20]  [12000/14658]  eta: 0:07:02  lr: 0.002  img/s: 60.66634122705199  loss: 0.7372 (0.8104)  time: 0.1557  data: 0.0128  max mem: 17059
2023-03-01 02:32:29,963	INFO	torchdistill.misc.log	Epoch: [20]  [13000/14658]  eta: 0:04:23  lr: 0.002  img/s: 60.088593450044414  loss: 0.8616 (0.8108)  time: 0.1575  data: 0.0124  max mem: 17059
2023-03-01 02:35:06,142	INFO	torchdistill.misc.log	Epoch: [20]  [14000/14658]  eta: 0:01:44  lr: 0.002  img/s: 62.08138895929812  loss: 0.8019 (0.8107)  time: 0.1569  data: 0.0125  max mem: 17059
2023-03-01 02:36:49,035	INFO	torchdistill.misc.log	Epoch: [20] Total time: 0:38:44
2023-03-01 02:36:52,971	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 0:59:02  model_time: 0.1030 (0.1030)  evaluator_time: 0.0284 (0.0284)  time: 0.7085  data: 0.5756  max mem: 17059
2023-03-01 02:38:32,662	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:06:41  model_time: 0.0770 (0.0829)  evaluator_time: 0.0082 (0.0161)  time: 0.0952  data: 0.0001  max mem: 17059
2023-03-01 02:40:12,774	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:00  model_time: 0.0800 (0.0828)  evaluator_time: 0.0096 (0.0164)  time: 0.0956  data: 0.0001  max mem: 17059
2023-03-01 02:41:51,434	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:19  model_time: 0.0839 (0.0826)  evaluator_time: 0.0092 (0.0161)  time: 0.0971  data: 0.0001  max mem: 17059
2023-03-01 02:43:30,080	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:39  model_time: 0.0831 (0.0825)  evaluator_time: 0.0096 (0.0160)  time: 0.0983  data: 0.0001  max mem: 17059
2023-03-01 02:45:08,813	INFO	torchdistill.misc.log	Validation: Total time: 0:08:16
2023-03-01 02:45:08,813	INFO	__main__	Averaged stats: model_time: 0.0798 (0.0825)  evaluator_time: 0.0097 (0.0159)
2023-03-01 02:45:08,991	INFO	__main__	Accumulating evaluation results...
2023-03-01 02:45:24,366	INFO	__main__	DONE (t=15.37s).
2023-03-01 02:45:24,367	INFO	__main__	IoU metric: bbox
2023-03-01 02:45:24,368	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.225
2023-03-01 02:45:24,368	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.395
2023-03-01 02:45:24,368	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.230
2023-03-01 02:45:24,369	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.064
2023-03-01 02:45:24,370	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.236
2023-03-01 02:45:24,370	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.376
2023-03-01 02:45:24,370	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.226
2023-03-01 02:45:24,371	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.344
2023-03-01 02:45:24,371	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.361
2023-03-01 02:45:24,371	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.114
2023-03-01 02:45:24,371	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.396
2023-03-01 02:45:24,371	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.585
2023-03-01 02:45:25,190	INFO	__main__	Best mAP (bbox): 0.2239 -> 0.2246
2023-03-01 02:45:25,193	INFO	__main__	Updating ckpt at ./resource/ckpt/coco2017/supervised_compression/entropic_student/coco2017-faster_rcnn_splittable_resnet50-fp-beta5.12_fpn.pt
2023-03-01 02:45:26,778	INFO	torchdistill.misc.log	Epoch: [21]  [    0/14658]  eta: 3:45:58  lr: 0.002  img/s: 53.9436905471949  loss: 1.0182 (1.0182)  time: 0.9250  data: 0.7646  max mem: 17059
2023-03-01 02:48:03,291	INFO	torchdistill.misc.log	Epoch: [21]  [ 1000/14658]  eta: 0:35:48  lr: 0.002  img/s: 59.809049847957134  loss: 0.7993 (0.8073)  time: 0.1562  data: 0.0126  max mem: 17059
2023-03-01 02:50:39,685	INFO	torchdistill.misc.log	Epoch: [21]  [ 2000/14658]  eta: 0:33:05  lr: 0.002  img/s: 59.241581920903954  loss: 0.7215 (0.8046)  time: 0.1542  data: 0.0119  max mem: 17059
2023-03-01 02:53:15,963	INFO	torchdistill.misc.log	Epoch: [21]  [ 3000/14658]  eta: 0:30:26  lr: 0.002  img/s: 57.925675034137974  loss: 0.7683 (0.8066)  time: 0.1562  data: 0.0122  max mem: 17059
2023-03-01 02:55:52,450	INFO	torchdistill.misc.log	Epoch: [21]  [ 4000/14658]  eta: 0:27:49  lr: 0.002  img/s: 61.90957414422011  loss: 0.7456 (0.8067)  time: 0.1548  data: 0.0118  max mem: 17059
2023-03-01 02:58:28,988	INFO	torchdistill.misc.log	Epoch: [21]  [ 5000/14658]  eta: 0:25:12  lr: 0.002  img/s: 59.65189936427119  loss: 0.8432 (0.8032)  time: 0.1541  data: 0.0116  max mem: 17059
2023-03-01 03:01:05,416	INFO	torchdistill.misc.log	Epoch: [21]  [ 6000/14658]  eta: 0:22:35  lr: 0.002  img/s: 59.7783629127369  loss: 0.8233 (0.8064)  time: 0.1566  data: 0.0116  max mem: 17059
2023-03-01 03:03:41,561	INFO	torchdistill.misc.log	Epoch: [21]  [ 7000/14658]  eta: 0:19:58  lr: 0.002  img/s: 59.62211501728013  loss: 0.7684 (0.8058)  time: 0.1543  data: 0.0116  max mem: 17059
2023-03-01 03:06:17,790	INFO	torchdistill.misc.log	Epoch: [21]  [ 8000/14658]  eta: 0:17:21  lr: 0.002  img/s: 59.01153694636727  loss: 0.8483 (0.8065)  time: 0.1559  data: 0.0121  max mem: 17059
2023-03-01 03:08:53,752	INFO	torchdistill.misc.log	Epoch: [21]  [ 9000/14658]  eta: 0:14:44  lr: 0.002  img/s: 58.96880953217813  loss: 0.8121 (0.8066)  time: 0.1558  data: 0.0119  max mem: 17059
2023-03-01 03:11:29,924	INFO	torchdistill.misc.log	Epoch: [21]  [10000/14658]  eta: 0:12:08  lr: 0.002  img/s: 59.017453139647984  loss: 0.7118 (0.8061)  time: 0.1559  data: 0.0116  max mem: 17059
2023-03-01 03:14:06,821	INFO	torchdistill.misc.log	Epoch: [21]  [11000/14658]  eta: 0:09:32  lr: 0.002  img/s: 53.67970487260953  loss: 0.7059 (0.8071)  time: 0.1582  data: 0.0124  max mem: 17059
2023-03-01 03:16:44,178	INFO	torchdistill.misc.log	Epoch: [21]  [12000/14658]  eta: 0:06:56  lr: 0.002  img/s: 59.62868409501655  loss: 0.8216 (0.8075)  time: 0.1556  data: 0.0127  max mem: 17059
2023-03-01 03:19:21,743	INFO	torchdistill.misc.log	Epoch: [21]  [13000/14658]  eta: 0:04:19  lr: 0.002  img/s: 53.28231610104359  loss: 0.7605 (0.8079)  time: 0.1579  data: 0.0129  max mem: 17059
2023-03-01 03:21:59,797	INFO	torchdistill.misc.log	Epoch: [21]  [14000/14658]  eta: 0:01:43  lr: 0.002  img/s: 53.6058675894285  loss: 0.7781 (0.8084)  time: 0.1578  data: 0.0131  max mem: 17059
2023-03-01 03:23:43,794	INFO	torchdistill.misc.log	Epoch: [21] Total time: 0:38:17
2023-03-01 03:23:50,279	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 0:58:12  model_time: 0.0968 (0.0968)  evaluator_time: 0.0287 (0.0287)  time: 0.6985  data: 0.5704  max mem: 17059
2023-03-01 03:25:30,337	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:06:42  model_time: 0.0814 (0.0831)  evaluator_time: 0.0082 (0.0162)  time: 0.0980  data: 0.0001  max mem: 17059
2023-03-01 03:27:10,658	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:01  model_time: 0.0789 (0.0829)  evaluator_time: 0.0106 (0.0165)  time: 0.0971  data: 0.0001  max mem: 17059
2023-03-01 03:28:49,724	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:20  model_time: 0.0818 (0.0828)  evaluator_time: 0.0093 (0.0162)  time: 0.0970  data: 0.0001  max mem: 17059
2023-03-01 03:30:28,477	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:39  model_time: 0.0802 (0.0826)  evaluator_time: 0.0085 (0.0161)  time: 0.0960  data: 0.0001  max mem: 17059
2023-03-01 03:32:06,820	INFO	torchdistill.misc.log	Validation: Total time: 0:08:17
2023-03-01 03:32:06,821	INFO	__main__	Averaged stats: model_time: 0.0799 (0.0825)  evaluator_time: 0.0089 (0.0160)
2023-03-01 03:32:07,043	INFO	__main__	Accumulating evaluation results...
2023-03-01 03:32:22,412	INFO	__main__	DONE (t=15.37s).
2023-03-01 03:32:22,412	INFO	__main__	IoU metric: bbox
2023-03-01 03:32:22,413	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.225
2023-03-01 03:32:22,413	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.396
2023-03-01 03:32:22,414	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.227
2023-03-01 03:32:22,414	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.065
2023-03-01 03:32:22,415	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.235
2023-03-01 03:32:22,416	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.373
2023-03-01 03:32:22,416	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.227
2023-03-01 03:32:22,416	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.345
2023-03-01 03:32:22,416	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.361
2023-03-01 03:32:22,416	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.117
2023-03-01 03:32:22,416	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.399
2023-03-01 03:32:22,416	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.584
2023-03-01 03:32:24,514	INFO	torchdistill.misc.log	Epoch: [22]  [    0/14658]  eta: 5:28:48  lr: 0.0002  img/s: 55.97349658865331  loss: 0.9301 (0.9301)  time: 1.3460  data: 1.1742  max mem: 17059
2023-03-01 03:35:00,057	INFO	torchdistill.misc.log	Epoch: [22]  [ 1000/14658]  eta: 0:35:40  lr: 0.0002  img/s: 57.92887515429834  loss: 0.7196 (0.7978)  time: 0.1565  data: 0.0118  max mem: 17059
2023-03-01 03:37:37,402	INFO	torchdistill.misc.log	Epoch: [22]  [ 2000/14658]  eta: 0:33:07  lr: 0.0002  img/s: 58.340111831307205  loss: 0.9133 (0.7926)  time: 0.1595  data: 0.0125  max mem: 17059
2023-03-01 03:40:15,097	INFO	torchdistill.misc.log	Epoch: [22]  [ 3000/14658]  eta: 0:30:33  lr: 0.0002  img/s: 52.99100140553687  loss: 0.7927 (0.7969)  time: 0.1600  data: 0.0124  max mem: 17059
2023-03-01 03:42:53,949	INFO	torchdistill.misc.log	Epoch: [22]  [ 4000/14658]  eta: 0:28:00  lr: 0.0002  img/s: 59.34940419653643  loss: 0.7652 (0.7984)  time: 0.1607  data: 0.0135  max mem: 17059
2023-03-01 03:45:32,350	INFO	torchdistill.misc.log	Epoch: [22]  [ 5000/14658]  eta: 0:25:24  lr: 0.0002  img/s: 60.03602043281059  loss: 0.8494 (0.7978)  time: 0.1572  data: 0.0133  max mem: 17059
2023-03-01 03:48:11,222	INFO	torchdistill.misc.log	Epoch: [22]  [ 6000/14658]  eta: 0:22:47  lr: 0.0002  img/s: 59.92569124218211  loss: 0.6870 (0.7973)  time: 0.1582  data: 0.0123  max mem: 17059
2023-03-01 03:50:50,189	INFO	torchdistill.misc.log	Epoch: [22]  [ 7000/14658]  eta: 0:20:10  lr: 0.0002  img/s: 57.305106397513406  loss: 0.7985 (0.7976)  time: 0.1605  data: 0.0126  max mem: 17059
2023-03-01 03:53:29,375	INFO	torchdistill.misc.log	Epoch: [22]  [ 8000/14658]  eta: 0:17:33  lr: 0.0002  img/s: 60.7613670316696  loss: 0.7767 (0.7989)  time: 0.1592  data: 0.0133  max mem: 17059
2023-03-01 03:56:07,968	INFO	torchdistill.misc.log	Epoch: [22]  [ 9000/14658]  eta: 0:14:55  lr: 0.0002  img/s: 59.71580809464996  loss: 0.7990 (0.7980)  time: 0.1603  data: 0.0134  max mem: 17059
2023-03-01 03:58:46,874	INFO	torchdistill.misc.log	Epoch: [22]  [10000/14658]  eta: 0:12:17  lr: 0.0002  img/s: 52.932485684087645  loss: 0.8196 (0.7988)  time: 0.1594  data: 0.0131  max mem: 17059
2023-03-01 04:01:25,826	INFO	torchdistill.misc.log	Epoch: [22]  [11000/14658]  eta: 0:09:39  lr: 0.0002  img/s: 59.49757696870185  loss: 0.7935 (0.7996)  time: 0.1568  data: 0.0129  max mem: 17059
2023-03-01 04:04:05,003	INFO	torchdistill.misc.log	Epoch: [22]  [12000/14658]  eta: 0:07:01  lr: 0.0002  img/s: 59.02264375964158  loss: 0.6770 (0.8001)  time: 0.1594  data: 0.0128  max mem: 17059
2023-03-01 04:06:43,963	INFO	torchdistill.misc.log	Epoch: [22]  [13000/14658]  eta: 0:04:22  lr: 0.0002  img/s: 59.078552652197416  loss: 0.7649 (0.7996)  time: 0.1579  data: 0.0124  max mem: 17059
2023-03-01 04:09:22,896	INFO	torchdistill.misc.log	Epoch: [22]  [14000/14658]  eta: 0:01:44  lr: 0.0002  img/s: 58.05044098667525  loss: 0.8168 (0.7996)  time: 0.1580  data: 0.0132  max mem: 17059
2023-03-01 04:11:07,801	INFO	torchdistill.misc.log	Epoch: [22] Total time: 0:38:44
2023-03-01 04:11:14,356	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 1:00:10  model_time: 0.1242 (0.1242)  evaluator_time: 0.0293 (0.0293)  time: 0.7220  data: 0.5664  max mem: 17059
2023-03-01 04:12:55,275	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:06:46  model_time: 0.0798 (0.0838)  evaluator_time: 0.0087 (0.0163)  time: 0.0947  data: 0.0001  max mem: 17059
2023-03-01 04:14:35,914	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:03  model_time: 0.0822 (0.0834)  evaluator_time: 0.0101 (0.0166)  time: 0.0971  data: 0.0001  max mem: 17059
2023-03-01 04:16:15,337	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:21  model_time: 0.0817 (0.0833)  evaluator_time: 0.0091 (0.0163)  time: 0.0959  data: 0.0001  max mem: 17059
2023-03-01 04:17:54,492	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:40  model_time: 0.0796 (0.0831)  evaluator_time: 0.0086 (0.0162)  time: 0.0932  data: 0.0001  max mem: 17059
2023-03-01 04:19:33,670	INFO	torchdistill.misc.log	Validation: Total time: 0:08:20
2023-03-01 04:19:33,670	INFO	__main__	Averaged stats: model_time: 0.0775 (0.0830)  evaluator_time: 0.0088 (0.0160)
2023-03-01 04:19:33,845	INFO	__main__	Accumulating evaluation results...
2023-03-01 04:19:52,462	INFO	__main__	DONE (t=18.62s).
2023-03-01 04:19:52,463	INFO	__main__	IoU metric: bbox
2023-03-01 04:19:52,465	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.228
2023-03-01 04:19:52,465	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.397
2023-03-01 04:19:52,465	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.232
2023-03-01 04:19:52,466	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.066
2023-03-01 04:19:52,467	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.239
2023-03-01 04:19:52,468	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.379
2023-03-01 04:19:52,468	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.230
2023-03-01 04:19:52,469	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.349
2023-03-01 04:19:52,469	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.366
2023-03-01 04:19:52,469	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.118
2023-03-01 04:19:52,469	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.402
2023-03-01 04:19:52,469	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.588
2023-03-01 04:19:53,254	INFO	__main__	Best mAP (bbox): 0.2246 -> 0.2277
2023-03-01 04:19:53,256	INFO	__main__	Updating ckpt at ./resource/ckpt/coco2017/supervised_compression/entropic_student/coco2017-faster_rcnn_splittable_resnet50-fp-beta5.12_fpn.pt
2023-03-01 04:19:54,650	INFO	torchdistill.misc.log	Epoch: [23]  [    0/14658]  eta: 3:31:01  lr: 0.0002  img/s: 52.772978770921604  loss: 0.8410 (0.8410)  time: 0.8638  data: 0.7013  max mem: 17059
2023-03-01 04:22:32,077	INFO	torchdistill.misc.log	Epoch: [23]  [ 1000/14658]  eta: 0:35:59  lr: 0.0002  img/s: 64.35646663495619  loss: 0.7151 (0.8051)  time: 0.1551  data: 0.0116  max mem: 17059
2023-03-01 04:25:09,671	INFO	torchdistill.misc.log	Epoch: [23]  [ 2000/14658]  eta: 0:33:18  lr: 0.0002  img/s: 59.92194567913581  loss: 0.7595 (0.7981)  time: 0.1569  data: 0.0119  max mem: 17059
2023-03-01 04:27:48,035	INFO	torchdistill.misc.log	Epoch: [23]  [ 3000/14658]  eta: 0:30:42  lr: 0.0002  img/s: 57.40294452751043  loss: 0.7511 (0.8012)  time: 0.1596  data: 0.0131  max mem: 17059
2023-03-01 04:30:27,322	INFO	torchdistill.misc.log	Epoch: [23]  [ 4000/14658]  eta: 0:28:07  lr: 0.0002  img/s: 60.02517325395434  loss: 0.7584 (0.7987)  time: 0.1585  data: 0.0126  max mem: 17059
2023-03-01 04:33:06,613	INFO	torchdistill.misc.log	Epoch: [23]  [ 5000/14658]  eta: 0:25:31  lr: 0.0002  img/s: 56.787699598053734  loss: 0.6963 (0.7982)  time: 0.1590  data: 0.0128  max mem: 17059
2023-03-01 04:35:45,935	INFO	torchdistill.misc.log	Epoch: [23]  [ 6000/14658]  eta: 0:22:53  lr: 0.0002  img/s: 53.53710165600055  loss: 0.8773 (0.7997)  time: 0.1595  data: 0.0130  max mem: 17059
2023-03-01 04:38:25,124	INFO	torchdistill.misc.log	Epoch: [23]  [ 7000/14658]  eta: 0:20:15  lr: 0.0002  img/s: 59.99072456720309  loss: 0.7624 (0.8001)  time: 0.1587  data: 0.0132  max mem: 17059
2023-03-01 04:41:04,211	INFO	torchdistill.misc.log	Epoch: [23]  [ 8000/14658]  eta: 0:17:37  lr: 0.0002  img/s: 53.46774512240982  loss: 0.7818 (0.8007)  time: 0.1597  data: 0.0130  max mem: 17059
2023-03-01 04:43:43,383	INFO	torchdistill.misc.log	Epoch: [23]  [ 9000/14658]  eta: 0:14:58  lr: 0.0002  img/s: 59.33502620652581  loss: 0.8333 (0.8019)  time: 0.1591  data: 0.0136  max mem: 17059
2023-03-01 04:46:22,834	INFO	torchdistill.misc.log	Epoch: [23]  [10000/14658]  eta: 0:12:20  lr: 0.0002  img/s: 58.929248580089286  loss: 0.6516 (0.8003)  time: 0.1597  data: 0.0126  max mem: 17059
2023-03-01 04:49:01,970	INFO	torchdistill.misc.log	Epoch: [23]  [11000/14658]  eta: 0:09:41  lr: 0.0002  img/s: 59.642992740691234  loss: 0.7836 (0.8008)  time: 0.1591  data: 0.0132  max mem: 17059
2023-03-01 04:51:41,285	INFO	torchdistill.misc.log	Epoch: [23]  [12000/14658]  eta: 0:07:02  lr: 0.0002  img/s: 59.536531616731196  loss: 0.7914 (0.8005)  time: 0.1593  data: 0.0123  max mem: 17059
2023-03-01 04:54:20,295	INFO	torchdistill.misc.log	Epoch: [23]  [13000/14658]  eta: 0:04:23  lr: 0.0002  img/s: 59.786351269245365  loss: 0.7396 (0.7999)  time: 0.1584  data: 0.0130  max mem: 17059
2023-03-01 04:56:59,288	INFO	torchdistill.misc.log	Epoch: [23]  [14000/14658]  eta: 0:01:44  lr: 0.0002  img/s: 52.89493662904344  loss: 0.7572 (0.7999)  time: 0.1575  data: 0.0126  max mem: 17059
2023-03-01 04:58:44,009	INFO	torchdistill.misc.log	Epoch: [23] Total time: 0:38:50
2023-03-01 04:58:48,019	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 1:00:19  model_time: 0.1178 (0.1178)  evaluator_time: 0.0310 (0.0310)  time: 0.7238  data: 0.5731  max mem: 17059
2023-03-01 05:00:28,779	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:06:45  model_time: 0.0784 (0.0835)  evaluator_time: 0.0084 (0.0165)  time: 0.0929  data: 0.0001  max mem: 17059
2023-03-01 05:02:09,359	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:02  model_time: 0.0803 (0.0832)  evaluator_time: 0.0102 (0.0167)  time: 0.0986  data: 0.0001  max mem: 17059
2023-03-01 05:03:49,032	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:21  model_time: 0.0816 (0.0832)  evaluator_time: 0.0093 (0.0164)  time: 0.0963  data: 0.0001  max mem: 17059
2023-03-01 05:05:28,304	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:40  model_time: 0.0836 (0.0830)  evaluator_time: 0.0086 (0.0163)  time: 0.1005  data: 0.0001  max mem: 17059
2023-03-01 05:07:07,194	INFO	torchdistill.misc.log	Validation: Total time: 0:08:19
2023-03-01 05:07:07,194	INFO	__main__	Averaged stats: model_time: 0.0798 (0.0829)  evaluator_time: 0.0095 (0.0161)
2023-03-01 05:07:07,415	INFO	__main__	Accumulating evaluation results...
2023-03-01 05:07:23,191	INFO	__main__	DONE (t=15.78s).
2023-03-01 05:07:23,191	INFO	__main__	IoU metric: bbox
2023-03-01 05:07:23,192	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.226
2023-03-01 05:07:23,193	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.395
2023-03-01 05:07:23,193	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.230
2023-03-01 05:07:23,194	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.065
2023-03-01 05:07:23,194	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.238
2023-03-01 05:07:23,195	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.377
2023-03-01 05:07:23,195	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.229
2023-03-01 05:07:23,195	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.347
2023-03-01 05:07:23,195	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.363
2023-03-01 05:07:23,196	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.118
2023-03-01 05:07:23,196	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.399
2023-03-01 05:07:23,196	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.585
2023-03-01 05:07:25,324	INFO	torchdistill.misc.log	Epoch: [24]  [    0/14658]  eta: 5:27:18  lr: 0.0002  img/s: 54.982027921609756  loss: 0.7754 (0.7754)  time: 1.3398  data: 1.1672  max mem: 17059
2023-03-01 05:10:03,165	INFO	torchdistill.misc.log	Epoch: [24]  [ 1000/14658]  eta: 0:36:11  lr: 0.0002  img/s: 59.12862786837292  loss: 0.7122 (0.8026)  time: 0.1583  data: 0.0128  max mem: 17059
2023-03-01 05:12:42,261	INFO	torchdistill.misc.log	Epoch: [24]  [ 2000/14658]  eta: 0:33:33  lr: 0.0002  img/s: 52.940001893282  loss: 0.6814 (0.8047)  time: 0.1590  data: 0.0131  max mem: 17059
2023-03-01 05:15:20,891	INFO	torchdistill.misc.log	Epoch: [24]  [ 3000/14658]  eta: 0:30:52  lr: 0.0002  img/s: 59.337649407674505  loss: 0.8349 (0.8027)  time: 0.1578  data: 0.0132  max mem: 17059
2023-03-01 05:17:59,906	INFO	torchdistill.misc.log	Epoch: [24]  [ 4000/14658]  eta: 0:28:13  lr: 0.0002  img/s: 60.07858781147663  loss: 0.7010 (0.7998)  time: 0.1582  data: 0.0126  max mem: 17059
2023-03-01 05:20:39,053	INFO	torchdistill.misc.log	Epoch: [24]  [ 5000/14658]  eta: 0:25:35  lr: 0.0002  img/s: 58.82934030425917  loss: 0.7195 (0.8020)  time: 0.1595  data: 0.0127  max mem: 17059
2023-03-01 05:23:18,056	INFO	torchdistill.misc.log	Epoch: [24]  [ 6000/14658]  eta: 0:22:56  lr: 0.0002  img/s: 57.33742075494267  loss: 0.6780 (0.8028)  time: 0.1581  data: 0.0126  max mem: 17059
2023-03-01 05:25:56,945	INFO	torchdistill.misc.log	Epoch: [24]  [ 7000/14658]  eta: 0:20:17  lr: 0.0002  img/s: 59.671736760581666  loss: 0.8345 (0.8020)  time: 0.1579  data: 0.0132  max mem: 17059
2023-03-01 05:28:36,016	INFO	torchdistill.misc.log	Epoch: [24]  [ 8000/14658]  eta: 0:17:38  lr: 0.0002  img/s: 57.36849646003628  loss: 0.7000 (0.8007)  time: 0.1573  data: 0.0124  max mem: 17059
2023-03-01 05:31:15,023	INFO	torchdistill.misc.log	Epoch: [24]  [ 9000/14658]  eta: 0:14:59  lr: 0.0002  img/s: 59.19977417078334  loss: 0.7433 (0.7982)  time: 0.1567  data: 0.0124  max mem: 17059
2023-03-01 05:33:53,564	INFO	torchdistill.misc.log	Epoch: [24]  [10000/14658]  eta: 0:12:20  lr: 0.0002  img/s: 58.5739383021213  loss: 0.9166 (0.7986)  time: 0.1606  data: 0.0134  max mem: 17059
2023-03-01 05:36:32,350	INFO	torchdistill.misc.log	Epoch: [24]  [11000/14658]  eta: 0:09:41  lr: 0.0002  img/s: 57.46802767691992  loss: 0.8187 (0.7984)  time: 0.1590  data: 0.0126  max mem: 17059
2023-03-01 05:39:11,281	INFO	torchdistill.misc.log	Epoch: [24]  [12000/14658]  eta: 0:07:02  lr: 0.0002  img/s: 59.7893341363587  loss: 0.7721 (0.7983)  time: 0.1577  data: 0.0125  max mem: 17059
2023-03-01 05:41:50,360	INFO	torchdistill.misc.log	Epoch: [24]  [13000/14658]  eta: 0:04:23  lr: 0.0002  img/s: 59.3613736760447  loss: 0.7730 (0.7990)  time: 0.1583  data: 0.0124  max mem: 17059
2023-03-01 05:44:29,105	INFO	torchdistill.misc.log	Epoch: [24]  [14000/14658]  eta: 0:01:44  lr: 0.0002  img/s: 59.60919299280343  loss: 0.8007 (0.7987)  time: 0.1604  data: 0.0128  max mem: 17059
2023-03-01 05:46:13,929	INFO	torchdistill.misc.log	Epoch: [24] Total time: 0:38:49
2023-03-01 05:46:17,989	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 1:00:41  model_time: 0.1273 (0.1273)  evaluator_time: 0.0285 (0.0285)  time: 0.7283  data: 0.5707  max mem: 17059
2023-03-01 05:48:01,274	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:06:55  model_time: 0.0811 (0.0837)  evaluator_time: 0.0084 (0.0188)  time: 0.0965  data: 0.0001  max mem: 17059
2023-03-01 05:49:41,694	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:06  model_time: 0.0781 (0.0834)  evaluator_time: 0.0099 (0.0177)  time: 0.0949  data: 0.0001  max mem: 17059
2023-03-01 05:51:20,515	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:22  model_time: 0.0823 (0.0831)  evaluator_time: 0.0093 (0.0170)  time: 0.0978  data: 0.0001  max mem: 17059
2023-03-01 05:53:00,244	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:40  model_time: 0.0830 (0.0831)  evaluator_time: 0.0103 (0.0167)  time: 0.1005  data: 0.0001  max mem: 17059
2023-03-01 05:54:38,634	INFO	torchdistill.misc.log	Validation: Total time: 0:08:21
2023-03-01 05:54:38,635	INFO	__main__	Averaged stats: model_time: 0.0797 (0.0830)  evaluator_time: 0.0099 (0.0164)
2023-03-01 05:54:38,812	INFO	__main__	Accumulating evaluation results...
2023-03-01 05:54:54,357	INFO	__main__	DONE (t=15.54s).
2023-03-01 05:54:54,357	INFO	__main__	IoU metric: bbox
2023-03-01 05:54:54,358	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.228
2023-03-01 05:54:54,358	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.399
2023-03-01 05:54:54,359	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.231
2023-03-01 05:54:54,359	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.066
2023-03-01 05:54:54,360	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.240
2023-03-01 05:54:54,361	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.379
2023-03-01 05:54:54,361	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.229
2023-03-01 05:54:54,361	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.348
2023-03-01 05:54:54,361	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.365
2023-03-01 05:54:54,361	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120
2023-03-01 05:54:54,361	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.399
2023-03-01 05:54:54,361	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.584
2023-03-01 05:54:55,118	INFO	__main__	Best mAP (bbox): 0.2277 -> 0.2279
2023-03-01 05:54:55,120	INFO	__main__	Updating ckpt at ./resource/ckpt/coco2017/supervised_compression/entropic_student/coco2017-faster_rcnn_splittable_resnet50-fp-beta5.12_fpn.pt
2023-03-01 05:54:56,510	INFO	torchdistill.misc.log	Epoch: [25]  [    0/14658]  eta: 3:17:29  lr: 0.0002  img/s: 50.93226675571679  loss: 0.6580 (0.6580)  time: 0.8084  data: 0.6405  max mem: 17059
2023-03-01 05:57:34,338	INFO	torchdistill.misc.log	Epoch: [25]  [ 1000/14658]  eta: 0:36:04  lr: 0.0002  img/s: 53.6219726763818  loss: 0.7511 (0.7945)  time: 0.1564  data: 0.0115  max mem: 17059
2023-03-01 06:00:13,179	INFO	torchdistill.misc.log	Epoch: [25]  [ 2000/14658]  eta: 0:33:28  lr: 0.0002  img/s: 57.82604844338363  loss: 0.7696 (0.7965)  time: 0.1599  data: 0.0136  max mem: 17059
2023-03-01 06:02:52,299	INFO	torchdistill.misc.log	Epoch: [25]  [ 3000/14658]  eta: 0:30:51  lr: 0.0002  img/s: 59.094575816867994  loss: 0.8274 (0.7973)  time: 0.1603  data: 0.0139  max mem: 17059
2023-03-01 06:05:31,475	INFO	torchdistill.misc.log	Epoch: [25]  [ 4000/14658]  eta: 0:28:13  lr: 0.0002  img/s: 59.02731609834358  loss: 0.7523 (0.7981)  time: 0.1602  data: 0.0135  max mem: 17059
2023-03-01 06:08:10,738	INFO	torchdistill.misc.log	Epoch: [25]  [ 5000/14658]  eta: 0:25:35  lr: 0.0002  img/s: 63.96925305982385  loss: 0.7961 (0.7989)  time: 0.1586  data: 0.0132  max mem: 17059
2023-03-01 06:10:49,476	INFO	torchdistill.misc.log	Epoch: [25]  [ 6000/14658]  eta: 0:22:56  lr: 0.0002  img/s: 52.81924979811702  loss: 0.8222 (0.7971)  time: 0.1612  data: 0.0134  max mem: 17059
2023-03-01 06:13:28,510	INFO	torchdistill.misc.log	Epoch: [25]  [ 7000/14658]  eta: 0:20:17  lr: 0.0002  img/s: 59.63981244823308  loss: 0.6434 (0.7981)  time: 0.1581  data: 0.0122  max mem: 17059
2023-03-01 06:16:07,649	INFO	torchdistill.misc.log	Epoch: [25]  [ 8000/14658]  eta: 0:17:38  lr: 0.0002  img/s: 58.905247931127704  loss: 0.8425 (0.7983)  time: 0.1592  data: 0.0131  max mem: 17059
2023-03-01 06:18:47,166	INFO	torchdistill.misc.log	Epoch: [25]  [ 9000/14658]  eta: 0:14:59  lr: 0.0002  img/s: 59.3786013983539  loss: 0.7287 (0.7989)  time: 0.1598  data: 0.0131  max mem: 17059
2023-03-01 06:21:26,394	INFO	torchdistill.misc.log	Epoch: [25]  [10000/14658]  eta: 0:12:20  lr: 0.0002  img/s: 57.56504076198841  loss: 0.7713 (0.7989)  time: 0.1603  data: 0.0132  max mem: 17059
2023-03-01 06:24:05,375	INFO	torchdistill.misc.log	Epoch: [25]  [11000/14658]  eta: 0:09:41  lr: 0.0002  img/s: 59.739835777209635  loss: 0.7159 (0.7983)  time: 0.1569  data: 0.0127  max mem: 17059
2023-03-01 06:26:44,349	INFO	torchdistill.misc.log	Epoch: [25]  [12000/14658]  eta: 0:07:02  lr: 0.0002  img/s: 58.756817429645594  loss: 0.8031 (0.7985)  time: 0.1588  data: 0.0129  max mem: 17059
2023-03-01 06:29:23,514	INFO	torchdistill.misc.log	Epoch: [25]  [13000/14658]  eta: 0:04:23  lr: 0.0002  img/s: 57.69936668048059  loss: 0.9110 (0.7982)  time: 0.1616  data: 0.0135  max mem: 17059
2023-03-01 06:32:02,411	INFO	torchdistill.misc.log	Epoch: [25]  [14000/14658]  eta: 0:01:44  lr: 0.0002  img/s: 57.30794468421601  loss: 0.6821 (0.7985)  time: 0.1581  data: 0.0126  max mem: 17059
2023-03-01 06:33:47,261	INFO	torchdistill.misc.log	Epoch: [25] Total time: 0:38:51
2023-03-01 06:33:51,213	INFO	torchdistill.misc.log	Validation:  [   0/5000]  eta: 0:57:22  model_time: 0.1088 (0.1088)  evaluator_time: 0.0309 (0.0309)  time: 0.6885  data: 0.5472  max mem: 17059
2023-03-01 06:35:34,613	INFO	torchdistill.misc.log	Validation:  [1000/5000]  eta: 0:06:55  model_time: 0.0815 (0.0838)  evaluator_time: 0.0087 (0.0188)  time: 0.0975  data: 0.0001  max mem: 17059
2023-03-01 06:37:14,679	INFO	torchdistill.misc.log	Validation:  [2000/5000]  eta: 0:05:06  model_time: 0.0813 (0.0832)  evaluator_time: 0.0103 (0.0177)  time: 0.0986  data: 0.0001  max mem: 17059
2023-03-01 06:38:54,393	INFO	torchdistill.misc.log	Validation:  [3000/5000]  eta: 0:03:22  model_time: 0.0847 (0.0833)  evaluator_time: 0.0089 (0.0170)  time: 0.0980  data: 0.0001  max mem: 17059
2023-03-01 06:40:33,277	INFO	torchdistill.misc.log	Validation:  [4000/5000]  eta: 0:01:40  model_time: 0.0784 (0.0830)  evaluator_time: 0.0089 (0.0167)  time: 0.0983  data: 0.0002  max mem: 17059
2023-03-01 06:42:12,114	INFO	torchdistill.misc.log	Validation: Total time: 0:08:21
2023-03-01 06:42:12,115	INFO	__main__	Averaged stats: model_time: 0.0796 (0.0830)  evaluator_time: 0.0096 (0.0164)
2023-03-01 06:42:12,322	INFO	__main__	Accumulating evaluation results...
2023-03-01 06:42:27,860	INFO	__main__	DONE (t=15.54s).
2023-03-01 06:42:27,861	INFO	__main__	IoU metric: bbox
2023-03-01 06:42:27,862	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.228
2023-03-01 06:42:27,862	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.398
2023-03-01 06:42:27,862	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.232
2023-03-01 06:42:27,863	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.066
2023-03-01 06:42:27,864	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.238
2023-03-01 06:42:27,865	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.379
2023-03-01 06:42:27,865	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.230
2023-03-01 06:42:27,865	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.349
2023-03-01 06:42:27,865	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.365
2023-03-01 06:42:27,865	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.121
2023-03-01 06:42:27,865	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.399
2023-03-01 06:42:27,865	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.583
2023-03-01 06:42:28,626	INFO	__main__	Training time 20:31:55
2023-03-01 06:42:29,521	INFO	torchdistill.common.main_util	Loading model parameters
2023-03-01 06:42:29,591	INFO	__main__	[Student: faster_rcnn_model]
2023-03-01 06:42:33,968	INFO	torchdistill.misc.log	Test:  [   0/5000]  eta: 1:35:14  model_time: 0.1176 (0.1176)  evaluator_time: 0.0261 (0.0261)  time: 1.1429  data: 0.9978  max mem: 17059
2023-03-01 06:44:16,151	INFO	torchdistill.misc.log	Test:  [1000/5000]  eta: 0:06:52  model_time: 0.0796 (0.0838)  evaluator_time: 0.0081 (0.0176)  time: 0.0956  data: 0.0001  max mem: 17059
2023-03-01 06:45:56,562	INFO	torchdistill.misc.log	Test:  [2000/5000]  eta: 0:05:05  model_time: 0.0818 (0.0837)  evaluator_time: 0.0095 (0.0169)  time: 0.0965  data: 0.0001  max mem: 17059
2023-03-01 06:47:35,731	INFO	torchdistill.misc.log	Test:  [3000/5000]  eta: 0:03:21  model_time: 0.0858 (0.0836)  evaluator_time: 0.0089 (0.0163)  time: 0.1002  data: 0.0001  max mem: 17059
2023-03-01 06:49:14,971	INFO	torchdistill.misc.log	Test:  [4000/5000]  eta: 0:01:40  model_time: 0.0820 (0.0834)  evaluator_time: 0.0077 (0.0160)  time: 0.0953  data: 0.0001  max mem: 17059
2023-03-01 06:50:53,633	INFO	torchdistill.misc.log	Test: Total time: 0:08:20
2023-03-01 06:50:53,633	INFO	__main__	Averaged stats: model_time: 0.0795 (0.0833)  evaluator_time: 0.0098 (0.0158)
2023-03-01 06:50:53,862	INFO	__main__	Accumulating evaluation results...
2023-03-01 06:51:12,378	INFO	__main__	DONE (t=18.52s).
2023-03-01 06:51:12,378	INFO	__main__	IoU metric: bbox
2023-03-01 06:51:12,379	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.228
2023-03-01 06:51:12,379	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.399
2023-03-01 06:51:12,380	INFO	__main__	 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.231
2023-03-01 06:51:12,381	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.066
2023-03-01 06:51:12,381	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.240
2023-03-01 06:51:12,382	INFO	__main__	 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.379
2023-03-01 06:51:12,382	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.229
2023-03-01 06:51:12,382	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.348
2023-03-01 06:51:12,382	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.365
2023-03-01 06:51:12,382	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120
2023-03-01 06:51:12,383	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.399
2023-03-01 06:51:12,383	INFO	__main__	 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.584
2023-03-01 06:51:12,384	INFO	sc2bench.analysis	Bottleneck size [KB]: mean 12.4281140625 std 1.7749194908781416 for 5000 samples
